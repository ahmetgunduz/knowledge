// The markup language of this document is AsciiDoc
:encoding: UTF-8
:toc:
:toclevels: 4

= Algorithms and data structures


== Misc. terms

In-place:: An algorithm using +O(1)+ auxiliary memory space.  Often even +O(log n)+ is considered as in place.

Sentinel:: A sentinel is a dummy object that allows us to simplify boundary conditions.

Memoization:: The solution to a given (sub)problem is memoized in a `memo pad' (aka table).  E.g. upfront or when first encountering it.  When later seeing the same (sub)problem again, its solution can be looked up in the memo.  See also <<dynamic_programming>>.

[[whp]]
With high probability (w.h.p.):: An event E occurs with high probability if Pr[E] ≥ 1−1/n^c^ for any constant c.

Output-sensitive algorithm:: An algorithm whose running time depends on the size of the output, in addition to, or instead of, the size of the input.

== Asymptotic notations / big O notation

In computer science, big O notation is used to classify algorithms by how they respond to changes in input size, typically regarding running time and space (memory/disk/...).

In the following +n+ is the _input size_, +f(n)+ is the _number of steps_ needed by an algorithm.

Recall definitions from math:

[cols="2,1,4"]
|====
| _upper bound_ | f(x) ≤ c ∀ x | f has upper bound c. f is bounded from above by c.
| _supremum_ (_tight/sharp upper bound_) | | Least upper bound. Not required to be in range of f.
| _maximum_ | | Largest element of f's range. ``worst case'' (if f models costs).
| _minimum_ | | Smallest element of f's range. ``best case'' (if f models costs).
| _infimum_ (_tight/sharp lower bound_) | | Greatest lower bound. Not required to be in range of f.
| _lower bound_ | f(x) ≥ c ∀ x | f has lower bound c. f is bounded from below by c.
|====

Types of asymptotic notations:

[cols="3,2,2,6,6"]
|====
| notation | | relation of growth rate | definition | notes
| f(n) ∊ ο(g(n)) | little-oh | f < g | For all c>0 there exists an n~0~>0 such that \|f(n)\| < c⋅\|g(n)\| for all n≥n~0~ | f is dominated by g asymptotically.  Intuitively: grows strictly slower than. Rarely used in computer science.
| f(n) ∊ O(g(n)) | big-oh    | f ≤ g | There exist an c>0 and n~0~>0 such that \|f(n)\| ≤ c⋅\|g(n)\| for all n≥n~0~ | Asymptotic upper bound (Mnemonic: O has a squiggle at the top (at least in some fonts)). Intuitively: grows no faster than.
| f(n) ∊ Θ(g(n)) | big-theta | f = g | There exist an c~1~>0, c~2~>0 and n~0~>0 such that c~1~⋅\|g(n)\| ≤ \|f(n)\| ≤ c~2~⋅\|g(n)\| for all n≥n~0~ | Asymptotic tight bound. Also called _rate/order of growth_. (Mnemonic: the bar is in the middle). Θ(g(n)) = O(g(n)) ∩ Ω(g(n))
| f(n) ∊ Ω(g(n)) | big-omega | f ≥ g | Like O, but ≥ instead ≤ | Asymptotic lower bound (Mnemonic: the bar is at the bottom).
| f(n) ∊ ω(g(n)) | little-omega | f > g | Like ο, but ≥ instead ≤ | f dominates g asymptotically. Rarely used in computer science.
|====

Note: Except for Θ(g(n)), no claim is made on how tight a bound is.  Technically it woudn't be wrong to say that a linear algorigthm is O(2^n^).

Note: Because O(g(n)) is really a set, we should actually write f(n) ∊ O(g(n)).  However we often write f(n) = O(g(n)), the equal sign meaning ∊. Informally, especially in computer science, the big-oh notation often is permitted to be somewhat abused to describe an asymptotic tight bound (it really only describes an asymptotic upper bound) where using big-theta notation might be more factually appropriate in a given context.

_worst case_ / _average case_ / _best case_ refers to the worst / average / best input -- a ``good'' input results in a short running time of the algorithm, a ``bad'' input results in a long running time.  For many algorithms we only care about the worst case, not the average case, because a) the worst case occurs fairly often in practice b) the average case is often as bad as the worst case c) it's difficult to know what an ``average'' input is (often it is assumed that all possible inputs are equally likely).

_Asymptotic efficiency_: Only look at rate of growth.  An algorithm is said to be _asymptotically optimal_ if, roughly speaking, its big-oh is equal to the big-oh of the best possible algorithm.

_amortized time_: `amortized +O(f)+' for operation o: In a sequence of length L of such o operations, the overall time is +O(L*f)+.  I.e. one of those o operations might use a particular large amount of time compared to the average case, but that time is amortized in the large.  A typical example is appending to an array; if the capacity is full, a new array of larger capacity needs to be allocated, and the data has to be copied.

An event E occures _with high probability_ (or __w.h.p.__ or _WHP_) if Pr(E) ≥ 1 - n^-c^ for any constant c.  I.e. we can make Pr(E) as close to 1 as we want by making c large enough.

Common functions ordered after order of growth: c, log~c~(n), n^1/c^, n, n·log~c~(n), n^c^, c^n^, n!, n^n^.

[[big_oh_cheat_sheets]]
Big oh cheat sheets:

- https://www.hackerearth.com/practice/notes/big-o-cheatsheet-series-data-structures-and-algorithms-with-thier-complexities-1/

References:

- Book "Introduction to algorithms", subchapter "3.1 Asymptotic notation"

- http://stackoverflow.com/questions/1364444/difference-between-big-o-and-little-o-notation

- http://stackoverflow.com/questions/2986074/algorithm-analysis-orders-of-growth-question


[[master_theorem]]
=== Master theorem for solving recurrences

Is a way of obtaining the asymptotic bounds of the running time T(n) of an algorithm when being given T(n) as a recurence relation.  Say the running time T(n) of an divide and conquer algorithm can be described recursively in the form ``T(n) = aT(n/b) + f(n)'', where a is the number of created subproblems and n/b is the size of each subproblem.  In other words, there are a subproblems which are solved recursively, each in time T(n/b). f(n) is the cost outside the recursive calls which includes dividing the problem and combining the results of the subproblems. In the following, ε is some constant greater than zero, c is a constant smaller than one, and p(n) = n^log~b~ a^.  The cases are numbered the same way as done by the book CLRS, which seems to be the canonical way of refering to the different cases.

[cols="1,4,4,6,6"]
|=====
|Case |Asymptotic bounds of T(n) |Condition for f(n) |Informal condition for f(n) |Additional conditions
|1    |Θ(p(n))                   |O(p(n)·n^-ε^)      |Grows polynomically slower than p(n)      |
|2    |Θ(p(n) · lg n)            |Θ(p(n))            |Same order of growth as p(n)|
|3    |Θ(f(n))                   |Ω(p(n)·n^ε^)       |Grows polynomically faster than p(n)      |af(n/b) ≤ cf(n) for sufficiently large n
|=====

Note that there is a gap between case and 1 and 2, when f(n) is maller than p(n) but not polynomically smaller.  To be polynomically smaller, it must be smaller by a factor of n^ε^.  Between 2 and 3 there is also a gap for analogous reasons.  Additionally the stated additional condition also contributes to the gap between 2 and 3.  Not all recurrence relations can be solved with the use of the master theorem; its generalizations include the Akra–Bazzi method.

An example of where f(n) grows faster than p(n), but not polynomically faster: T(n) = 2T(n/2) + n log n. We obtain p(n) = n^log~2~2^ = n. f(n) = n log n grows faster than p(n) = n, but not polynomically, since f(n) / p(n) = log n is asymptotically less than n^ε^ for any positive constant ε.

References:

- Book "Introduction to algorithms", subchapter "4.5 The master method for solving recurrences"

- https://www.saylor.org/site/wp-content/uploads/2011/06/Master-theorem.pdf


== Computational complexity classes

The field of computational _complexity classes_ categorizes decidable decision problems by how difficult they are to solve. "Difficult", in this sense, is described in terms of the needed computational resources.  A _decision problem_ is a problem with a binary answer, e.g. yes or no.  A _function problem_ can have answers that are more complex than a simple `yes' or `no'.  Function problems can be transformed into decision problems and vice versa.  Thus computational complexity can focus on decision problems. An _intractable problem_ is one that can be solved in theory (i.e. which is in R), but which in practice takes too long to be usefull. There's no exact definition, but in general problems not in P (but in R) are considered intractable.

Common complexity classes:

P:: (Decision) problems solvable in at most polynomial tyme (n^c^).  If you can establish a problem as not in P, you provide good evidence for its intractability.  You'd better spend your time developing an approximation algorithm or solve a tractable special case.

NP (non-determiniatic polynomial):: (Decision) problems solveable in polynomial time via a ``lucky'' algorithm: Like in dynamic programm the algorithm makes a guess at each branch points where it could follow multiple paths.  However, if the overall answer of the decision problem is yes, it magically (being an awsome cool fairy tale computer) always guesses the path that ultimatively leads to the yes.
+
Equivalently: (Decision) problems where the a given yes-answer (e.g. yes, this sudoku has a solution), has a proof (can take more than polynomial time) (e.g. this solved sudoku) which can be checked in at most polynomial time (e.g. take the alleged solution / proof and verify it holds up to the sudoku rules).
+
Is a nondeterministic computation model.  It's not a realistic model, but it's still a usefull model.

EXP:: (Decision) problems solvable in at most exponential tyme (2^n^).

R (recursive):: (Decision) problems solvable in finite time. Etymology: R stands for recursive, which in the old days stood for `will terminate'.

NP-hard (or X-hard in general):: At least as hard as every element in NP (X in general) (i.e. same hardness or harder, but not less hard than any element in NP (X in general))

NP-complete (or X-complete in general):: Intersection of NP and NP-hard.

[[pseudo_polynomial]]
Pseudo-polynomial:: A numeric algorithm runs in pseudo-polynomial time if its running time is polynomial in the numeric value of the input, but is exponential in the length of the input – the number of bits required to represent it.  E.g. <<knapsack>>, <<ford_fulkerson_algorithm>>.

Visualization of complexity classes, ordered on a line after hardness:

--------------------------------------------------
              P-complete  NP-complete  EXP-complete    R-complete
easier <----------|----------|-------------|---------|------> harder
      
P(incl P-complete)   P-hard (incl P-complete)
<-----------------+----------------------------------------->

      NP (incl NP-complete)     NP-hard (incl NP-complete)
<----------------------------+------------------------------>
--------------------------------------------------

Most people think P≠NP is true, but no one could prove it so far. It's one of the Millenium Prize Problems.  P≠NP translates to ``you can't engineer luck'', or to  ``solving problems is harder than checking solutions''.  NP is an awfully powerfull model of computation.  It can use this fairy tale computer which always magically guesses the right path.  So NP `obviously' is more powerfull than P -- except we don't know how to proof it.

Examples of NP-complete problems:

- Determining whether a graph contains a simple path with at least a given number of edges
- <<TSP,Travelling salesman problem>>
- <<knapsack>>
- <<hamiltoninan_path_problem>>
- _Boolean satisfiability_ (_SAT_) problem: *to-do*:
- _Subset sum problem_: Given a set (or multiset) of integers, is there a non-empty subset whose sum is zero?
- _clique problems_
 * Finding the maximum clique (a clique with the largest number of vertices)
 * Finding the maximum weight clique in a weighted graph
 * Listing all maximal cliques (cliques that cannot be enlarged)
- _minimum vertex cover_
- _maximum independent set problem_
- _Graph coloring_ regarding vertices (edges): Coloring the vertices (edges) of a graph such that no two adjacent vertices (edges) share the same color.


== Algorithm classifications by implementations

=== Recursion vs iteration

- What is computable by recursive functions is computable by an iterative model and vice versa.

- KISS: Use whichever is more easy to reason about for the given problem.  Since recursion maps easily to proof by induction, for many problems recursion is a straight forward choice.

* Recursion has to pay expense of function calls and function returns, which is typically larger than the (conditional) jump used in the iterative solution.  However in case of tail calls and an compiler featuring tail call optimization becomes pretty much equivalent to iteration since the machine code is iterative.

* Recursion needs memory on the stack for all the locals, the stack frame (the return address, the old stack pointer, ...).  However there are iterative solutions which need an stack or queue, which internally probably uses the heap with all its overhead in space and time.  It depends on the queue/stack implementation which is more efficient in terms of memory usage, locality, ....

- Modern compilers are good at converting some recursions to loops without even asking.


Terms: _base case_ is input for which the solution is directly known.  When the recursion arrives at the base case it is said to _bottom out_.


=== Recipes for convertion recursion to iteration

==== Tail call
Recipe for translating recursion into iteration for a function ++foo++ for the case where recursive calls are convertible to tail calls:

. Convert all recursive calls into tail calls.  If you're programming language supports tail call optimization, you're already done.

. Enclose the body of the function with a ++while(true) { ... }++ loop.

. Replace each call to ++foo++ according to this scheme: ``++foo(f1(...), f2(...), ...)++'' => ``++x1=f1(...); x2=f2(...); ...; continue;++''

. For languages where identifiers need to be defined: For each +x+ object introduced in the previous step, define the object before the while loop introduced earlier.

. Tidy up.


==== Non tail call
`Recipe' for translating recursion into iteration in case there are n multiple recursive calls which are not tail calls and not convertible to tail calls.  It's more tips than a proper recipe.

- Remember that all local variables (which includes parameters) and the return address are on the stack.  So if one needs to know the return address, i.e. one of multiple possible places, it gets nasty difficult.

- Enclose the whole body in a ++stack<...> s; s.push(args); while (!s.empty()) { current_args = s.pop(); ... }++

- Instead of n times recursively calling foo like ++foo(args1); foo(args2);...++ push the args on the stack in reverse order ++s.push(args2); s.push(args1)++.




Recipe for turning a non-tail call recursive function ++foo++ into one having a tail call:

. Identify what work is being done between the recursive call and the return statement.  That delivers a function +g(x,y)+, so the respective expression could be written as ++return g(foo(...), bar)++.
. Extend the function to do that +g+ work for us.  Extend it with an new accumulator argument, ++foo(..., acc=default_doing_nothing)++, and replace all return statements ++return lorem;++ with ++return g(lorem, acc);++.
. Now you can replace very occurrence of ++return g(foo(...), bar)++ with ++return foo(..., bar)++, since we don't have to do +g+ ourselves any more, we can let +foo+ do +g+ for us.

--------------------------------------------------
// example step 1
def factorial(n):
    if n < 2: return 1
    return factorial(n - 1) * n // thus we have an g: g(x,y)=x*y

// example step 2
def factorial(n, acc=1):
     if n < 2: return 1 * acc
     return (n * factorial(n - 1)) * acc //==factorial(n-1)*(acc*n)

// example step 3
def factorial(n, acc=1):
     if n < 2: return acc * 1
     return factorial(n - 1, acc*n)
--------------------------------------------------
See also: http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html


==== Non tail call

--------------------------------------------------
stack localsAndParamsStack;
stack addrStack;
addr = FunEntr;
auto done = false;
do {
  switch (addr) {
  case FunEntry:
    ...
  case X:
    ...
  }
} while (not done);
--------------------------------------------------


*to-do*: mind implicit return at end of original function

*to-do*: how to return values from called function?

How to translate calls and returns:

--------------------------------------------------
             function call                      | return
machine instr.     pseudo code in loop          | pseudo code in loop
 -----------------------------------------------|-------------------------
                                                | continue
                                                |
(save locals)      localsAndParamsStack.push(   | localsAndParams = 
                       locals and params)       |    localsAndParamsStack.pop()
                                                |
push params        params = new params          |
                                                |
push returnAddr    addrStack.push(addr)         |
                                                |
jmp funAddr        addr = FunEntry              | addr = addrStack.pop()
                   continue                     |
                                                |
                                                | if (addrStack.empty())
--------------------------------------------------


=== Deterministic vs non-deterministic
*to-do*

=== Serial vs parallel vs distributed
*to-do*

=== Exact vs approximate
*to-do*


== Algorithm design techniques / paradigms

[[relation_between_techniques]]
=== Relation between techniques

Decrease and conquer is similar to divide and conquer.  However the latter splits the problem into two or more sub problems.  The former doesn't need to combine the results of the sub problems.

In dynamic programming, subproblems overlapp and we need to solve them only once. In divide/decrease and conquer, sub problems do not overlap.

Dynamic programming vs greedy algorithm: in dynamic programming and divide/decrease and conquer the choices are made depending on the result of the sub problems. I.e. the sub problems are solved first.  The greedy algorithm makes first a (greedy) choice, thus reduces the problem to a subproblem, and then solves that remaining subproblem.


=== Brute force (aka exhaustive search)
This is the naive method of trying every possible solution to see which is best.


[[divide_and_conquer]]
=== Divide and Conquer

_Divide_ the problem into two or more subproblems that are smaller instances of the same problem.  _Conquer_ the subproblems by solving them recursively.  If the size of a subproblem is small enough, stop recursion (we say the recursion _bottoms out_) and solve it (we call that small subproblem a _base case_) in a straightforward manner.  _Combine_ the solutions the subproblems into the solution of the original problem.  See also <<relation_between_techniques>>.

See <<master_theorem>> for a possible way of calculating assymptotic bounds on the running time.

Examples: Quick sort

References:

- Book "Introduction to algorithms", chapter "Divide-and-Conquer"


[[decrease_and_conquer]]
=== Decrease and conquer (aka prune and search)

In each step the problem is turned into one single sub problem of smaller size, where as the rest ist pruned.  The algorithm stops when the base case is reached.  My thoughts: The size of a subproblem is typically by a constant factor (on average) smaller than one of the parent problem -- if the size would only decrease by a constant amount, in the worst case 1, it would just be the naive brute force solution.  See also See also <<relation_between_techniques>>.

Examples: binary search, quickselect.


[[dynamic_programming]]
=== Dynamic programming (DP)
Basic idea: `carefull brute force'.  Use brute force, i.e. try all possible ways (and in case of optimization problems, take the best one).  However do that `carefully', by dividing the problem recursively into subproblems and use <<memoization>> to solve a particular subproblem only once.  Thus DP is often good for optimizations problems.  The memo is typically an associative array with +O(1)+ insert and lookup time.

The following demonstrates dynamic programing by solving the <<rod_cutting_problem>>: Consider a steel company cutting steel rods and selling the pieces.  For simplicity lengths are integers.  Given a table of prices which states the price for a rod of length i.  How to cut a rod of length n into multiple smaller rods to maximize revenue.

Dynamic programming needs two hallmarks:

- _Optimal substructure_: An optimal solution to the problem contains within it optimal solutions to subproblems.  I.e. if you have an optimal solutions to each sub problem, you can combine them to form the optimal solution to the original problem.  Example: in the rod cutting problem, if we cut a rod of length +n+ in two pieces,  that gives us two new subproblems, namely optimally cutting these two pieces.

- _Overlapping subproblems_: A given sub-problem has to be solved/computed many times.  If that's not the case, there's no point in doing memoization.  Example: in the rod cutting problem, the problem of cutting a rod of length 2 has to be solved again and again within the problem of cutting a rod of length greater than 2.  Effectively the sub-problems form a directed graph, where x->y means subproblem x depends on subproblem y (i.e. y must be solved first).

Dynamic programming recipe:

1. _Define all subproblems_: I.e. define all vertices in the subproblem DAG. Details: Typically the input is a sequence of n items. For a given problem, it's subproblems are often either suffixes [i:] (Θ(n)) or prefixes [:i] (Θ(n)) or substrings [i:j] (Θ(n*n)).

2. _Guessing_ (I would say try all): For each step (i.e. node / subproblem), think about all the possible paths (i.e. outgoing edges) that have to be tried.

3. _Recurrence_: Same as step 2, but more formal: Formulate the recursive DP(...) function which returns the min/max/..., which includes defining the base cases.  Check that graph of subproblems is acyclic, i.e. is a DAG.

4. _Implement algorithm_: Implement DP(...), e.g. using one of the approaches presented below: top-down, bottom-up approach or shortest-path in DAG.

5. _Solve original problem_: Just call your algorithm with the right arguments. E.g. in the rod cutting problem, with the original rod lenght as in the problem statement.

6. _Reconstructing a solution_: Step 5 only gave a the value of the optimal solution (e.g. in case of the <<knapsack>> problem: the maximal value is 42), but you might also want to know which choices led there (e.g. which items to pack into the knapsack).
+
Variant 1) Each vertex also stores which choice it made.  Analogous to
DP(a,b,c,...), make it accessible e.g. via DPChoice(a,b,c,...).  Starting at
the root vertex, follow the path of those choices.
+
Variant 2) Starting at root of the DAG (e.g. DP(0,X) in the knapsack problem),
for current DP(a,b,c,...), try again, analogous to step 3, all possible paths
and take the one which results in the current DP(a,b,c,...), then recurse to
the choosen subproblem.

Approaches to implement the actual algorithm, see step 4 above:

_top-down approach_: DFS traverse the subproblem DAG from the root via recursion.  At each node, solve a particular problem only once (when it is first encountered) and in this case save its solution in the memo, and when it later is encountered again, look up the solution in the memo.

_bottom-up approach_: Iteratively solve the subproblems, in reverse topological order of the subproblem DAG.  Each iteration blindly uses the memo (knowing the solution must be there due to the topological order) and then memoizes the solution in memo. In general does the same computation as the top-down approach, provided you only solve those subproblems needed to ultimatively solve the orginal problem (e.g. a naive bottom-up approach of solving the _knapsack_ problem solves the whole DAG / matrix which includes nodes not reachable from the root / original problem).  Sometimes the bottom-up approach can save space, because you might know that you only need the last i solutions, e.g. in the fibonacci example you only need the last two. The topological sorted DAG helps to see if that is the case and how big i is.

_shortest path in DAG_: Often (*to-do*: when exactly / when not?) possible: Solve the <<shortest_path_problem>> (which is has a specialiced, more efficient version for DAGs) in the DAG.

Overall running time: +O(#subprobs * time/subprob)+.  Step 1 gives you #subprobs.  Step 3, i.e. the implemenation of DP, gives you time/subprob.  Recall that each subproblem is solved at most once.

Tiny example: An algorithm returning the n-th fibonacci number. For realistic examples, see <<edit_distance>>, <<knapsack>>.

--------------------------------------------------
# bottup-up                          # top down
                                     memo = {}
fun fib(n):                          fun fib(n):
  memo = {}                            if n in memo: return memo[n]
  for k=1 to(incl) n
    if k<=2: f = 1                     <--same
    else: f = memo[k-1]+memo[k-2]      <--" (recursive calls instead lookup)
    memo[k] = f                        <--"
                                       return f
--------------------------------------------------

Trivia: `Dynamic programming' is a wierd term, just take it for what it is. Still: in british english, `programming' means optimize.  The inventor, Bellman, choose it for reasons among `sounds cool to a congress man', `to hide the fact he was doing math research'.

Example algorithms or example problems solvable with dynamic programing: Bellman-Ford, Floyd-Warshall, edit distance, <<knapsack>> (<<rod_cutting_problem>>, change-making problem), <<Dijkstra>>. *to-do* more examples of problems which can be solved using dynamic programming, e.g. from the problems sections. https://en.wikipedia.org/wiki/Dynamic_programming


[[greedy_technique]]
=== Greedy technique / algorithm

A _greedy algorithm_ repeatedly makes locally best choice/decision, ignoring effect on future, with the hope, but not guarantee, of finding an optimal solution to the overall problem.

Problems for which a greedy algorithm works well generally have these two properties:

- _Optimal substructure_: See also <<dynamic_programing>>.  Rational: The choice we just made (an optimal solution to a (mini) sub problem), plus the optimal solution to the subproblem that remains (which we will solve recursively), yields an optimal solution to the original problem.

- _Greedy choice property_: Locally optimal choices lead to globally optimal solutions.

In many problems, a greedy strategy does not in general produce an optimal solution, but nonetheless a greedy heuristic may yield locally optimal solutions that approximate a global optimal solution in a reasonable time.  A greedy algorithm never reconsiders its choices; it makes locally best choices. This is the main difference from dynamic programming, which is exhaustive and is guaranteed to find the solution.

Example algorithms: (Greedy) best-first search, A*, <<Dijkstra>>, fractional knapsack problem, change-making problem for canonical coin system. *to-do*: more examples.


=== Linear programming (LP)

_Integer linear programming_ (ILP) adds the additional constraint that numbers must be integers, making the problem NP-complete.

_standard form_ (aka _general form_, or _primal form_ (see LP duality)): Maximize, by solving for x⃑, a linear objective function x⃑·c⃑, subject to the linear inequalities A·x⃑≤b⃑ and to x⃑≥0. A, c⃑ and b⃑ are constant.

Any linear problem can be converted to the standard form. Original problem wants to minimize: switch signs of c⃑'s coefficients. Original problem has not a non-negative constraint on x~j~: Replace x~j~ by xʹ~j~-xʺ~j~.  Original problem has an equality constraint, say x~1~+x~2~=42: Replace that constraint by two constraints, x~1~+x~2~≤42 and -x~1~-x~2~≤-42.  Original problem has an ≥ constraint, say x~1~≥42 : Replace that constraint by -1 times the original constraint, e.g. -x~1~≤-42.

_certificate of optimality_: *to-do*

_LP duality_: Know the concept, but you probably won't use it often in practice. Every primal form has a _dual form_, where ``everything is inversed'': Minimize, by solving for y⃑, a linear objective function b⃑·y⃑, subject to the linear inequalities Aᵀ·y⃑≥c⃑ and to y⃑≥0.  The primal form and the dual form are equivalent.


References:

- MIT course 6.046J, Design and Analysis of Algorithms (Spring 2015), Lecture 15: "Linear Programming: LP, reductions, Simplex":  https://www.youtube.com/watch?v=WwMz2fJwUCg&t=603s[video], https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-notes/MIT6_046JS15_lec15.pdf[lecture notes]


=== Heuristic method
Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms.

*to-do*

=== Branch and bound

*to-do*


== Augmenting data structures

1. Choose an underlying data structure DS.
2. Determine additional information AI to maintain in DS.
3. Verify that we can maintain AI for the basic operations on DS.
4. Develop new operations.

Let +f+ be an attribute that augments a red-black tree +T+, and suppose that the value +x.f+ for each node +x+ only depends on only the information in the nodes +x+, +x.left+ and +x.right+. Then we can maintain +f+ in all nodes of +T+ during insertion and deletion without affecting the +O(lg n)+ performance of these operations.


[[ADT]]
== Misc. abstract data types (ADT)
An abstract data type is defined only by the operations that may be performed on it and by mathematical pre-conditions and constraints on the effects (and possibly cost) of those operations.  In OO lingo, it is an interface.  See also <<data structures>>,  which in OO are (non-abstract) classes.

=== Summary

*to-do*: finish tables

*to-do*: combine header cells , e.g. queue and stack are specialized deques

linear collections, excluding priority queues
|=====
|               | list | array | deque | queue  | stack
|insert-at(iter)| x    |       |       |        |      
|insert-front   | x    |       | x     | x      | x
|insert-back    | (x)  |       | x     |        |
|find(pos)      |      | x     |       |        |
|find-front     | x    | x     | x     |        | x
|find-back      | (x)  | x     | x     | x      |
|delete-front   | x    |       | x     |        | x
|delete-back    | (x)  |       | x     | x      |
|delete(iter)   | x    |       |       |        |
|successor/pred.| x    | x     |       |        |
|=====

associative collections and ordered by a key, plus priority queues
|=====
|               | priority queue | BST
|insert         | x              | x
|find(key)      |                | x
|find-min       | x              | x
|find-max       |                | x
|delete-min     | x              | x
|delete-max     |                | x
|delete(key)    |                | x
|successor/pred.|                | x
|=====

// associative unordered collections
// |=====         | set | 
// |insert
// |find(value)
// |delete
// |=====

*to-do*: draw is-specialization/generalization DAG plus data structures implementing them


[[collection]]
[[container]]
=== Collection (aka container)
Grouping of data items.  Generally, the data tiems will be of the same type.

Common operations: Create empty container, report number of objects it stores (size), delete all its objects (clear), insert new objects, remove objects, provide access to stored objects.

[[linear_collection]]
.Linear collections
The elements form a sequence. Example ADTs: <<list_adt>>, <<stack>>, <<queue>> (<<priority_queue>> [not associative since only the min element can directly be accessed], <<deque>>, <<depq>>)

[[associative_collection]]
.Associative collections (sorted or unsorted)
Given a key, the collection yiels a value. Example ADTs: <<associative_array>> (<<set>> [value being the key] (<<multiset>>))

.Graphs
Data items have associations with one or data items in the collection.


Notably usually not considered a collection: fixed-sized arrays


[[array_ADT]]
=== Array (ADT)

Random access, fixed size.

Implementation: array data structure


[[list_adt]]
=== List (aka sequence)

Sequencial access (no random access)

Implementations: linked list, doubly linked list, array data structure


[[associative_array]]
=== Associative array (aka map, symbol table, dictionary)
<<collection>> of (key, value) _pairs_ (aka _items_), such that each key appears at most once in the collection.  Specialization of <<multimap>>.

Operations: _insert_ (aka add) a pair, _delete_ (aka remove) a pair, _look-up_ (aka search, find) value associated to a given key.  Optionally also _iterate_ over all pairs, _modify_ (aka reassign), the value of an already existing pair.

Implementations: association list, hash table, binary search tree, radix trees, tries, Judy arrays, ....


[[multimap]]
==== Multimap (aka multihash)
Is a generalization of a <<associative_array>> (aka associative array) in which more than one value may be associated with a given key.  My words: As with <<multiset>>s, this is used in two distinct senses: either equal values are considered identical, and are simply counted, or equal values are considered equivalent, and are stored as distinct items.


[[multiset]]
==== Multiset (aka bag)
A specialization of an <<associative_array>> in that the value part of the associative array's (key, value) pairs is absent or a sentinel value (like 1).

A generalization of a <<set>> in that it allows duplicates.  This is used in two distinct senses: either equal values are considered identical, and are simply counted, or equal values are considered equivalent, and are stored as distinct items.


[[set]]
==== Set
A specialication of a <<multiset>> (which in turn is a specialization of an <<associative_array>>), in that no duplicates are allowed.


[[dequeue]]
=== Double-ended queue (aka dequeue, deque, deck)
<<linear_collection>> where elements can only be inserted to and removed from either side of the sequence.  Is a generalization of a <<queue>> and a <<stack>> in that elements can be inserted and removed to/from both sides.

Implementations: <<circular_buffer>> which resizes when it's full. <<dynamic_array>>, placing the current elements in its middle, and resize when either side becomes full.

Implemented more specialized ADTs: <<collection>>.

Terminology: Deque is the abbrevation of double-ended queue.  Deque (pronounced deck) is the abbbreviation thereof.  Deck is as in an deck of cars, which also provides a good mental image.

See also: - http://www.codeproject.com/Articles/5425/An-In-Depth-Study-of-the-STL-Deque-Container
- C&plus;&plus;'s deque allows random access/insertion, is thus pretty similar to vector. vector vs deque discussions: http://stackoverflow.com/questions/5345152/why-would-i-prefer-using-vector-to-deque, http://www.gotw.ca/gotw/054.htm


[[depq]]
=== Double-ended priority queue (aka depq or double-ended heap)
*to-do*


[[queue]]
=== Queue
<<linear_collection>> where the element removed is prespecified by a first-in-first-out (FIFO) policy.  Is a specialization of a <<dequeue>> in that insertion is only allowed on one side and removal only on the other side.

Common operations: Elememts can only be added to its _tail_ side (_enqueue_), and only be removed from the other side called _head_ (_dequeue_).  The only element that can be accessed is the one on the head side (_front_ or _peek_).

Common implementations offer +O(1)+ time and +O(1)+ auxiliary space for these operation and +O(n)+ space for the collection aspect.

Common implementations: circular buffer, doubly linked list, singly linked list with an additional pointer to the last node

Implemented more general ADTs: <<collection>>, <<deque>>


[[priority_queue]]
=== Priority Queue

A min (max) priority queue is similar to a queue, however dequeue extracts the element with the max (min) key.  I.e. each element has a key.  Principal operations for a max-(min-)priority queue: _insert_ (aka _enqueue_), _dequeue_ (aka _extract-max_(__-min__)), _peek_ (aka _max_(_min_)), _increase-key_(_decrease-key_).

Sorting and priority queues: If it is possible to perform integer sorting in O(n) time per key, then the same time bound applies to the time per insertion or deletion operation in a priority queue data structure (Thorup 2007.  It's however a complicated reduction).

Common implementations: <<heap>>, self-balancing binary tree


[[stack]]
=== Stack
<<linear_collection>> where the element removed is prespecified by a last-in-first-out (LIFO) policy.  Is a specialization of a <<deque>> in that insertion and removal are only allowed on one single side.

Main operations:  Insertion is often called _push_ and can be only to one side called _top_.
Removal is often called _pop_ and can only be the element at the top end.  The only element that can be accessed is the one on the top end of the stack (_top_ or _peek_).

Implementations: <<array>>, <<linked_list>>.


[[graph_adt]]
=== Graph (ADT)
Chapter <<graph_theory>> explains the mathematical theory behind the graph ADT.

Common implementations / representations:

- _Adjacency list_: An ADT having the function Adj(u:vertex), which returns a linked list defining the vertices adjacent to vertex u.  E.g. an associative array (i.e. a collection) of linked lists.  It is left to the more concrete implementation, whether the collection element definitely defines a vertex with all its attributes, or whether the vertex is defined by yet another object and the collection element only defines its adjacent vertices.  Note that in an undirected graph, an edge appears twice.  Typically data structures for the outer collection:

 * A (dynamic) array. Each slot represents a vertex.  Vertices are identified by theyr index in the array.  Only works well with the variant where vertices are separate objects, if these separate vertices objects store their array index as attribute.

 * A hash table, the key being a vertice's hash.  A linked list node can define the adjacent vertex via a pointer, or its hash, or directly the slot index.

 * A function which implicitely defines the adjacent vertices.

- _Objects and pointers_: Can also be seen as a variant of the adjacency list representation.  A collection stores pointers to all vertices.  Each vertex stores its adjacent vertices via a collection of pointers.  Alternatively, each vertex stores a collection of outgoing edges.  An outgoing edge stores a pointer to the source and to the destination vertex, and possibly other edge attributes such as weight.  The other graph representations have the advantage, that with them you can have multiple graphs using the same vertex objects.

- _Edge list_: A collection of edge objects, each edge object storing something to identify the start and end vertex, possibly additionally also the edge's weight.

- _Adjacency matrix_ |V|×|V|:  Rows represent source vertices and columns represent destination vertices and cells the associated edge.  Data on vertices typically stored externally.  Typically for dense graphs, or when a quick way is needed to tell if two vertices are adjacent.  Does not work for multigraphs. *to-do* symetric for undirected graphs, inf for not adjacent vertexes, edge weights...

- _Incidence matrix_ |V|×|E|: The rows represent the columns, the columns the edges, a cell is 1 if the associated vertex is an start point of the assiciated edge, -1 if it's the end point, and 0 otherwise.  In a weighted graph, the 1s are replaced by the edge's weight.

The time complexities for adjacency list assume that Adj(u:vertex) takes O(1) time. a is the number of incident edges to the vertex in question.

|======
|                           | adjacency list         | adjacency matrix  | incidence matrix
|Space requirements         | O(V+E) ☺ if sparse     | O(V²)             | O(VE)
|Add vertex                 | O(1) ☺                | O(V²)             | O(VE)
|Remove vertex and its edges| ✝                     | O(V²)             | O(VE)
|Add edge                   | O(1)                   | O(1)              | O(VE)
|Remove edge                | O(V+E) / digraph O(a)  | O(1)              | O(VE)
|Are two vertices adjacent? | O(a)                   | O(1) ☺            | O(E)
|Get adjacent vertices      | O(a) ☺                | O(V)              | O(E)
|======

✝) To remove vertex itself from outer collection: O(V) for array, O(1) for hash table. To remove incident edges of vertex u: For directed graph O(a), for undirected graph O(V+E) (for each vertex v in Adj(u), remove u from in Adj(v)).

References:

- Book "Introduction to algorithms", chapter "Representations of graphs"

- https://www.ics.uci.edu/~eppstein/161/960201.html

- https://en.wikipedia.org/wiki/Graph_(abstract_data_type)#Representations

- MIT course 6.006 Introduction to Algorithms, lecture 13. Breadth-First Search (BFS), https://www.youtube.com/watch?v=s-CYnVz-uh4&index=13&list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&t=0s, starting 20:23


[[binary_search_tree]]
=== Search Tree and Binary Search Tree (BST) (ADT)

A _search tree_ is a specialized tree used store a set of compareable keys or key-value pairs. Often used to implement the more general <<associative_array>> ADT.

A _binary search tree_ (_BST_) is a specialized search tree based on a binary tree and where each node satisfies the _binary-search-tree property_: Each node has a comparable key, and the key of the left child, if child present, is smaller than the node's key, and the key of the right child, if child present, is larger than the node's key.  Be n the number of stored elements.  The height h of the tree is h >= log n.  The expected height is h = log n for a randomly built binary tree.

Some implementations store data only in the leaves.  Each non-leaf node stores the min and max of the leaves in its subtrees; alternatively, we can store the max value in the left subtree if we want to store just one value per node.  An advantage is that keys are closer together, i.e. there are less page misses.  An advantage of storing values also in internal nodes is that often accessed keys are found in less hops.

On _duplicates_: 1) disallow them 2) Adapt the binary search tree property such that either the left or the right subtree includes equal keys. 3) Each node can store a collection of elements with that key, or store the number of times the key occures.

_search_ key k: Say x is the current node. If x.key = k then the node is found and returned, else if k < x.key then continue with left subtree, else with right subtree.  Stop when reaching a null pointer and return null. O(h) time.

_insert_: Assumes key does not already exist.  Use the search algorithm to arrive at a null child ptr, replace that with a ptr to the new element.  If the tree was empty before, make the new element the root. O(h) time.

_delete_: *to-do*

_min_/_max_: Follow left/right subtree until the leaf is reached. O(1) time.

_successor_: The successor is the next node in inorder traversl.  Thus if there's a right child, return min of the right subtree.  Otherwise, travel up the tree following the parent pointers until coming up from a left child. O(h) time.

_predecessor_: Symmetric to Successor.

[[rotation]]_left/right rotation_: Swaps the heights of the subtrees while preserving the order of elements of an in-order traversal.  Note that thus, in case of an BST, also the binary-search-tree property is preserved.  O(1) time.  The following visualizes left/rifght rotation. x/y are nodes, A/B/C are subtrees.

----------------------------------------------------------------------
   x      left       y
A     y     →     x    C
     B C    ←    A B
          right    
----------------------------------------------------------------------

Implementations of binary search trees: <<avl_tree>>, <<red_black_tree>>

Implementations of search trees in general: <<2_3_tree>>, <<2_3_4_tree>>, <<b_tree>>

Implements these more general ADTs: <<associative_array>>


[[disjoint_set]]
=== Disjoint-set (aka union-find, merge-find set)
A collection of n elements, partitioned into a number of disjoint sets. Or from another point of view: Given an undireced graph of n vertices, keeps track of connected components, and thus can answer which vertices are connected.

Usually each set chooses one of its elements as the representative; that representative element identifies the set. It is undefined which element is chosen, but it stays the same as long as the data structure is not modified.

Main operations:

- make-set(v): Adds element / vertex v to the collection, as a new set containing only that element.
- find-set(v): Returns the id of the set / connected-component element / vertex v is in. To see if elements / vertices u and v are in same set / connected: find-set(u)==find-set(v).
- merge-sets(u,v): Merges the sets of elements u and v / adds edge between vertex u and vertex v. It is undefined what the id of the new set is.

Implementations: <<disjoint_set_linked_list>>, <<disjoint_set_forest>>

|============
|                  | optimized disjoint set linked list | naive disjoint set forest | optimized disjoint set forest
| make-set(v)      | O(1)           | O(1)                      | O(1)
| find-set(v)      | O(1)           | O(n)                      | O(α(n))
| merge-sets(u,v)  | O(n) *          | O(n)                      | O(α(n))
|============

*) However, a sequence of m make-set / find-set / merge-set operations, n of which are make-set, take O(m + n log n) time.  Thus when m ≫ n, informally the running time of merge-set tends towards O(1).

Applications:

- <<kruskals_algorithm>>

- <<cycle_detection>>

- <<finding_connected_components>>

References:

- Book "Introduction to algorithms", chapter "21.1 Disjoint-set operations"


[[data_structures]]
== Misc. Data structures
A concrete particular way of organizing data in memory.  In OO lingo, its is a (non-abstract) class.  See also <<ADT>>, which is in OO lingo an interface.


[[data_structure_comparison]]
=== Data structures comparison

*to-do*: Intro about why certain applications care about worst-case performance, and compared to an alternative, rather have a worse average case than a much worse worst-case.  E.g. to counter DoS attacks, realtime systems.

Key properties of general data structures:

|=====
|                        | Pros                             | Cons
| Array in general       | Cache hierarchy friendly, simple | O(n) insertion/deletion
| Hash table             | O(1) average                     | O(n) worst case, no ordering
| Balanced search tree   | Balanced properties              |
|=====

Key properties of more specialized data structures, in addition to the key properties above:

|=====
|                        | Pros                                     | Cons
| Sorted array           | O(1) order stastics                      | 
| B-tree                 | Optimized for secondary memory           |
| Skip list              | Simple, especially regarding concurrency | O(n) worst case
|=====

.Array in general

Even though asymptotically requiring O(n) space as most others, no space is wasted at all for a fixed sized array, since no house keeping data like pointers are needed.  A dynamic array usually has some consecutive unused slots at the end, which doesn't affect cache hierarchies.  An array is highly CPU cache friendly, thus the hidden constant factors are typically very small.  Thus in practice, for many applications an array is a better choice than a more `advanced' data structure, especially when considering sorted arrays.

.Hash table

Hash tables are great on average having O(1) running time, however their worst-case of O(n) is worse than the O(log n) worst-case of most search tree based data structures.  In certain cases you can have perfect hashing, in which case the worst-case is O(1).  Also, opposed to search trees, a hash table has no notion of ordering.


.AVL tree and red-black-tree

Theoretically equivalent since time and space complexity are identical.  AVL trees are more rigidly balanced (≈ 1.44 lg(|V|)) than red-black trees (≈ 2 lg(|V|)), whereas the number of rotations when inserting or deleting is O(lg n) for AVL and O(1) for red-black.  Followingly prefer AVL when number of lookup operations dominate sum of insert/delete operations, and red-black otherwise.

.B-tree

Has the same asymptotic complexities as AVL tree and red-black tree, but is optimized for large data structures not fitting into main memory and residing mostly in secondary memory.


.Skip List

Is just are another variant of a binary search tree. Is easier to implement than a AVL tree or red-black tree, especially when considering the respective concurrent data structure variants.  However a skip list has a worst-case running time of O(n), opposed to the O(log n) of most BBSTs, however with low probability.  Also the space complexity is O(n log n) in the worst-case, opposed to O(n) worst-case of most other data structures. Concurrent variants of AVL trees or red-black trees often trade concurrency for balancedness, so their worst case guarantees drops, which was one of their main benefits over skip lists.  Skip lists have more pointers per key, thus are less chache friendly.

*to-do*: data strucures optimized for secondary memory, e.g. B-trees.

*to-do*: cache-oblivious data structures

*to-do*: concurrent data structures.  Most AVL tree and red-black tree implementations implement insert and delete in a locking fashion.  Note that these operations in the worst case affect large portions of the tree.  Only recently lock free variants emerged: http://www.cs.umanitoba.ca/~hacamero/Research/RBTreesKim.pdf.  Typically concurrent balanced search trees trade better concurrency for worse guaranteed balancedness.

*to-do*: specialed for integers (e.g van Emde Boas trees), specialized for strings (e.g. all the trie based data structures).

References:

- <<big_oh_cheat_sheets>>

- https://stackoverflow.com/questions/256511/skip-list-vs-binary-tree

- https://www.quora.com/Why-arent-skip-lists-used-more-often-instead-of-balanced-trees

- https://people.cs.clemson.edu/~bcdean/skip_bst.pdf[Exploring the Duality Between Skip Lists and
Binary Search Trees]

- https://en.wikipedia.org/wiki/Search_data_structure#Asymptotic_amortized_worst-case_analysis


[[succinct_data_structures]]
=== Succinct data structures

This subchapter is about what succinct data structures are.  Actual succinct data structures are described in other chapters throughout this document.

The term ``succinct data structures'' sadly is ambigous.  On one hand it is used as an umbrella term for space-efficient data structures close to the information-theoretic optimum, which still support fast query operations, i.e. without first decompressing everything.  On the other hand it designates a specific class of space-efficient data structures.  The following is a classification of data structures according to their space usage in bits, not words, where OPT is the information-theoretic optimum:

_implicit_: OPT + O(1).  The ideal is ⌈OPT⌉, so the intend of O(1) is more that the OPT may be a fractional and we need to round up the next integer, rather than using O(1) bits for auxillary information.  Usually very hard, thus usually not achieved.  Examples: array, heap.

_succinct_: OPT + o(OPT).  In other words, less than twice the OPT.  Most common type of space-efficient data structures.

_compact_: O(OPT).  When a space-efficient data structure is the goal, being compact is often not good enough and just an intermediate step towards becoming succint.

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 17. Succinct Structures I: https://www.youtube.com/watch?v=3Y2weLDiUWw&t=3901s[video], https://courses.csail.mit.edu/6.851/spring14/scribe/L17.pdf[lecture notes]


[[array]]
=== Array data structure (aka table)
Fixed size, +Θ(1)+ time for indexing, with a very low constant factor.  ++O(0)++ wasted space.  Due to the fixed size, elements cannot be added / removed.


[[dynamic_array]]
=== Dynamic array (aka array list, dynamic table, resizeable array)
In contrast to <<array>> the size is variable, thus allows elements to be added / removed.  _Capacity_ is the number of elements the container could currently hold, and the _size_ is the number of elements it actually currently contains.


[[table_doubling]]
==== Table doubling

When size equals capacity upon an insertion, create a new table with double the capacity and copy all elements over.  Thus insertions are +Θ(1)+ amortized.  Upon deletions, when you don't mind slack, never resize the table (as the STL does), or half the capacity when size drops below capacity/4. In that case both insertions and deletions are +Θ(1)+ amortized. (You can't half the capacity when the size reaches half the capacity because in a sequence like inserting/deleting/inserting/deleting, each operation could encompass a table resize which would mean +O(n)+ per operation.)  Of course, other constants than 2 can be used, as long as the factor which is to do shrink is greater than the factor to enlarge.

One can get +Θ(1)+ by roughly this idea: When you remark that you start to get full, start a new table with a larger capacity, initially empty.  On each insertions operation, copy a constant amount of items from the old table to the new one.  Once the old table is really full, just switch over to the new table.  All in all it's quite complicated, so it's not that often used.

Applications: Used in <<hash_table>> to keep load factor small enough.


=== Sorted array

Based on an array, and additionally maintain the invariant the the elements are sorted. <<search_in_sorted_array>> presents algorithms which find an element in an sorted array.


[[linked_list]]
=== Linked list

Implementation of the ADT <<list>>.

Orthogonal properties:

- Singly, Doubly or Multiply linked
- Circular linked yes/no
- Sentinel nodes yes/no


[[circular_buffer]]
=== Circular buffer (aka cyclic buffer, ring buffer, circular queue)
Uses a single, fixed-size buffer as if it were connected end-to-end.

Internally uses 1) an array which's size equals circular's buffer capacity, 2) an pointer (or index) to the first element and 3) one to the last element.  Pointers in a circular buffer wrap around at the underlying array border (array.first and array.last (according array.size=circular_buffer.capacity)).

Implements the ADT <<queue>>

Difficulties:

- Depending on the exact implementation, distinguish the case that the buffer is empty and that it is full is not possible, because in both cases start and end point to the same element.


[[direct_address_table]]
=== Direct-address table

Implements the <<associative_array>> ADT.  An array of size |U|, where U is the universe of keys, i.e. the set of possible keys.  A key's value is the index into the array where the data corresponding to the key is stored.  In other words, it's a special case of a hash table.  As with any hash table variant, each slot needs to store wheter it's occupied, e.g. by setting its key to NIL or by having a flag.

Obviously direct-address tables only make sense when |U| is small enough. If it's not, we might not even have enough memory available.  Also the number of actually stored keys |K| should not be significantely smaller than |U|, otherwise we waste too much sapce.

Time: +O(1)+ worst average best case.  Space: +O(|U|)+.


[[hash_table]]
=== Hash table

Implements the <<associative_array>> ADT.  Is an array of size m.  As usual, the number of elements stored is denoted n.  Is based on an array, called the _hash table_, of size m.  A <<hash_function>> h(k,m) is used to map a key k to [0,m), i.e. to an index into the hash table.  We say that a key k _hashes_ to slot h(k,m).  We also say that h(k, m) is the _hash value_ of key k.  When two keys hash to the same slot that is called a _collision_. The following subchapters describe ways how to deal with collisions.  α = n / m is the _load factor_ of the table.  The set of possible keys is called the _universe_ and denoted U.  The set of actually stored keys is denoted K. |K| = n.

In general, the various hash table variants have the following properties: Search/insert/delete time in O(k) for the best and average case, and O(k+n) worst case, where k is the key length. Space is usually O(n).

See <<table_doubling>> on how to grow / shrink the table in order to keep the load factor small. More concretely, we want loadfactor=Θ(1) or equivalently m=Θ(n), or else we no longer have O(1) for insertion / search / delete.  `Copying' from the old table to the newly allocate table obviously includes rehashing every key, since the hash function is dependend on the table size m.  Despite table doubling, insertions / deletions still have O(1) time complexity, but now its amortized time.

Applications:

- databases (which typically either use hash tables or search trees)

- compilers & interpeters

- network router

References:

- MIT Course 6.006 Introduction to Algorithms, Lectures 8-10: https://www.youtube.com/playlist?list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb

- MIT course 6.851 Advanced Data Structures, lecture 10 Dictionaries: https://www.youtube.com/watch?v=Mf9Nn9PbGsE&index=10&t=0s&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf[video], https://courses.csail.mit.edu/6.851/spring12/scribe/lec10.pdf[lecture notes]. !! But definitions seem to be inexact since they don't clearly state when something must be chosen random and when something can be freely choosen !!

- Hacettepe University course BBN 402 Theory of Computation, Lecture 12 Hash Tables: https://web.cs.hacettepe.edu.tr/~ozkahya/classes/bbm402/Reading/Hashing.pdf. !! But Uniform hashing is defined differently than elsewhere !!

- Book "Introduction to algorithms", chapter "Hash functions"

- Book "Design and Analysis of Randomized Algorithms", chapters "3.2 Hashing" and "3.3. Universal Hashing"


[[direct_addressing]]
==== Collision resolution with direct addressing

Make collisions impossible by making the `hash table' large enough for the whole universe of keys.  The key then directly is the index into the array.  See <<direct_address_table>>.


==== Collision resolution with (separate) chaining

Each table slot has associated a sequence of items, typically a singly linked list. The expected chain length is the table's load factor.

Insert/delete/find: Θ(1) average and Θ(n) worst-case, assuming simple uniform hashing, and O(1) to compute the hash, i.e. ignoring prehashing.  Actually the average case is Θ(1+loadfactor), but when the loadfactor is O(1), i.e. m = Ω(n), it becomes Θ(1).  Rational: Paying O(1) to find table slot, then O(loadfactor) to walk the list.

Loadfactor should be Θ(1), i.e. m should be Θ(n).  If m is too small, the loadfactor is too high, in the worst case not Θ(1) anymore.  That would lead to hash table operations not being Θ(1) anymore.  On the other side if m is too large, we waste space.


==== Collision resolution with open addressing

Each slot can really only take one key, and has an attribute whether it's free. If a hash function maps a given key to an non-free slot, a probe sequence is used iteratively to ultimatively find a free slot. Typically delition and table resize are possible but complicated.  Unlike with chaining, if all slots are used, the table must be enlarged, see also <<table_doubling>>.  Since at most one element occupies one slot, obviously the load factor is one or less.

A _probe sequence_ is a permutation of all possible slots.  Obviously there are m! different probe sequences.  The hash function is generalized to take a further parameter: h(k,m,i) is the same as h(k,m), with the aditional parameter i, denothing the i-th probe. If h(k,m,0) returns a used slot, you try h(k,m,1) and so on.  An ideal such hash function is a <<strong_uniform_hash_function>> (as opposed to a <<simple_uniform_hash_function>>).  The definitions below make use of an _auxiliary hash function_ hʹ which is some `normal' hash function producing a single hash value.  _Primary clustering_ means that if there is a cluster of occupied slots and the initial position of a probe falls anywhere in the cluster, then the cluster size increases.  _Secondary clustiring_ is less severe, two probe sequences only have the same collision chain if their initial position is the same.

We use probing to find a free slot instead linked lists which use only slots of the table as list elements in order to avoid pointers.  The extra memory freed by not storing pointers gives us more slots for the same amount of memory, thus a smaller load factor, thus fewer collisions, thus faster retrieval.

Linear probing:: ++h(k,m,i) = (hʹ(k,m)+i) mod m++. Good locality, but most sensitive to primary clustering.

Quadratic probing:: Try m1=m0+1, m2=m1+2=m0+3, m3=m2+3=m0+6. Properties between linear probing and double hashing. Suffers from secondary clustering.

Double hashing:: ++h(k,m,i) = (hʹ(k,m)+i*h2ʹ(k,m)) mod m++. Interval is computed by another hashfuncion. Bad locality, but exhibits virtualy no clustering. m is typically a power of two. If m is even, h2 should deliver an odd number, else every 2nd slot will never be probed.  Double hashing approximates uniform hashing and is thus one of the best methods available for open addressing.

Analysis: Assumes uniform hashing, as opposed to just simple uniform hashing. However none of the presented schemes actually fulfills the assumption of uniform hashing, because none of them is capable of generating more than m² different probe sequences, instead of the m! required.


[[collision_resolution_with_perfect_hashing]]
==== Collision resolution by using a perfect hash function

Make collisions impossible by using a perfect hash function.

The concrete variation described here is also called _FKS hashing_ after Fredman, Komlos and Szemeredi.  The way it is described here and probably done in practice is that the hash table data structure as a whole and the perfect hash function as a whole are intertwined.  We use two levels of hash tables.  The first level is a hash table of size m=n using a hash function randomly chosen from a universal class of hash functions.  This will map n~j~ keys to the j-th slot.  Each slot is then a hash table of size m~j~ = n~j~², constituting the second level.  Recall that the set of actual keys K is static and known.  For each secondary hash table, we try at random a hash function from a universal class of hash functions until we find one which doesn't produce any collision in that secondary hash table.  It can be prooven that given this setup, only a few tries are required.  It can also be proven that the overall space requirement is O(n).

Applications: Efficient lookup (O(1) worst-case) for a set of keys which is known in advance.

*to-do* The above describes a static data structure. You can make it dynamic, when you rebuild the second level hashtable when an insert does create a collision in that second level hash table.


[[cockoo_hashing]]
==== Collision resolution with cuckoo hashing

We maintain two hash tables, each having m slots.  We choose two hash functions h1 and h2 from a universal familiy of hash functions.  Any key k will be either at h1(k) in table one, or h2(k) in table two.  To insert a key, if slot h1(k) in table one is free, place it there.  Otherwise, replace the old key with the new key.  Now we have that old key in our hand, and the process repeats, now trying to insert that old key into table two.  We bounce between the two tables until all elements stabilize, or until we run into a cycle.  In the later case, we rehash by choosing a new h1 and h2.  Multiple rehashes might be required.

Analysis: Lookup and deletions in O(1) worst case. Insertions are O(1) amortized.


=== Association list
Is an implementation of the ADT <<associative_array>>.

*to-do*


[[naive_BST]]
=== Binary search tree (data structure)

A data structure implementing the binary search tree ADT. When inserting, the elements are always inserted as leaves, whithout changing previous nodes.

*to-do*


[[random_binary_tree]]
=== Randomized binary search tree

Randomly permute the input before building the <<naive_BST>>.

*to-do*

Expected height E[height]=O(lg(n))


=== Treap

A randomized binary search tree.  At the same time a Cartesian tree in which each key is given a randomly chosen numeric priority, the heap property applies to the priority.

*to-do*

Etymology: A portmanteau of tree and heap.


[[avl_tree]]
=== AVL Tree

A data structure implementing the binary search tree ADT.  Is a balanced binary search tree; balance is ensured by the following invariant: For each node n: |height(n.left) - heigh(n.right)| ≤ 1.  From that (indirectly) follows: tree height ≈ 1.44 lg(|V|).

Time complexity: O(log n) average and worst case for all basic operations (search, insert, delete).

Space complexity: O(n)

Each node stores its _balance factor_, which is the difference in height of the left and right subree. Must be in range [-1,1].

Rough description of how insertion/deletion work:

1. First do a normal BST insertion or deletetion (which honor the BST property)

2. For each node on the path from the newly inserted node up to the root: if balance factor is not in range [-1,1], fix it by only _rotation_ operations.

See also <<data_structure_comparison>>.

Etymology: Named after its two inventors Adelson-Velsky and Landis.


[[red_black_tree]]
=== Red-Black tree

A data structure implementing the binary search tree ADT.  Is a balanced binary search tree; Balance is preserved by attributing each node with one of two colors (typically called `red' and `black') in a way that satisfies red-black properties (see below).  Tree height ≈ 2*lg(|V|).

red-black properties:

- Roots and NILs are black (typically NILs are called the leaves and all other `poper' nodes are called internal nodes).

- Every red node has a black parent (i.e. never two consequtive red nodes on a simple path)

- For each descendant of a node n, the number of black nodes on the simple path from n to descendant is the same

Time and space complexity: same as <<AVL>> tree.

See also <<data_structure_comparison>>.

References:

- MIT 6.046J, Lecture 10 Red-black Trees, Rotations, Insertions, Deletions: https://www.youtube.com/watch?v=O3hI9FdxFOM&t=158s


=== Weight-balanced tree (WBT)

The size difference between the left and the right subtree is kept within some constant factor.

*to-do*


[[b_tree]]
=== B-tree

B-trees are balanced search trees designed to work well on secondary storage devices such as disks.  B-trees are similiar to red-black trees, but thet are better at minimizing disk I/O operations.  In a typical B-tree application the amount of data fits not into main memory and thus most data must reside on disk.  B-trees generalize binary search trees in a natural manner.  Each node can have many children, not just two.  The number of childrens is called the branching factor.

In our model, when accessing an object pointed to by pointer x, we first have to read it from disk into a page in main memory.  When the object is modified, we need to write it back.  We don't care about pages no longer in use by leaving that to the system.  We want to minimize the disk read / write operations.  We often see branching factors between 50 and 2000.

Etymology: What the B stands for is not clearly known.  One of the co-inventors hinted that Rudolf Bayer was the senior in the team, and that they worked for Boeing.

References:

- MIT Course 6.046J Design and Analysis of Algorithms, Spring 2015, Recitation 2 2-3 Trees and B-Trees: https://www.youtube.com/watch?v=TOb1tuEZ2X4&list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&index=5

- Book ``Introduction to algorithms'', chapter ``B-Trees''.


[[2_3_tree]]
==== 2-3 tree

A <<b_tree>> of order three.  Each internal node has one key and two children or two keys and three children.

References:

- MIT Course 6.046J Design and Analysis of Algorithms, Spring 2015, Recitation 2 2-3 Trees and B-Trees: https://www.youtube.com/watch?v=TOb1tuEZ2X4&list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&index=5


[[2_3_4_tree]]
==== 2-3-4 tree

A <<b_tree>> of order four.


==== B+ tree

A variant of a B tree which stores all values in the leave nodes, never in internal nodes.  See data_base_systems.txt


[[vEB_tree]]
=== Van Emde Boas tree (aka vEB tree)

Is a tree data structure implementing the ordered <<associative_array>> ADT with m-bit integer keys. It performs all operations in O(lg m) time. The vEB tree has good space efficiency when it contains a large number of elements

References:

- MIT Course 6.046J Design and Analysis of Algorithms, Spring 2015, Lecture 4 Divide & Conquer: van Emde Boas Trees: https://www.youtube.com/watch?v=hmReJCupbNU&list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&index=6


[[cartesian_tree]]
=== Cartesian tree

A binary tree T having the min heap property and having the additional porperty that its in-order traversal delivers a given array A.  In other words, each node has the min heap property and the property that it corresponds to the element A[i], its left subtree is a cartesian tree of A[<i], and its right subtree is a cartesion tree of A[>i].

Example:
--------------------------------------------------
A = [8,7,2,8,6,9,4,5]

T =      2
        / \______
       7         4
      /       __/ \
     8       6     5
            / \
           8   9
--------------------------------------------------

If there are multiple equal elements in A, break ties arbitrarily, i.e. pick any one of the equal elements as the parent of the other.

Applications:

- <<RMQ>> in A corresponds to <<LCA_problem,LCA>> in T.

- <<orthogonal_range_search>>

- A <<treap>> is a specialization of a cartesian tree

References:

- https://www.geeksforgeeks.org/cartesian-tree/

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees: https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video]


[[RMQ_LCA_equivalence]]
==== RMQ LCA equivalence

Given a cartesian tree T, a RMQ in A is equivalent to an LCA in T. Only that in RMQ we're talking about array elements identified by their index, and in LCA about tree nodes identified by themselves.

[[reduce_RMQ_to_LCA]]
_Reduce RMQ to LCA_: Building a cartesian tree T from an array A in O(n), i.e. reduce RMQ to LCA:  This assumes each node has a parent pointer.  Process the array from left to right, inserting the array element in the cartesian tree at the appropriate position.  To insert the next array element into T, start at the node just inserted before. Visualizing that in the standard way of drawing a cartesian tree, that node will be the rightmost node, since it corresponds to the last element of A inserted into the tree so far. Follow parent pointers until encountering a node v which is smaller.  Note that we will always take edges going to the left.  Then insert the new node by breaking up the edge (v, v.right), and by making v.right the left child of the new node.  Note the edge case of the new element being smaller than the root; it may help to have a sentinel node with value −∞ pointing to the tree's actual root.

[[reduce_LCA_to_RMQ]]
_Reduce LCA to RMQ_: Building an array A from a cartesian tree T in O(n).  Do an in-order traversal.  If T's nodes are not already labeled with values as above, which is the case in many applications, label each node with it's depth; with that labeling RMQ on A will be equivalent to LCA on T.

[[reduce_LCA_to_pm1_RMQ]]
_Reduce LCA to ±1 RMQ_: Perform an Eulerian tour based on the in-order traversal and append every encountered node to A. At each step we either go up or down one level, thus consequtive elements in A differ by exactly either +1 or -1.  Every edge is visited twice, so the resulting array contains a given node up to three times, but that's still O(n).


[[treap]]
=== Treap (aka priority search tree)

A _treap_ is a <<cartesian_tree>> in which each key is given a (randomly chosen) numeric priority.  In other words, it's a balanced (with high probability) binary search tree. The idea is to use randomization and the heap property to maintain balance with heigh probability, i.e. balancedness is not guaranteed. Search, insert, delete in O(log n) time with high probability, but O(n) worst case.

Each node in the this BST additionally has a priority, which is assigned a random value upon insertion. Upon insertion/deletion, both the BST invariant regarding the key and the heap property regarding the priority have to be fullfulled. This is done by a normal BST insert using the key, and then do rotations until the heap property is fullfulled regarding the priorities.

Trivia: The name is a portmenteau of tree and heap.


[[skip_list]]
=== Skip list (aka jump list)

Is a randomized data structure implementing the ordered <<associative_array>> ADT based on a hierarchy of ordered linked lists. Search, insert, delete take O(lg n) time with high probability.  It consists of layered ordered linked lists.  The bottom linked list contains all keys.  The 2nd acts as an express lane, having about half as many nodes, each node being linked to the respective node in the layer below.  The further layers are built analogously.  Having a −∞ sentinel key makes the implementation easier.

--------------------------------------------------
−∞------------------------------79
|                               |
−∞--------------50--------------79
|               |               |
−∞------34------50------66------79------88
|       |       |       |       |       |
−∞--23--34--42--50--59--66--72--79--82--88--95
--------------------------------------------------

_search_: Start at the highest linked list.  When being at any node, when the search key equals the node's key, go straight down to the respective node in the bottom most linked list.  If the search key is less then the next node in the current linked list, go one node down, else go the next node in current linked list.

_insert_: Use search to find the correct place in the bottom most linked list to insert.  After insertion, we must decide how high we want to make the node's `tower', i.e. in how many of the upper linked lists we also want to introduce a respective node.  Flip a coin, until tail appears; for each head appearing in the process, make the tower one node higher.  As a consequence, each layer has about half as many elements as its adjacent lower layer.

Note that space complexity is O(n log n) in the worst case, opposed to O(n) worst case for most other data structres.

The randomization is independent of the keys, thus an adversary cannot directly provok worst-case behavior via the set of input keys.

Essentially a skip list is just a variant of a binary search tree:  https://people.cs.clemson.edu/~bcdean/skip_bst.pdf[Exploring the Duality Between Skip Lists and
Binary Search Trees].

See also <<data_structure_comparison>>.

References:

- https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/skiplists.pdf

- MIT 6.046J Design and Analysis of Algorithms, Spring 2015, Lecture 7 Randomization: Skip Lists: https://www.youtube.com/watch?v=2g9OSRKJuzM&list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&index=10&t=0s[video], https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-notes/MIT6_046JS15_lec07.pdf[lecture notes]

- http://cglab.ca/~morin/teaching/5408/refs/p90b.pdf


[[kd_tree]]
=== k-d tree

Assumptions for simplicity: No two points have same x coordinate, and no two points have same y coordinate.

A _k-dimensional k-d tree_ is a non-balanced binary search tree storing k-dimensional points.  They are often used for k-dimensional <<orthogonal_range_search>>.  Informal description for the 2D case: Each subtree represents an rectangular area,  possibly unbounded, i.e. rectangle edges can be at infinity.  The root represents the whole plane.  As normal in BSTs, each node stores a value, here a point.  Each node splits its associated area in two halfes by an imaginary line through its point.  Nodes at even tree levels split vertically, nodes at odd tree levels horizontally.  Each of its subtrees is then associated with one of the halfes.  Thus the plane is recursively diveded into smaller and smaller rectangles.

Algorithm to build tree:  Partion the of set points in x-direction in two equal halfes by finding the median point in x direction, see <<order_statistics>>.  That point becomes the root.  For each of the two partitions recurse.  Only that now, on depth 1 of the recursion, we partition in y-direction.  In general, in a k-dimensianal tree, we partition after the (depth%k+1)-th dimension.

--------------------------------------------------
build-2dimensional-kd-tree(points, depth): node
  if points.size=1: return new leaf node having value points[0]
  if depth is even: splitdirection = in x
  else            : splitdirection = in y
  find median of points in splitdirection -> median, smallerpoints, greaterpoints
  node = new node
  node.value = median
  node.right = build-2dimensional-kd-tree(smallerpoints, depth+1)
  node.left = build-2dimensional-kd-tree(greaterpoints, depth+1)
  return node
--------------------------------------------------

Optimisation:  For each dimension, have a presorted sequence of all points.  The recursively called core function gets the current sequence of points for each dimenssion.  Partitioning is now trivially possible in O(kn).

Applications:

- <<orthogonal_range_search>>

References:

- http://www.cs.utah.edu/~lifeifei/cs6931/kdtree.pdf

- https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/kdtrees.pdf

- Book "Computational Geometry - Algorithms and Applications", subchapter "kd-trees"

- https://www.youtube.com/watch?v=W94M9D_yXKk&index=3&list=PLe-ggMe31CTdBsRIw0hXln0hilRs-DqAx


[[range_tree]]
=== Range tree

*to-do*.

Applications:

- <<orthogonal_range_search>>

References:

- https://courses.csail.mit.edu/6.851/spring12/scribe/lec3.pdf

- https://www.youtube.com/watch?v=xVka6z1hu-I, 59:08

- Book "Computational Geometry - Algorithms and Applications", subchapter "Range Trees"


[[interval_tree]]
=== Interval tree / interval search tree

Augments a binary search tree to store a set of intervals.  In case a BBST is augmented, each operation can be done in O(log n) time.

The value stored in each node is a pair representing the interval [low, high] and max, which is the maximum high value stored in this subtree.  The low value of the pair is used as key to maintain order in the BST.

insertion(low, high): First do a regular insertion.  Recall, low is key.  After insertion, for all nodes on the way from the new node to the root, update max.

search(low, high):  Searches any one interval in the tree that intersects the given interval. If interval in node intersects given interval, return node.  Else if there's no left subtree or max endpoint in root of left subtree is less than low, descend right.  Else descend left.


Applications: <<rectangle_intersection>>

References:

- https://www.youtube.com/watch?v=E-9b8k7JK6I&index=4&list=PLe-ggMe31CTdBsRIw0hXln0hilRs-DqAx

- https://www.geeksforgeeks.org/interval-tree/


=== Splay tree

A balanced binary search tree with the additional property that recently accessed elements are quick to access again.

*to-do*


=== Scapegoat tree

A self-balancing binary search tree.  Instead of the small incremental rebalancing operations used by most balanced tree algorithms, scapegoat trees rarely but expensively choose a "scapegoat" and completely rebuild the subtree rooted at the scapegoat into a complete binary tree. Thus insert and delete have O(n) worst-case and O(log n) amortized on average.

*to-do*


[[sbt_level_order]]
=== Succinct binary tree, level order representation

All nodes of the tree (inclusive leaves), are called internal nodes, and the `missing leaves', or in other words the null-pointer childs, are called external nodes.  Traverse this extended tree in level order, writing down a 1 for an internal node and a 0 for an external node, resulting in a bit vector which is a definition of the tree.

Queries are based on rank and select provided by some <<bit_vector>> implementation:

left-child(i): 2·rank(i). O(1) time.

right-child(i): 2·rank(i) + 1. O(1) time.

parent(i): select(⌊i/2⌋). O(1) time.

Analysis: Uses 2n bits space, which is approximately optimal.  The Catalan number tells us how many different binary trees with n nodes there are.  It can be approximated by 4^n^.  log~2~(4^n^) = 2n.

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 17. Succinct Structures I: https://www.youtube.com/watch?v=3Y2weLDiUWw&t=3901s[video], https://courses.csail.mit.edu/6.851/spring14/scribe/L17.pdf[lecture notes]


=== Succinct binary tree, balanced parentheses representation

There's a bijection binary tree ⇔ balanced parentheses. Balanced parentheses have a natural encoding: 1 for an open parentheses, 0 for a closed one.

In contrast to the level order representation, now we can also answer subtree size queries.

*to-do*

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 17. Succinct Structures I: https://www.youtube.com/watch?v=3Y2weLDiUWw&t=3901s[video], https://courses.csail.mit.edu/6.851/spring14/scribe/L17.pdf[lecture notes]


[[bit_vector]]
=== Bit vector

Often used for <<succinct_data_structures>>.

Solutions:

- Brute force / trivial: Many succinct applications of bit vectors depend on fast rank and select, thus the trivial implementation is often not feasible.

- Auxillary data structure for rank query in O(1)

- Auxillary data structure for select query in O(1)

- <<rrr>>: fast queries and implicit compression

Applications: <<sbt_level_order,succinct binary tree>>


==== Auxillary data structure for rank query in O(1)

Given a bit vector, determine number of ones upto index i.  

*to-do* Using auxillary a data structure besides bit vector, query in O(1) time.

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 17. Succinct Structures I: https://www.youtube.com/watch?v=3Y2weLDiUWw&t=3901s[video], https://courses.csail.mit.edu/6.851/spring14/scribe/L17.pdf[lecture notes]


==== Auxillary data structure for select query in O(1)

Given a bit vector, determine index of i-th 1. 

*to-do* Using auxillary a data structure besides bit vector, query in O(1) time.

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 17. Succinct Structures I: https://www.youtube.com/watch?v=3Y2weLDiUWw&t=3901s[video], https://courses.csail.mit.edu/6.851/spring14/scribe/L17.pdf[lecture notes]


[[rrr]]
==== RRR

Stores a bitvector of length m (the universe) containing n ones (the stored set).  Answers rank and select queries in O(1) and provides implicit compression resulting in B(n, m) + o(n) + O(log log m) bits space.

Divide bitvector in p = m/u blocks of length u = 1/2 log~2~ m.  Each block stores the number of ones it contains, denoted n~i~ where i is the block's index.  So each block is u bits long and contains n~i~ ones.  Given a block, there are C(u n~i~) possible ways to arrange its n~i~ ones.  So for each block, we only have to store which of the C(u n~i~) variants equals the block's content, denoted O~i~.  So each block stores the tuple (n~i~, O~i~).  Note that O~i~is variable width, given by B~i~ = ⌈log~2~C(u, n~i~)⌉ bits.  Note that rank will add a bit more data.

Note the sequence of O~i~s is what we want to store at the core.  That contains the entropy.  Everything else is auxillary house keeping.

rank(x): In order not being forced to sequencially read all the n~i~ of every block until their sum reaches x, group every log^2^m blocks into a superblock.  Each superblock stores the tuple (sum of n~i~ of all blocks from the very beginning until inclusive this superbock, index into the bitvector of (n~i~, O~i~) tuples). *to-do* did I got this right?

select(x): Not in the scope of this document.

Analysis: O~i~ needs B~i~ bits.  Thus, regarding O~i~s, in total ∑B~i~ = ... = p + log~2~C(m n) bits. *to-do* be more thorough

Trivia: Named after inventors Raman, Raman, Rao.

References:

- http://alexbowe.com/rrr/


[[heap]]
=== Heap

A _heap_ is a specialized tree-based data structure that satisfies the _heap property_: If node A is a parent node of B, then the key of node A is ordered with respect to the key of node B with the same ordering applying across the heap.  In a _max heap_ the parent node key is greater than or equal to those of the children, in a _min heap_ it's smaller than or equal.  Thus the element with the largest (max heap) / lowest (min heap) key is always stored at the root.  Note that it follows that there is no implied ordering between siblings or cousins.

A heap is considered an data structure as opposed to an abstract data type, despite that it has multiple implementations (aka backing data structures).

Time complexities for binary, binomial, Fibonacci, pairing, Brodal, rank pairing, strict Fibonacci:

Creation::
- create-heap: create an empty heap
- make-heap (aka build-heap aka heapify): create a heap out of given elements. +O(n)+ binary, others *to-do*.
- union (aka merge): +Θ(m lg(n+m))+ binary, +O(lg(n))+ binomial, +Θ(1)+ others

Inspection::
- min (max) (aka peek or find-min/max): +Θ(1)+
- size()

Modification::
- extract-min(-max) (aka pop): +O(lg(n))+
- insert: +Θ(lg(n))+ binary, +Θ(1)+ others
- decrease-(increase-)key: +Θ(lg(n))+ binary & binomial & pairing,  +O(1)+ others

Binary heap vs BBST (balanced binary search tree), mainly from a priority queue perspective:  The killer feature of heaps is insertion in O(1) average, opposed to O(log n) for BBST.  Worst case is O(log n) for both.  Creating a binary tree from n elements is O(n), whereas it's O(n log n) for a BBST.  Altough most operations are of same time complexity, constants in binary heap are smaller and thus better.  Binary heaps have better locality of reference since they are array based, all elements are consequtive in the array.  Similarly, BBSTs waste more space for pointers.  Note that a BBST can be easily augmented such that it also supports find-min in O(1).  The killer feature of BBSTs over heaps is their O(log n) search time, opposed to heaps' O(n). https://stackoverflow.com/questions/6147242/heap-vs-binary-search-tree-bst, https://www.geeksforgeeks.org/why-is-binary-heap-preferred-over-bst-for-priority-queue/

Practical use of advanced heaps like Fibonacci or Brodal: ``To the best of my knowledge, there are no major applications that actually use Fibonacci heaps or Brodal queues. [...]  the data structures were not developed to meet practical needs, but rather to push forward our theoretical understanding of the limits of algorithmic efficiency. [...] the constant factors hidden in a Fibonacci heap or Brodal queue are very high. [...] If you're working on huge graphs, it's more common to use other techniques to improve efficiency, such as using approximation algorithms for the problem at hand, better heuristics, or algorithms that use specific properties of the underlying data.'' https://stackoverflow.com/questions/30782636/are-fibonacci-heaps-or-brodal-queues-used-in-practice-anywhere

Applications of heaps:

- The heap data structure is one maximally efficient implementation of the <<priority_queue>> ADT.

- <<heap_sort>>. Commonly a binary heap is used, since then then the algorithm can in-place sort an array.

- <<Dijkstra>>'s shortest-path algorithm

- Order statistics

A heap data structure should not be confused with `the heap' which is a common name for the pool of memory from which dynamically allocated memory is allocated.


[[binary_heap]]
==== Binary heap

In a _binary heap_ the tree is a complete <<binary_tree>>.  Keys are not stored in a typical tree data structure where each node has pointers to its childs.  Instead, keys are stored in an array.  The index in the array implies the position in the binary tree and vice versa.

Visualizing element array indexes (1 based) as a tree:
--------------------------------------------------
                   tree level
        1          0
    2       3      1 
  4   5   6   7    2
 8 9               3 
--------------------------------------------------

Visualizing element array indexes (1 based) as an array:
--------------------------------------------------
array index  123456789
tree level   01-2---3-
--------------------------------------------------

Many authors describe that a binary heap is more about algorithms than about a data structure. Most importantely heap sort.

Terminology: Often heap is used as a synonym for binary heap, altough heap actually is a more general data structure.  Also just `binary heap' as opposed to `binary max/min heap' technically means the above described array based data structure, however where the nodes in the associate tree do not necessarily follow the heap property.

++parent(i)++: return floor(i/2) // i>>2

++left_child(i)++: return 2i // a return value >= heapsize means i is a leaf

++right_child(i)++: return 2i+1 // a return value >= heapsize means i is a leaf

++max_heapify(i)++: Every node in i's subtree except i itself obeys the heap property; restore the heap propery of node i.  Float down the violating node, always swapping the vialoting root with the largest child.  It's the largest child in order that the tripple (root, left, right) obeys the heap property.  Stop once the node arrived at a position where it no longer violates the heap property, which includes the case that it is now a leaf. O(h) = O(log n) time complexity, where n is the number of nodes in tree rootet at i.

++build_heap()++: Converts a given array into a heap.  The leaf nodes are already one-element heaps.  I.e. there is a forest of heaps.  Look at the tree diagram above.  From left to right, from tree level h-1 downto tree level 0, i.e. from index array.size/2 downto 1, add a node to the forest as a new root combining two trees by treating it as a vialoting root of a subtree and call max_heapify on it.  The core loop really just is ++for i=arraysize downto 1: max_heapify(i)++.  Time complexity is O(n), which is the killer feature of an heap vs a BST which has O(n log n) to build.

++max()++: return A[0]

++extract_max()++: Swap the root, i.e. the max, with the right most child, i.e. the last element in the array. Now that last element can be easily removed from the array; typically just by decrementing the array size variable.  Call max_heapify(0) to restore the new root's heap property.  Return the value which was removed from the array before.  O(log n) time.

++increase_key(i, new_value)++: Bubble up the violating node (actually the node making its parent violate the heap property), always swapping the violating node with its parent, until the heap property is no longer violated.

++insert(val)++: Append val to the array, i.e. make it the right most child of the tree. Then use the same algorithm as in increase_key to restore the heap property by bubbling up the new element until it reaches its proper place.

++delete(i)++: Since binary heaps are mostly used to impement priority queues or heap sort, this operation is typically not needed. Swap i with the last array element; then this new last array element can easily be removed (aka popped) from the array. The node i now may violate the heap property. Bubble up or tickle down as in max_heapify or insert respectively.

++decrease_key(i, new_value)++: Since binary heaps are mostly used to impement priority queues or heap sort, this operation is typically not needed.  As in max_heapify, tickle down the node until the heap proprty is restored.

General anlysis: Height is h = Θ(log n) since it's a complete binary tree.


==== Fibonacci heap

*to-do*:


[[disjoint_set_linked_list]]
=== Disjoint-set linked list

A data structure implementing the <<disjoint_set>> ADT, based on a collection of linked lists.  Each linked list represents a each set, and each set element is stored as an element in one of the linked lists.  The element at the head of each list is chosen as its representative.  Each linked list node has a pointer to the head of its list, i.e. to the set representative.  Each linked list stores its size.

_make-set(x)_: Create a new linked list with v as its only element. Runs in O(1) time.

_find-set(x)_: Return the set representative which we get by following the `to-head' pointer of v. Runs in O(1) time.

_merge_set(x, y)_: Append the smaller list to the larger list.  Then reseat the `to-head' pointer of the appended list.  Runs in O(n) time.

References:

- Book "Introduction to algorithms", subchapter "21.2 Linked-list representation of disjoint sets"


[[disjoint_set_forest]]
=== Disjoint-set forest

A data structure implementing the <<disjoint_set>> ADT using a forest.  Each set is represented by a tree, each element is represented by a tree vertex.  The set representative is the root vertex.  Vertices have parent pointers.

+find_set(v)+ follows the parent pointers until the root, and then returns the root, which is the set representative.  +merge_sets(u,v)+ adds the root of one tree as a new child to the root of the other tree.

A common optimization is _path-compression_: When following the path from a vertex to the root, make all visited nodes direct children of the root. This helps to make the tree rather shallow.

Another common optimization is _union by rank_: Each vertex is assigned a rank, which is an upper bound on the height of the subtree rooted at the given vertex.  +make-set(v)+ sets it to zero, i.e. to the true height.  +merge_sets+ attaches the smaller tree to the larger tree, according to the ranks of the two roots.  The rank of the receiving root is increased by one.  Path compression does not change the rank of any vertex.  Path compression only reduces the height of a tree, so the rank, being an upper bound on the height, is still valid.  Note that it would not be trivial for path compression to maintain the true height of the tree.  Anyway, an upper bound is good enough.

--------------------------------------------------
insert(v):
  parent[v] = v
  rank[v] = 0

find-set(v):
 if parent[v]!=v:
   parent[v] = find-set(parent[v]) // "parent[v] =" is path compression
 return parent[v]

merge-sets(u,v):
  rootOfU = find-set(u)
  rootOfV = find-set(v)

  // naive variant
    parent[rootOfU] = rootOfV

  // union by rank optimization
    if rank[rootOfU]<=rank[rootOfV]: parent[rootOfU] = rootOfV
    else                           : parent[rootOfV] = rootOfU
    if rank[rootOfU]==rank[rootOfV]: rank[rootOfV] += 1
--------------------------------------------------

Trivia: Was invented specifically to make Kruskal's algorithm more efficient.

References:

- https://web.stanford.edu/class/cs166/lectures/16/Small16.pdf

- Book "Introduction to algorithms", subchapter "21.3 Disjoint-set forests"


== Misc. problems and algorithms

[[edit_distance]]
=== Edit distance

Given two strings x and y, the edit distance is the minimum cost series of
edit operations that transform x into y.  There are cost tables:
cost-deletete[c] is cost to delete char c from x, cost-insert[c] is cost to
insert char c into x, cost-replace[c1, c2] is cost to replace char c1 by
c2. Doing nothing modeled by cost-replace[c,c].

Solution using <<dynamic_programming>>:

_Define suproblems_: All possible suffixes of x and y.  I.e. edit distance on
x[i:] and y[i:] for all i∊[0,|x|) and j∊[0,|y|).

_Guessing_: In each step, there are three choices: ① replace x[i] by y[j] (do
nothing is modeled by replacing c by c) or ② insert (prepend) y[j] to x or ③
delete x[i].  The general idea is to consume the first character of x and/or y
in order to 1) make first char of x and y equal and to 2) be left with a
subproblem (to make progress at least one char needs to be consumed).

_Recurrence_: DP is defined as following:

-----
DP(i,j) =
  if i=|x| and j=|y|: ④ 0
  else: min(
  ① cost-replace[x[i],y[j]] + DP(i+1, j+1)  if i+1≤|x| and j+1≤|y|,
  ② cost-insert[y[j]]       + DP(i  , j+1)  if             j+1≤|y|,
  ③ cost-delete[x[i]]       + DP(i+1, j  )  if i+1≤|x|            )
-----

④ is the base case (aka smallest subproblem), which is the edit distance to
transform the empty string to the empty string, which obviously is 0.

_Implement algorithm_: The following describes the subproblem DAG: Imagine a
matrix, each cell represents a vertex in the DAG and thus also represents
DP(i,j). It has |x| rows indexed by i, and |y| columns, indexed by j. Thus the
top left cell/vertex is the original problem (edit distance to transform x into
y), and bottom-right cell/vertex is the base case ④.  The weight of the edges
are the respective cost-x[…] term in the DP formula of step 3.  Optionally each
cell/vertex can have a value attribute which then is DP(i,j).

Example: x=FLO and y=FOO:

-----
             outgoing edges of each matrix-cell / DAG-vertex
   FOOε      the cells in the left-most column and bottom-most row
   0123 j    naturally don't have edges leaving the matrix
F 0R···      ☐→① insert
L 1····      ↓ ↘③ replace
O 2····      ② delete  
ε 3···④      
  i          R means root of the DAG, i.e. the original problem
-----

bottom-up approach: Solve the subproblems by starting in the bottom
right corner and then going left and/or up.  E.g: ++for i=|x|⋯0: for
j=|y|⋯0: …++.

Space complexity: Θ(|x|⋅|y|) (number of cells) for a trivial implementation.
If only a sliding window of one row or column, which ever of |x| or |y| is
smaller, is kept, the space complexity becomes Θ(min(|x|,|y|)).

_Solve original problem_: The original problem is DP(0,0).


Analysis: time complexity: #subprobs=Θ(|x|⋅|y|) (number of cells). time/subproblem = Θ(1). Overall running time = #subprobs⋅time/subproblem = Θ(|x|⋅|y|).


*to-do*:

- Most sources on the net seem to solve it in terms of making the subproblems
  prefixes, opposed to suffixes as above.  So my matrix above doesn't match
  moste of the pictures / drawings found on the net.
- Backtracing / make the operations needed available to the caller

Applications:

- Computational biology: quantify similarity of DNA sequences

- Correction of spelling mistakes, i.e. which correct word is the most likely


=== Longest common subsequence (LCS)

Given a set of sequences, typically two, what is (are) the longest common subsequence(s) -- The solution might not be unique, i.e. multiple subsequences of same lenght will qualify as having the longest lenght.  Note that unlike substrings, subsequences are not required to occupy consecutive positions.

In general: NP-hard.

For two sequences: Equals the <<edit_distance>> problem, with cost of insert and delete being 1 and replace being 0 for c→cʹ and ∞ otherwhise.

Applications:

- File comparison, e.g. the diff utility.

- Bio informatics: as a measure how similar DNA sequences are (the longer the LCS the more similar).


[[knapsack]]
=== Knapsack

0-1 knapsack problem:: Given a set of n items, each item i with a weight w[i]
(an integer) and a value v[i], determine the items to include in a collection
so that the total weight is less than or equal to a given limit S (an integer)
and the total value is maximal.

Bounded knapsack problem (BKP):: Removes the restriction that there is only
one of each item, but restricts the number of copies of each item i to c[i].

Unbounded knapsack problem (UKP):: Places no upper bound on the number of
copies of each kind of item.

Change-making problem:: How can a given amount of money be made with the least
number of coins of given denominations. Similar to UKP, however capacity of
knapsack has to be hit exactly. `weight of item' corresponds to `value of
coin', and `value of item' is always -1.

[[rod_cutting_problem]]
Rod cutting problem:: Same as UKP. rod length -> knapsack capacity, length i
-> item i having a weight of i, value of length i -> value of item i.

Fractional/continuous knapsack problem:: Instead of items we think of
materials.  There is an certain amount (weight) of each material, and we can
pack any amount less than that per material into the knapsack. Solution: sort
materials descendinding by value/weight, then greedely take of each material
as much as possible until the knapsack is full. O(n*lg(n)).


Solution for the 0-1 knapsack problem using <<dynamic_programming>>:

Put the items in some sequence.

_Define suproblems_: All possible suffixes of the item sequence (items[i:]) ×
all possible remaining capacities X≤S.

_Guessing_: In each step, there are two choices: ① shall I include item i (aka
current/front item) or ② shall I not?

_Recurence_: DP is defined as following:

-------------------------------------------------------
DP(i,X) =
  if i=n: ③ 0
  else: max(
  ①        DP(i+1, X)       if i+1≤n            ,
  ② v[i] + DP(i+1, X-w[i])  if i+1≤n and w[i]≤X )
-------------------------------------------------------

③ is the base case, which is the knapsack problem for an empty set of items and
whatever remaining capacity: the maximal value is obviously 0.

_Implement algorithm_: The following describes the subproblem DAG. Imagine a
matrix, each cell represinting a vertex in the DAG and thus also represents
DP(i,X).  It has n+1 columns indexed by i, and S+1 rows, indexed by X.  Thus the
top left cell/vertex is the original problem (knapsack for all items and
capacity S).  The right column are the base cases.

Example: n=3 items, capacity S=4:

----------------------------------------------------------------------
c    item
a    0124     outgoing edges of each matrix-cell / DAG-vertex:
p   4R··③     ☐→① Don't include item i. Edge-weight 0.
a   3···③      ↘② Include item i, which removes w[i] from capacity X.
c   2···③         Edge-weight -v[i].
i   1···③     
t   0···③     R means root of the DAG, i.e. the original problem
y   
----------------------------------------------------------------------

Bottom-up approach: Solve subproblems by starting in the bottom right corner
and then going left and/or up: E.g.: ++for i=n⋯0: for X=0⋯S: …++.  Space
complexity can be improved by only using a sliding window of two columns.
Note that the top-down approach doesn't need to calculate all n*S vertices; it
only calculates the ones reachable from DP(0,S).

_Solve original problem_: The original problem is DP(0,S).

_Reconstruction a solution_: The items to be included into the knapsack are (for non-zero weights).
--------------------------------------------------
X = S
for i in [0,n)
  if DP(i, X) = v[i] + DP(i-1, X-w[i]): // i.e. if choice ② was made
    remember item i as included in knapsack
    X -= w[i]
--------------------------------------------------

Analysis: Time complexity is Θ(1) for one DP call. Thus the overall running time
is +Θ(n*S)+, i.e. <<pseudo_polynomial>>. It's exponential, since +Θ(n*S)+ is
exponential relative to the input size which is +O(n*lg S)+ (think how many bits
you need to represent the input).

Applications:

*to-do*

*to-do* process https://en.wikipedia.org/wiki/List_of_knapsack_problems


[[orthogonal_range_search]]
=== Orthogonal (rectangular) range (interval) search (query)

Given a set of points in k-dimensional space, find the ones being in a k-dimensional range.  E.g. when doing a database query, we want to find the persons with age in [20,40] and height in [150, 200] and weight in [50,100]. Don't confuse orthogonal range search with <<range_query>>.

Given a set of k-dimensional geomteric objects (aka ranges), find the ones which intersect (aka overlap).

Data structes / Algorithms:

- <<kd_tree>>

- <<range_tree>>

References:

- Book "Computational Geometry - Algorithms and Applications", chapter "Orthogonal range searching"

- http://www.cs.utah.edu/~lifeifei/cs6931/kdtree.pdf


[[1d_orthogonal_range_searching]]
==== 1d orthogonal range searching using a BST

Given a set P of points, find the points in range [f, t] (f=from, t=to).

Put the points in a a balanced binary search tree. Often it's one which stores its values in its leaves, see e.g. <<naive_BST>>.   This is especially convenient for higher dimensions, see <<range_tree>>.

Search f and t in the tree. There is one search path until a node, often called the split node, where the search splits in two paths.  Let nf and nt be the two leaf nodes where the two searches end. The leafes of all the subtrees `enclosed' by the two paths (splitnode, nf) and (splitnode, nt) are the result.  In text book examples, typically these subtrees are reported on the fly while descenting from the split node.  On the left search path, the right subtree when descending left, and nothing when descending right.  Analogously for the right search path.

Analysis: O(n log n) for building the binary search tree, and O(k + log n) for reporting, where k is the number of reported points.  Informal proof: Reporting a subtree is O(kʹ), where kʹ is the number of leavs in that subtree.  Searching f and t in the tree is O(log n).


References:

- Book "Computational Geometry - Algorithms and Applications", subchapter "5.1 1-Dimensional Range Searching"

- https://courses.csail.mit.edu/6.851/spring12/scribe/lec3.pdf, first part of section "range trees"

- http://www.cs.utah.edu/~lifeifei/cs6931/kdtree.pdf, chapter "1 - Dimensional Range Searching"


[[range_query]]
=== Range query (data structures)

A _range query_ consists of preprocessing some input data into a data structure to efficiently answer any number of queries on any subset of the input.  Don't confuse range query with <<orthogonal_range_search>>.

A q~f~(A, i, j) range query on an array A of n elements, takes two array indices i and j, an implied function f whose domain is a set of array elements, and outputs f(A[i,j]) = f(a~i~, ..., a~j~). E.g. the function f might be the sum over all input arguments.

Solutions:

- When the function f has an well defined inverse f^-1^: Have an auxillary array B of size n, B[i] storing the result of f(A[0,i]).  Then q~f~(A, i, j) = f(A[i,j]) = f^-1^(B[j], B[i-1]).  Costs O(n) auxillary space, O(n²) preprocessing time, O(1) query time.

- *to-do* order statistics in a range: https://en.wikipedia.org/wiki/Range_query_(data_structures)#Median


[[RMQ]]
=== Range minimim query (RMQ)

Given an array A, find the index k of the minimum element in a given range [i,j].  It can be shown that the two problems RMQ and <<LCA_problem,LCA>> are equivalent, see <<RMQ_LCA_equivalence>>.

The RMQ LCA equivalence even allows us to do a _universe reduction_ of RMQ problems.  The original RMQ problem may involve numbers of any size, or even any orderable things. By converting the original RMQ to a LCA, and then back to RMQ with node depths as labels, the new RMQ only deals with integers < n.  Of course we can alternatively even reduce to ± 1 RMQ instead, see <<reduce_LCA_to_pm1_RMQ,reduce LCA to ± 1 RMQ>>.

_± 1 RMQ_ is a special case of RMQ where each consecutive element differs by exactly either +1 or -1.  See also <<reduce_LCA_to_pm1_RMQ,reduce LCA to ± 1 RMQ>>.

Solutions:

- Reduce to LCA and solve there, see <<RMQ_LCA_equivalence>>.

- Brute force. O(n) query time.

- Naive loopkuptable storing the answer to all possible queries. O(n²) auxillary space, O(1) query time.

- Powers of two lookuptable.  O(n log n) auxillary space, O(1) query time. See subchapter.

- Indirection and lookuptables.  O(n) auxillary space, O(1) query time.  See subchapter.

References:

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees: https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video]


==== ① Powers of two lookuptable

Precompute RMQ for all intervals with lengths that are powers of two. O(n log n) auxillary space, O(1) query time. *to-do* brute force preprocessing time is O(n² log n), but can we do better?

There are a total of O(n log n) such intervals, as there are log n different possible interval lengths, with n possible start locations. To solve RMQ in interval [i,j], having a length k = j - i + 1, we fetch two of the precomputed RMQ of length floor(log k).  The one  starting at i and the one ending at j.  Take the min of the two precomputed answers, done.  The two fetched intervals might overlap, but that doesn't change the final RMQ result.

References:

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees, chapter "3.3 contant time, n lg n space RMQ" in https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], or https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video] at  24:30.


==== ② Technique indirection

Intended as building block to be used by a higher level algorithm.  Divide original array into N consecutive subarrays (aka bottom arrays) of length nʹ.  Create a parent array of length N.  Each cell corresponds to a subarray and stores that subarrays' RMQ over the whole subarray, i.e. the subarray's min.

The following is rather verbose, the intention being trying to highlight the more general idea of the technique.  Think of RMQ as being any associative operation.  Instead of RMQ in range [i,j], think x~i~ ∘ x~i+1~ ∘ ... ∘ x~j~.

The parent array intuitively serves as an highway by having whole subarrays precomputed. To answer a RMQ query in range [i, j], we split the request into three consecutive ranges, do a RMQ on each of the ranges, and then do an RMQ on the three results. That only works because RMQ is an associative operation.  Do a RMQ in range [i,∞] in the left subarray, go on the highway and do a RMQ in the enclosed range of the parent array and finaly do a RMQ in range [-∞,j] in right subarray.

Note that the problem of solving RMQ in the parent array has the same structure as the original problem, but now the problem is smaller in size.

--------------------------------------------------
  |    |     |     |     |     |  parent array cells store precomputed RMQ over
                                  whole corresponding subarray

  |    |     |     |     |     |  subarrays logically devide original array

  |                            |  original array

    <----------------------->     sample query
    <-> <---------------> <->
    i                       j
--------------------------------------------------

*to-do* I don't fully understand why this technique is called indirection. It has much more to do with precomputing / lookuptables I'd say.  Maybe because the problem of solving RMQ in the parent array has the same structure as the original problem?


==== ③ Technique lookuptables for a large set of small arrays

We are given a large amount of arrays of small and similar size n, and need to be able to solve RMQ in any of them.  Intended as building block to be used by a higher level algorithm.

Reduce each array to ± 1 RMQ, via <<reduce_RMQ_to_LCA>> and <<reduce_LCA_to_pm1_RMQ>>, which then can be interpretet as bit string of length n-1, by looking at the difference to the next element, which is either +1 or -1.  For simplicity we think of the string length as n oppose to n-1.  There are 2^n^ possible different arrays aka array types.  In meaningfull applications, there are much more arrays given than there are array types.

For each array type, we store a lookuptable which solves RMQ on that array type in O(1). (*to-do* why exactly uses Erik Demaine the naive lookuptable instead the power of two variant?)

Each array stores it's array type. Thus we can answer an RMQ on any array by quering the lookuptable associated with that array.


==== Indirection plus lookuptables

Use indirection as described above in ②. Have N = 2n / log n subarrays being of length nʹ = 1/2 log n. RMQ in the parent array can be solved using a ① powers of two lookuptable.  RMQ in a subarray is solved using the technique ③ lookuptables for a large set of small arrays.

Analysis for parent array:  Auxillary space for parent array's lookuptable is O(N log N) = O( (2n / log n) · log(2n / log n) ) = O(n) and query time is O(1).

Analysis for bottom arrays:  According to ③, there are 2^nʹ^ = √n different subarray types.  I.e. there are much less possible subarray types (√n) than there are concrete subarrays (2n / log n).  We can now afford so store a lookuptable for each subarray type.  We have √n subarray types, each lookuptable needs nʹ² enties, each entry needs log nʹ bits.  Space requirement thus is O(√n · log²n · log log n) = o(n) bits, query time is O(1)

Analysis total: O(n) auxillary space and O(1) query time.

The motivation for this algorithm is that we generally liked the properties of the powers of two lookuptable, but wanted to shave off the log n factor in its O(n log n) auxillary space complexity.  The combination of using indirection and the specific chosen subarray got us there for two reasons: 1) Using `power of two lookuptables' now costs only O(n) space instead O(n log n). This is because the lookuptable is now for the smaller parent array, size N = 2n / log n, opposed to the original array of size n. 2) The subarrays are small enough such that there are far less subarray types than actual subarrays, which makes ③ feasible, and thus gives O(n) space also for all the subarrays.

*to-do* Say I din't knew that subarray size should be 1/2 log n. How would I calculate it? Also, similarly, why exactly is the factor 1/2. Erik Demaine says that concerning the space complexity of the parent array nʹ = Θ(log n) is the only thing we need.
 
*to-do* Why exactly don't we recursively divide subarrays. My thoughts are between `we already have O(n) space and O(1) query time, what should we want more' and `would it be recursive, the query time would get worse and become O(log n)', but I am not sure.

References:

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees, chapter "3.4 Indirection to remove log factors" in https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], or https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video] at 27:30.


=== Consumer producer

Solution using semaphores.  Allows for multiple producers and consumers.

----------------------------------------------------------------------
Semaphore emptyCount
Semaphore fullCount
Semaphore useQueue

produce:
  wait(emptyCount)
  wait(useQueue)
  putItemIntoQueue(item)
  signal(useQueue)
  signal(fullCount)

consume:
  wait(fullCount)
  wait(useQueue)
  item ← getItemFromQueue()
  signal(useQueue)
  signal(emptyCount)
----------------------------------------------------------------------

*to-do*:
- Solution with monitors
- Question: why isn't it in the above solution good enough to only guard the one critical section with a single binary semaphore?


=== Dining philosophers
*to-do*


=== Horner's method / Horner's scheme

Task: Evaluate a polynomial P(x)=a~0~ + a~1~x + ... + a~n~x^n^ at x=x~0~.  Solution: Since the polynomial can be rewritten as a~0~ + x (a~1~ + x(a~2~+...+x(a~n~)...)) we can solve it beginning at the deepest level and iteratively go outward: b~n~=a~n~, b~n-1~=a~n-1~+x~0~b~n~, ..., b~0~=a~0~+x~0~b~1~ with b~0~ being the solution.  In code, with b~i~ stored in ++acc++umulator:

--------------------------------------------------
double polynomial(double x, const vector<double>& coefficients) {
    double acc = 0;
    for (int i=coefficients.size()-1; i>=0; --i) {
        acc = coefficients[i] + x * acc;
    }
    return acc;
}
--------------------------------------------------


[[hash_function]]
=== Hash function (aka hash)

A _hash function_ h(k, m) maps a key k to an integer in the range [0, m).  m is an integer m ≤ k.  In the case of a hash table, m is the size of the underlying array.  U is the universe of possible keys.  K is the set of keys actually used.  In the case of an hash table, contrast this with the keys currently stored in the table; K then is the set of keys ever stored in the table during it's life time.  Typically k is an integer of the size of a CPU word.  _Prehashing_ is used to map any originial key of any size to [0,k).

A _good hash function_:

- Is a <<simple_uniform_hash_function>>. In practice, we often can only approximate.

- Does not hash `similar' keys to the same slot.  Especially in the case of a hash table using linear probing.

Applications:

- <<hash_table>>

- String searching, e.g. <<rabin_karp>>

- Cryptography


References:

- See those of <<hash_table>>


[[division_method]]
==== Division method

A heuristic method. +h(k,m)=k mod m+. In practice not so bad if m is prime and not close to a power of two or power of then. Still pretty `hackish'; Work's a lot of the time in practice, but not always.  We can't proove much.

Rational for m being prime: When all (or most) keys are d appart (k~i~ = a+id), and d is a factor of m, then many slots or not used. E.g. when the keys are 3 appart like e.g. {1, 4, 7, 10, 13, ...}, m is 6=3*2, then the resulting hashes are {1, 4, 1, 4, 1, ...}. I.e. out of the slots {0, 2, 3, 5} are not used at all, and thus the slots {1, 4} have much more collisions than with a totally random hash.

Rational for m not being close to power of two or power of then:  In real world problems, powers of two or then are common.  *to-do* I still don't entirerly understand itd.  When m is exactly a power of two or then, then this case is already ruled out by the case that m should be prime.


[[multiplication_method]]
==== Multiplication method

A heuristic method. ++h(k,m,a,w) =((ak) mod 2^w^) >> (w-r)++, where as m=2^r^, i.e. +r=lg(m)+, and the machine stores integers in words of size w bits. a should be odd and not close to a power of two, between 2^r-1^ and 2^r^.  Works quite well in practice, altough we can't proove much.

Intuitively: The multiplication mixes up the bits of k.  Looking at the product, especially in the area from bit (w-r) to w, so we extract that area.  +% 2^w^+ cuts away the part left of bit w, the shift right cuts way the bits right of bit (w-r).


[[simple_tabulation_hashing]]
==== Simple tabulation hashing

View key x as vector of characters x~1~, ..., x~c~. We create a totally random hash table T~i~ for each character.

h(x) = T~1~(x~1~) xor ... xor T~c~(x~c~)

Is <<k_wise_independent_hash_functions,3-wise independent>>, but no 4-wise independent.


[[simple_uniform_hash_function]]
====  Simple uniform hash function

A hash function is called _totally random_ (or _uniform_ or _ideal_) it satisfies the _simple uniform hashing assumption_ (_SUHA_), which is:

Pr(h(x) = t) = 1/m, for all keys x ∈ U and every slot t ∈ [m] and independend of all y ≠ x ∈ U.

In plain English, that says each key is equally likely to to be hashed to any slot, independent of where any other key is hashed to.  I.e. all keys must be mutually independent, opposed to 2-wise independent as it is the case for universal hashing.

Note that ideal hash function and <<perfect_hash_function>> are different things.  Perfect hashing guarantees no collisions, ideal hashing guarantees certain probabilities about collisions.

However an implementation would require Θ(U log m) space: A table of |U| entries, each entry storing the hash value.  Each entry then needs Θ(log m) space.  In general this space requirement is far too large.  Such a table is called a _totally random hash table_.

In practice it's not possible to create a simple uniform hash function.  Thus approximations are used such as <<division_method>>, <<multiplication_method>>, <<simple_tabulation_hashing>>, or defining weaker guarantees such as <<universal_hash_function>>.

In practice it's not possible to check SUHA, since we rarely know the probability distribution of the keys.  In practice, we often employ heuristic techniques to create a hash function that approximates simple uniform hashing.


[[strong_uniform_hash_function]]
==== Strong uniform hash function

Generalizes the notion of simple uniform hash function to a hash function that produces not just a single hash value, but a whole probe sequence of hash values.  Each produced probe sequence of hash values is equally likely to be any of the m! possible permutations.  In other words, each possible sequence of hash values must be equaly likely.

True strong uniform hashing is difficult to implement, however, and in practice suitable approximations (e.g. double hashing) are used.


[[perfect_hash_function]]
==== Perfect hash function

A _perfect hash function_ maps the set K of actual keys (as opposed to the universe U of all keys) to [m] with no collisions at all, i.e. it is an injective function.  It may be used to to implement a hash table with O(1) worst-case access time, see <<collision_resolution_with_perfect_hashing>>.

Note that perfect hash function and ideal hash function are different things, see respective paragraph in <<simple_uniform_hash_function>>.

Note that <<direct_addressing>> maps the whole universe U of key, not just the set of actually used K, to [0, m), which is a stricter form of perfect hashing.  To implement it, you need a table mapping each key of K to [0, m), which is not trivial.  You then might as well use a <<trie>>, also <<trie_vs_hash_table>>.


==== Hash function Family

Any fixed hash function maps multiple keys to the same slot.  Thus given a fixed hash function, a malicious adversary can always choose a set of keys that map to the same slot, yielding an average retrieval time of Θ(keys in slot).

At the creation of a given hash table, we select a hash function h at random and independent from the keys that are actually going to be stored from a given famility of hash functions H.  This guarantees that no single input will always evoke worst-case behaviour.


[[universal_hash_function]]
==== Family of universal hash functions

A family H of hash functions is called a _universal familiy_ (or just _universal_) if

Pr~h~[h(x) = h(y)] = O(1/m) for a randomly chosen h ∈ H and for all x ≠ y ∈ U.

Alternatively: For for all x ≠ y ∈ U, the number of hash functions h ∈ H for which h(x) = h(y) is O(|H|/m).  Note that in other definitions, the rhs is ``≤ 1/m'' opposed to ``= O(1/m)''.

Examples of universal families:

- h~a,b~(x) = ((ax+b) mod p) mod m, for a prime p where p ≥ |U| and integers a, b where 0 < a < p and 0 ≤ b < p.  Note that some sources wrongly omit the b.  ax can also be vector dot product. Note that this is not exactly the same as the division method.  Is relatively expensive to compute due to the mod operations. (*to-do* is b really required? That makes the distinction between being universal and 2-wise independent, no?)

- h~a~(x) = (ax) >> (log U − log m),  i.e. use log m high order bits of product ax.

- Family of all hashfunctions h: U → [m].  That includes also the stupid hash function which maps every key to slot 0.  But it's only one of many hashfunction, so the probability to choose it is very low and the condition holds overall.  (*to-do* isn't there a better definition which excludes `stupid' hash functions from the family definition?).


[[k_wise_independent_hash_functions]]
==== Family of k-wise independent hash functions

A family H of hash functions is k-wise independent if:

Pr(⋀~1≤i≤k~h(x~i~)=t~i~) = O(1/m^k^) for a randomly chosen h ∈ H and for all distinct x~1~, ..., x~k~ ∈ U and for all (not necessarily distinct) t~1~, ..., t~k~ ∈ [m].

k=2: In other words, if h is choosen at random from H, then the random variables h(x) and h(y) are uniformly distributed and pairwise indpendent.

k-wise independent gives stronger guarantees than universal.  Even pairwise independent (k=2) is already stronger than universal.  Every totally random hash function is k-wise independent for any k.

*to-do*: understand the following

- https://crypto.stackexchange.com/questions/28938/prf-and-pairwise-independent-hash-function

- https://cs.stackexchange.com/questions/50922/is-the-following-intuition-valid-for-understanding-k-wise-independent-hash-fun

Examples:

- k=2: h(x) = [(ax + b) mod p] mod m, for integers a 0<a<p and b 0≤b<p. Here, again, p is a prime greater than |U|.

- k=2: h(x) = ((∑~0≤i<k~a~i~x^i^) mod p) mod m, for integers a~i~ 0≤a~i~<p and 0<a~k-1~<p. Here, again, p is a prime greater than |U|.  Is relatively expensive to compute.

- k=3: <<simple_tabulation_hashing>>

References:

- http://people.csail.mit.edu/mip/papers/kwise-lb/kwise-lb.pdf

- http://www.wisdom.weizmann.ac.il/~oded/CC/X/hash.pdf


== Sorting algorithms

Properties of sorting algorithms.  See also properties of algorithms in general.  Comparison-based sorting algorithm are asymptotically optimal when they run in +O(n lg(n))+ time.

Stable::
Stable sorting algorithms maintain the relative order of records with equal keys

Adaptive::
Whether or not the presortedness of the input affects the running time.

internal/external sorting::
Internal: all the data fits into main memory. External: the input data does not fit into main memory, and parts of it must reside on secondary storage.


=== Comparison of sorting algorithms


References:

- Book ``Introduction to algorithms'', subchapter ``Introduction / Sorting algorithms'' in chapter ``II Sorting and Order statistics''.

- https://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_of_algorithms

- Non comparison sorts with integers: http://en.wikipedia.org/wiki/Integer_sorting

* MIT course MIT 6.851 Advanced Data Structures, Spring 2012, Lecture 14 Sorting in Linear Time: https://www.youtube.com/watch?v=pOKy3RZbSws&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=14, 6:40

- Book "Algorithms" (4th Edition), Sedgewick & Wayne, chapter "5.1 String Sorts", section "Which string-sorting algorithm should I use", p. 724.

- Book "Algorithms" (4th Edition), Sedgewick & Wayne, chapter "2.5 Applications" (of Sorting). In particular section "Which sorting algorithm should I use?", p. 342.


==== Comparison based

* Bubble sort, Insertion Sort and Selection Sort, having +O(n^2^)+, are bad. However insertion sort is online, stable, adaptive and has a small constant factor (also due to being CPU cache friendly), works well for small input sizes,  so it's often used for the base case of the recursive +O(n log n)+ algorithms. Bubble sort has tiny code size.

* Quick sort is great when it works due to tight code and small hidden constant factor, but unreliable (O(n²) worst case), not stable and it needs O(log n) auxillary space (even O(n) in the worst case) for the stack. Time complexity has a relatively small constant factor since it's CPU cache friendly.  Countless implementation support the hypothesis that quick sort is the fastest general purpose sorting algorithm.

* Merge sort is reliably good (+O(n log n)+ worst case), stable, highly parallelizable, allows for external sorting, but requires +O(n)+ auxiliary space;

* Heap sort is reliably good (+O(n log n)+ worst case), but unstable, and also about a factor of 4 slower than quick sort's best case.

* Introsort (hyprid of quick sort and heap sort) almost same as quicksort, but is now relyably good (+O(n log n)+ worst case), however the constant factor is between quick sort and heap sort.  I.e. on average introsort is worse than quick sort.


==== Sorting integers (non comparison based)

* Counging sort is Θ(k+n) average and worst-case. Stable. The integers must be in range [0,k].

* Radix sort is Θ(d(k+n)) average and worst-case; large constant factor. The integers are d-digit numbers with radix k.  Considering the large constant factor, radix sort might be preferable over a comparison based sort with O(n log n) when log n is much larger than d.

* Van Emde Boas tree based: Depending on the variant O(n log k) or O(n log(k/log(n))); large constant factor.  k is the radix.

* Bucket sort is Θ(n) on average and Θ(n²) in the worst-case.  Stable.  The numbers must be uniformly distributed in a given range.

* Signature sort is O(n). *to-do*


==== Sort strings

- least-significant-digit first (LSD) string sort

- most-significant-digit-first (MSD) string sort

- three-way string quicksort

*to-do*


==== External sorting

- Merge sort

*to-do*


=== Insertion sort / sort by insertion

Properties:   Adaptive.  Stable.  In-place.  Online.

Algorithm brief: In each outer iteration, the next element from the yet unsorted part is inserted into its correct position in the sorted part.

Algorithm detailed: The input is logically divided into a sorted part at the left, initially empty, and an unsorted part at the right, initially the complete input.  In each outer iteration, insertion sort removes (see following swap) the leftmost element from the unsorted part.  In an inner iteration it drags the element to the location the elements belongs to within the sorted part by searching to the left and swapping elements on the way.

Time: O(n^2^) worst case & average case, O(n) best case.  It has a small constant factor since its CPU cache friendly, thuse its often used for small arrays, e.g. as the base case for O(n log n) algorithms.

Space: O(1).


=== Selection sort / sort by selection

Algorithm brief: In each outher iteration, select the min element from the yet unsorted part and append it to the sorted part.

Algorithm detailed: Divide the input logically into a sorted part (initially empty) followed by an unsorted part (initially the whole input).  In each iteration search the smallest element in the unsorted part, swap it with the leftmost element of the unsorted part, then increment the pointer dividing the sorted / unsorted sub lists.

Time: O(n^2^) worst case & average case & best case.

Space: O(1).


=== Bubble sort / sort by exchange

Algorithm: The input is devided logically into an unsorted part to the left, initially the whole input, followed by an sorted part, initially empty.  In each inner iteration, a sliding window of length two elements traverses the unsorted list from left to right, advancing in one element steps.  At each step, the two elements in the sliding window are swapped if needed to ensure the right element is larger than the left element.  The result of one inner iteration is that the sorted part gets one element added to its left side, and the unsorted part gets one element smaller.  The process is repeated until all is sorted. As an optimisation, if an inner loop makes no swaps, it means the `unsorted' part is actually sorted and we can terminate early.


=== Shell sort

Properties: Adaptive.  Stable.  In-place.

Algorithm: Iterate over a sequence of positive integers denoting gaps.  The sequence is typically statically predefined.  The gaps are in decreasing order.  The last gap must be 1.  For each gap, use insertion sort to sort the subarrays {A[0+0·gap], A[0+1·gap], ...}, {A[1+0·gap], A[1+1·gap], ...}, ..., {A[gap-1+0·gap], A[gap-1+1·gap], ...}.

Can be seen as a generalization of insertion sort.  Tries to take advantage of the fact that insertion sort is adaptive.  Each subarray that is sorted via insertion sort is likely to be partially sorted due to a previous outer iteration.  The question of deciding which gap sequence to use is difficult.  Too few gaps slows down the insertion sorts, and too many gaps produces an overhead by too many outer iterations.

Time: Depends all on the gap sequence. Best known gap sequence results in O(n log² n) worst case.

Space: O(1)

Etymology: Named after Donald Shell.


[[quick_sort]]
=== Quick sort

Properties: Not stable in naive implementation.  In-place.

Algorithm: Choose a random element as pivot. Partition in-place into two arrays: elements smaller than pivot element and elements larger than the pivot element.  The pivot element being between the two partitions. Recurse into the two arrays.

Optimization: Insertion sort is great for small arrays, thus during recursion, when n falls below a certain threshold, switch to insertion sort.

Optimization: Median-of-three pivot: Instead of choosing any pivot, choose the median of the first, middle and last element.  Also sort these three elements before partitioning.  This helps when the input is already nearly sorted.  Compared to choosing a random pivot, we're more likely to get a good partition.  Sorting these three elements affects what pivot will be choosen in the next iteration.

Optimization: 3-way partitioning: We partition into three parts opposed to two: smaller than pivot, equal to pivot and greater than pivot.  The benefit of this optimization is that the algorithm performs better when there are duplicate keys, which is common in practice in many applications.

Time: +O(n^2^)+ worst case, +O(n lg(n))+ average case, best case: (simple partition: +O(n lg(n))+, 3way partition and equal keys: +O(n)+).  Hidden factor in time complexity is in practice quite small.  The +O(n^2^)+ worst case running time might be a problem when input size is large and used in an real-time system or system concerned with security (because malicious user potentially can trigger worst case behaviour).

Space: worst case: (naive: +O(n)+, Sedgewick +O(log n)+).


[[merge_sort]]
=== Merge sort

Properties:  Stable.  Good locality of reference.  Parallelizes very well.  External sorting possible. Good for sequentially accessible data.

Algorithm: 1) Divide the sequence into two equal length subsequences 2) sort the two sequences using recursion, recursion stops at a sequence of one element 3) merge the two sequences, see <<merge_sorted_sequences>>.

Time: O(n lg(n)) worst case & average case & best case.

Space: O(n).

Variant _natural merge sort_:  Time: +O(n)+ best case, the rest remains equal.  Exploits any naturally occurring runs in the input.

Variant _external merge sort_: Motivation: input data does not fit into memory.  Divide the input data into N blocks, each block fitting into memory.  Sort each block with any sorting algorithm and write the result to disk (N files).  Then with ``externally merge sorted sequences'' merge the blocks/files.

Variant _merge sort for linked lists_: *to-do*


[[heap_sort]]
=== Heap sort

Properties: Not stable.  In-place.

Algorithm brief: As selection sort, however the min element is found via an heap.

Algorithm detailed: The input is logically divided into an unsorted part, initially the whole input, followed by a sorted part, initially empty.  The unsorted part is heapified into a max heap.  In each iteration, the first (i.e. max) element is swapped with the last,  thus appending a new element to the left side of the sorted part, and thus also shrinking the heap / unsorted part by one.  Using the heap's sift down operation (or just heapify again the unsorted part), the heap property is re-established.

Time: O(n lg(n)) worst case & average case & best case.  In practice often somewhat slower that quick sort, however it has a better worst case run time.

Auxillary Space: O(1). In-place.


[[bucket_sort]]
=== Bucket sort

Properties: Stable. Not comparison-based.

Restrictions: Assumes that the elements' values are uniformily distributed.  For simplicity, without loss of generality, we here assume within the range [0,1).  The time complexity gets worse if the data is not uniformly distributed as assumed, since certain bucket sequences get much longer than other.

Algorithm: Make an array of k `buckets', where each bucket is a sequence of elements, initially empty.  For each element in the input, insert it into the bucket having the array index k*elementvalue.  Then sort each of the buckets with another sort.  Then produce the final output by concatenating the buckets.

Time: O(n^2^) worst case, O(n+k) average-case and best case.

Auxiliary space: O(n+k).


=== Counting sort (aka histogram sort)

Properties: Not comparison-based.  It assumes that each element is an integer in the range +0--k+, where +k=O(n)+ (If you start off with non-integers, you might be able to map to integers).  Stable sort.

Algorithm: With an array a of size k, for each input element x, increment a[x]. Then for each item (index i) in the array, print the number i a[i] times.

--------------------------------------------------
k=5, input={3,4,2,2,4}
             1s   2s  3s  4s  5s
a           { 0,  2,  1,  2,  0 }
output      {     2,2,3,  4,4   }
--------------------------------------------------

Time: Θ(k+n).

Space: Θ(k+n) or Θ(k), depending on whether the _required_ output array (sorting in-place only with the input array is not possible) is taken into account or not.


=== Radix sort

Sorts n d-digit numbers/strings, where each digit can take up to k possible values.

Properties: Not comparison-based. Stable sort.

First sort/group after least significant digit, then after second least, and so on. The inner sort must be a stable sort, typically counting sort or bucket sort.

Time: Θ(d(n+k)), provided the internally used stable sort has +Θ(n+k)+.  However the hidden constant factor is in practice quite large relative to other sort algorithms.


[[merge_sorted_sequences]]
=== Merge sorted sequences

Algorithm intuition: Imagine n cards within m sorted piles of cards face up.  Take the smallest card yous see and put it on the sorted pile.

Time: Θ(n)

Space: O(n)


=== Externally merge sorted sequences

Given N sorted sequences on disk which do not fit all together into memory.

For each, make a buffered (in memory) input stream.  Make an (buffered) output stream for the result.  Now there are N input streams and 1 output stream and the algorithm works as described in ``merge sorted sequences''.  You might want the I/O to be in separate threads, so the actual algorithm can run while there is IO filling parts of in input stream with new data, or flushing part of the output stream. However, if there are only B blocks/pages of memory available but there are more than B-1 input streams, multiple passes have to be made.


[[BST_sort]]
=== BST sort

Take an implementation of the BST ADT, insert all elements of the input, then do an in-order walk.

When the <<naive_BST>> is used, BST sort does same comparisons as <<quick_sort>>, but in a different order. (where quick sort uses first element as pivot, and then does stable partitioning). When the input is randomly permuted before building the BST, _randomized BST sort_ does again the same comparisons as randomized quick sort choosing its pivot randomly.

=== Partial sorting

Sort the k smallest elements.  Opposed to all elements, as in total sorting.

_partial heapsort_: Heapify to a min heap, then do m extractions.

_quickselsort_: Use quickselect to find k-th smallest element. The way that
algorithm works will leave it at the k-th position. Sort the elements [0,k).

|=====
|                    | time av.       
| partial heapsort   | O(n + k log n)
| quickselsort       | O(n + k log k)
|=====


[[search_in_sorted_array]]
=== Search in sorted array

==== Linear search

A brute force algorithm which finds the element in O(n) time, average and worst-case, and with O(1) auxillary space.

Examine first element, then the second, and so on until the element is found.


==== Binary search

A divide and conquer algorithm which finds the element in O(log n) time, average and worst-case, and with O(1) auxillary space.

Compare the searched key with the middle element.  If it is a match, the search terminates.  If the search key is smaller, recurse in the left half, otherwise recurse in the right half.


==== Interpolation search

Assumes that the elements in the sorted array are uniformely distributed.  However even if this assumption is violated, the algorithm still works, however it no longer has an average running time of O(log log n).

A divide and conquer algorithm which finds the element in O(log log n) average time provided uniform distribution, O(n) worst case time, and with O(1) auxillary space.  It is a specialization of binary search.  Instead of examining the middle element, examine the element which results when interpolating the range given by the first and last array element with the searched key.

Similar to introsort, a variant is to start with interpolation search.  But when remarking that progress is not fast enough, switch to binary search.  This reduces the worst-case runtime to O(log n).


==== Uniform binary search

*to-do*


==== Fractional cascading

*to-do*


==== Fibonacci search

*to-do*


==== Noisy binary search

*to-do*



==== Jump search (aka block search)

Finds the element in O(√n) time and O(1) auxillary space.  First check every k'th element, which effectively divides the array in blocks of length k.  k is typcally √n because that delivers the best runtime performance.  If the search key is equal to the current element, then the search terminates.  If the search key is smaller, search in the previous block using linear search.

Jump search is favorable over binary search when jumping backwards is much more expensive than jumping forward, since jump search at most jumps backward once, while binary search jumps backward O(log n) times.


==== Exponential search (aka galloping search, doubling searchp)

Intended for unbounded arrays, or when it's expected that the element is near the beginning of the array.

An algorithm for finding an element in an sorted, possibly unbounded array.  It finds the element in O(log i) time, where i is the position of the element in the array, or the position where it would be if it's not in the array.

The algorithm first determines the range in which the search key would reside if it were in the list.  For that, every 2^j^-th element is examined and compared with the search key, where j is the iteration of this loop.  When the search key equals the element, the search terminates.  Otherwise when its smaller, continue the first stage, otherwise use binary search in the found range to find the element.


[[order_statistics]]
== Order statistics / medians / selection problem

_Selection problem_: Find the i-th order statistic, i.e. find the i-th smallest element out of an, typically unsorted, set of elements.

The _i-th order statistic_ is the i-th smallest element out of a set of elements.  For example, the _minimum_ of a set of elements is the first order statistic, and the _maximum_ is the n-th order statistic.  A _median_, informally, is the “halfway point” of the set.  When n is odd, the median is unique, occurring at i D .n C 1/=2.  When n is even, there are two medians, occurring at i D n=2 and i D n=2C1.  Thus, regardless of the parity of n, medians occur at i D b.n C 1/=2c (the _lower median_) and i D d.n C 1/=2e (the _upper median_).  For simplicity in this text, however, we consistently use the phrase “the median” to refer to the lower median.

Overview:

|======
|                                  | time av.               | time worst  
|via sort                          | O(sort(n))             | O(sort(n))
|quick select / random             | O(n) almost certain    | O(n^2)
|quick select / median of 3        | O(n)                   | O(n^2)
|quick select / median of medians  | O(n) high const factor | O(n) high const factor
|Introselect                       | O(n)                   | O(n) high const factor
|Floyd–Rivest algorithm            | O(n)                   | ? *to-do*
|======

=== Trivial algorithms

Finding the minimum, i.e. i=1, element can be trivially solved in +O(n)+ time and +O(1)+ auxillary space by iteratively searching through the array for the smallest element respectively.

If the input is preprocessed sorting it first, then we can just access the i-th element in the sorted collection in +O(1)+. Recalling sorting algorithms, the cost of the preprocessing is typically +O(n log n)+, but can be +O(n)+ for certain input. Obviously this might be a good strategy if the collection is static and thus has to be preprocessed only once, and there are more than +O(log n)+ queries (assuming +O(n log n)+ sorting and +O(n)+ for the competing selection algorithm).


=== Quick select

A <<decrease_and_conquer>> algorithm: In each recursion step, choose a pivot and partition the input (of the current recursion step) into a part smaller than the pivot and larger than the pivot respectively.  That delivers the position / index of the pivot, i.e. if all the values were sorted, the pivot would be at the same position.  Then recurse into the left/right part depending on whether i is smaller/larger than the pivot's index.  The base case is either if i is equal the pivot after partitioning, or when the input size is 1.

The best possible pivot is the median (apart from the i-th element, which would directly deliver the solution), since it halves the input.  Like quicksort, the quickselect has good average performance, but is sensitive to the pivot that is chosen.  See the next chapters on strategies how to choose the pivot.


==== Quick select / variant random pivot random

See the previous `common core' chapter. The pivot is chosen randomly.


==== Quick select / variant median of 3

The pivot is the median of the first, middle and last element. Also sort these three elements.


[[median_of_medians]]
==== Quick select / variant median of medians (aka BFPRT)

See the previous `quick select core' chapter. The chosen pivot is an approximate median (remember that the real median would be optimal). It is guaranteed being between 30th and 70th percentiles.

Algorithm to find pivot in array A: Make groups of five elements and find median in each of those (e.g. via insertion sort and taking 3rd element). Then recursively find median of those medians.

Trivia: BFPRT stands for the name of its inventors Blum-Floyd-Pratt-Rivest-Tarjan

*to-do*: Time, auxillary space?


=== Introselect

The idea is to start out with an decrease and conquer selection algorithm that has very good average performance but bad worst case performance, and if it on the fly remarks that it is making bad progress (i.e. steers towards the worst case), switch to choosing a selection algorithm that has optimal worst case perforamnce.

Concretely, starts out with the quick select variant which uses a random pivot, and potentially switches to the median of medians quick select variant.

Examples of possible switching strategies:

- If the sum of partitions so far exceeds the original input size times a constant factor. Only one variable needed to track sum of partitions so far.
- If at any point the last k partitions did not half the input size, where k is some small positive constant. 

Trivia: Introselect is short for introspective selection.

=== Order statistics tree

1) Augment a binary search tree by augmenting each node with the size of its subtree.

Select(i): O(log n) [however that does not include the cost of creating the tree!!]

2) Via min max heap

*to-do*

=== Floyd–Rivest
Functionally equivalent to quickselect, but runs faster in practice on average.

*to-do*


== Strings

References:

- http://cs.au.dk/~cstorm/students/Fogh_Nov2014.pdf


[[string_searching]]
=== String searching / matching problem

Problem: Find all/some occurences of a pattern P in a given text T.  Let _Σ_ be an alphabet (finite set), _T_ a string of length _n_, _P_ a string of length _m_.  Both the pattern and searched text are vectors of elements of Σ.

With preprocessing, idealy we don't want to spend more than O(P) query time, since we at least have to look at the queried string P, and no more than O(T) auxillary space, since the data structure should not be much bigger than the orginal text T.

Solutions:

- _naive string search_: iteratively check at each location in the searched-text.  Time: +O((n-m+1)m)+ worst case, +O(n)+ average case (note that m<=n).

- <<rabin_karp>>

- <<knuth_morris_pratt>>

- <<boyer_moore>>

- With preprocessing: <<suffix_tree>>, <<suffix_array>>, <<fm_index>>

Comparision *to-do*: Small/big T, small/big P, small/big Σ, repeatedly searching in same T, repeatedly searching same P, ...:

- http://programmers.stackexchange.com/questions/183725/which-string-search-algorithm-is-actually-the-fastest


==== Misc string problems

- Predecessor problem: Given k strings T~i~, and search pattern P which is one of these k strings, find P's predecessor / successor according to the lexicographical order of the k strings.

- Associative array ADT where key is a string

*to-do*


[[rabin_karp]]
==== Rabin-Karp

Time: +Θ(m)+ pre-processing, +Θ((n-m+1)m)+ worst case running time,  +O(n+m)+ expected running time.  *to-do*: I don't see why the naive approach should have a worse expected running time, or a worse constant factor if equal

Compute a hash of the pattern.  Iteratively move a window over the search text until the left edge of the window hits the end of the search text.  The window has the same length as the pattern.  In each iteration compute a rolling hash of the window.  If the window-hash matches the pattern-hash, do a regular string comparison between the window and the pattern, and if they still match, the pattern is found.

Popular rolling hash functions for Rabin-Karp:

--------------------------------------------------
static const int q = ...; // a prime where q*radix<INT_MAX
static const int h = pow(d, m-1) % q;

int find(const string& text, const string& pattern) {
   int radix = ...; // aka d.  size of alphabet, e.g. 127 or 255
   int textlen = text.length(); // aka n
   int patternlen = pattern.length(); // aka m
   int patternhash = hash(pattern, m); // aka p
   int texthash = hash(text, m); // aka ts
   for ( int s=0; s<=textlen-patternlen; ++s ) {
     if (patternhash==texthash && text.issubstring(s,pattern))
       return s;
     if (s<textlen-patternlen)
       texthash = rollinghash(texthash, text[s+1], text[s+patternlen+1]);
   }
   return -1;
}

int hash(const string& str, int len) {
    int acc = 0;
    for ( int i=0; i<len; ++i ) acc = (radix * acc + str[i]) % q;
    return acc;
}

int rollinghash(int hash, char ch_out, char ch_in) {
    return (radix*(hash - ch_out*h) + ch_in) % q;
}
--------------------------------------------------


[[knuth_morris_pratt]]
==== Knuth-Morris-Pratt

Time O(n+m) worst case [O(m) preprocessing], O(m) auxillary space

*to-do*


[[boyer_moore]]
==== Boyer-Moore

O(n+m) worst case

*to-do*


[[tries_comparision]]
=== Tries / suffix tree/arrays comparison

For terms and notations, see <<string_searching>>. Additionally, k is the number of stored strings.

The data structure implementing a node of the global tree stores the edges of a global tree node to its global tree node childs.  In other words, for each node in the global tree, its parent node in the global tree uses O(1) space.  Thus O(k) space in total.

|=======
|                                                  | query     | space  | construction | notes
| c. trie / nodes as array                         | O(P)      | O(k·Σ) |              |
| c. trie / nodes as BST ②                        | O(P·lg Σ) | O(k)   |              |
| c. trie / nodes as hash table                    | O(P)      | O(k)   |              | no ordering
| c. trie / nodes as vEB tree                      | O(P·lglgΣ)| O(k)   |              | randomized
| c. trie / nodes as vEB tree and hash table ①    | O(P+lglgΣ)| O(k)   |              | randomized
| c. trie / global tree weight balanced            | O(P+lg k) | O(k)   |              |
| c. trie / ... plus indirection                   | O(P+lg Σ) | O(k)   |              |
|=======

① Use redundantely both vEB tree and hash table.  Normally use the hash table.  However if a query letter is not on an edge, i.e. not not in the hash table, use the vEB tree to find the previous/next child node of the global tree.  Note that the vEB will at most be used once per query.

② We're considering here static problems, thus we can balance the BSTs upon construction because we know all the nodes.

*to-do* is ``tray'' really a data structure distinct from suffix tray which solves the problem of finding a key in a collection of keys? 

|=======
|                      | query     | space    | construction | notes
| suffix tray          | O(P+lg Σ) | O(k)     | ?            |
| suffix tree          | see trie  | see trie | see trie     |
| suffix array         | O(P·lg Σ) | O(n)     | O(n)         |
| suffix array + LPC   | O(P+lg Σ) | O(n)     | O(n)         |
| suffix array + ?     | O(P)      | ?        | ?            | Abouelhoda, Kurtz & Ohlebusch (2004)
| FM index             | ?         | ?        | ?            |
|=======

*to-do* relation radix sort vs trie, ...

References:

- MIT course 6.851 Advanced Data Structures, Spring 2012, Lecture 16. Strings: https://www.youtube.com/watch?v=NinWEPPrkDQ&t=0s&index=16&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf[video],
https://courses.csail.mit.edu/6.851/spring12/scribe/lec16.pdf[lecture notes]


[[trie]]
=== Trie (aka digital tree, radix tree, prefix tree)

See this as an intro to what a trie is. In practice you will use a <<compressed_trie>>, see there for more details.

Is an implementation of the ordered <<associative_array>> ADT. It stores +k+ items (key/value pairs), the stored keys being strings _T~i~_, i=1,...,k, the strings' letters are from alphabet _Σ_.  Internally, there is also the special letter _$_ which represents the end of a string and lexicographically is smaller than any letter in Σ.  A trie is a rooted tree where each edge is labeled with a letter.  Thus child nodes have an order.  A root-to-leaf path represents a string/key, the so reached leaf node the value associated with that key.  The strings derived from paths root to leaf are called _words_, the strings from other paths are called _prefixes_.  Note that the number of leaves equals k.  The maximal number of nodes stored in the tree is |T| = ∑|T~i~|. In query/lookop, _P_ is a _pattern_ (or _query_) searched in the trie.

Since the child nodes have an ordering, an in-order traversal prints the stored keys in order.

A trie can be seen as a DFA (Deterministic finite automaton) without loops (mind: a loop is not a cycle).  A trie can be compressed into an DAFSA (deterministic acyclic finite state automaton).  A trie eliminates prefix redundancy.  A DAFSA additionally also removes suffix redundancy.

Applications: See <<suffix_tree>>

Trivia: The name trie is a pun on re__trie__val.  Originally pronounced it as `tree'.  However, other authors pronounce it as `try', in an attempt to distuinguish it from `tree'.


==== Storing nodes

There multiple ways to actually store a trie.  Subchapter <<tries_comparision>> gives an overview.  The more simple methods are not further explained.  The more complex ones are explained in the following subchapters.  Recall that most of the time, we will use a compressed trie rather than a (uncompressed) trie.


==== Storing nodes, global tree weigth balanced

Each node of the original compressed trie, which has up to |Σ| children, is stored as a weight balanced BST, resulting in a new tree with more nodes.  The weight of a node is the number of its descendand leaves.  Each edge stores wheter it's an edge in the original compressed trie or an edge within the BST within a node of the original compressed trie.  Each edge of the internal BST is labeled as follows: look at the edge's end node. Look that node's initernal BST, take the rightmost edge leaving the internal BST, i.e. an edge of the original compressed trie.  Take the label of that edge.

Construction: Each node of the original tree, having multiple children labeled with letters from Σ, is turned into a BST as follows: Partitionate children into two sets, such that each set has about the same cumulative weight.  Create a root node having these two sets as its two children.  Recurse.

Analysis:  Query takes O(P + log  k) time.  This is because it can be proven that for each traversed edge, we either advance one letter in P or we decrease the number of descendant leaves by at least 1/3.


==== Storing nodes, global tree weigth balanced plus indirection

Cut edges below all maximall deep nodes that have at least |Σ| descendat leaves.  We will thus get a parent tree which has at most n / |Σ| leaves.  Obviously there also at most as many bottom trees.  Store the nodes of the parent tree using lookup table of size |Σ|.  Store the nodes of the bottom trees using weight balanced trees as described in the previous chapter.

Analysis: O(P + log Σ) query time and O(n) space.  Space for each bottom trie is linear. Space for the parent tree becomes O(n) because it has O(n / Σ) nodes, each using O(Σ) space.  Query time in the parent tree is linear.  The size of a bottom tree is O(Σ), thus, being a balanced tree, query time in a bottom tree is O(log Σ).



[[compressed_trie]]
=== Compressed trie (aka radix tree, radix trie, compact prefix tree)

Based on <<trie>>, see there for terms and symbols. Is an implementation of the ordered <<associative_array>> ADT.  A radix tree is a space-optimized trie, where a node with only one child is removed, merging its two adjacent edges into one, which is then labeled with the concatenation of the labels of the two previous edges.  That is each edge is no longer labeled with a single character but potentially with a string.  Typically the nodes/edges do not store the string leading to a child, but the pair (startindex, endindex) into the original text.  Each internal node consequently has at least two children, so there are less internal nodes than leaves.  The [[letter_depth]]_letter depth_ of a node is the lenght of the key/path that leads to it.

[[trie_vs_hash_table]]
Compared to a hash table:

- A trie can have (depending on how nodes are represented) predictable look-up time +O(k)+.  A hash table has +O(k+n)+ time complexity worst case:  O(k) is used to generate the key, looking up the key is O(1) average but O(n) worst case.
- A trie does not need a hash function
- A trie can provide an ordering of the entries by key.  I.e. a trie supports ordered traversal.
- Locality is worse for a key, since it randomly accesses the nodes.
- A trie typically uses more space than a hash table, since the graph uses quite a lot pointers.

Compared to a binary tree:

- Binary tree has +O(k * (lg n))+ time complexity for look-up, insertion, deletion.  Mind that comparing a key requires +O(k)+; in many times the worst-case occurs, due to long prefixes towards the leaves.

References:

- https://courses.csail.mit.edu/6.851/spring12/scribe/lec16.pdf


[[suffix_tree]]
=== Suffix tree (aka PAT tree, suffix trie)

Based on compressed trie, see there for terms and symbols. Given a text T, append $ (see <<trie>>), then store all suffixes of T in a (compressed) <<trie>>. The value associated with a leaf is the starting position of the suffix in T.

When given multiple documents T^i^, i=1, 2, ..., n, append $~1~, $~2~, ... and $~n~ to each T^i^ respectively, and then throw all suffixes of each document into the suffix tree.

The suffix tree contains O(T) nodes, thuse O(T) space needed (using reasonable representations of the trie, see there).

Details: Seeing a letter as a string of size one, all edges in a compressed trie have strings on them. Such a string can be stored in O(1) by storing only the indicies (within T) of its first and last letter.

Applications:

* Find (all) occcurences of pattern P in text T. Create suffix tree for T. Using P as key delivers subtree whose leaves corresponds to all occurences of P in T.

* Find first i occurences of pattern P in text T: Augment the leave nodes so they build a linked list, and augment internal nodes by a pointer to its leftmost descendant leaf.

* Find number of occurences of pattern P in T: Augment internal nodes in the suffix tree with the number of leaves. Use P as key, the found node thus delivers number of leaves, which equals number of occurences.

* Find longest substring that occures twice in P: Augment internal nodes with their <<letter_depth>>. Then search the internal node with the largest letter depth in O(T) time.

* Find longest substring that occures in multiple documents T^i^: Similar to above, but look for the internal nodes with maximum letter depth with greater than one distinct $~x~ below.

* Longest common prefix of two substrings in T in O(1) time: Take the two leaves corresponding to the indexes where the substring start, <<LCA_problem,find LCA>> in O(1) time, and the letter depth of the found node is the answer.

* Find all occurences of T[i:j]: Instead of, as in a normal search, finding the node from the root in O(j-i) time, find the (j-i)the ancestor of leaf i in O(1) time (via an _LA_query_)


[[suffix_array]]
=== Suffix array (SA)

A suffix array is an index into a string T.

Given a string T of length n over alphabet Σ.  The last character of T is a special character $ ∉ Σ which is lexicographically smaller than all characters in Σ.  Conceptually sort all suffixes of T.  The cell SA[i] in the suffix array SA provides the position within T at which the i-th sorted suffix starts.

--------------------------------------------------
      sorted             T = banana$    
      suffixes               0123456
 row  of T       SA LCP      
  0   $          7  -
  1   a$         5  0
  2   ana$       3  1
  3   anana$     1  3
  4   banana$    0  0
  5   na$        4  0
  6   nana$      2  2
--------------------------------------------------

To query a string P in T:

_trivial binary search_: O(P log n) query time.  Do a binary search of P in T via SA.

_LPC + binary search_: O(P + log n) query time.  As a preprocessing step, construct longest common prefix (LCP) array which stores the length of two consecutive suffixes.  LCP[i] = |i-th suffix| - |(i-1)-th suffix|. With the information provided by the LCP array, individual comparisons during the binary search can compare fewer characters than the trivial binary search.  Algorithm exists which construct LCP together with SA in O(n) time.

Constructible in O(n log n) time with simple methods and O(n) time with complex methods.


=== (Suffix) tray

Is a combination of a suffix tree and a suffix array,

*to-do*

References:

- https://courses.csail.mit.edu/6.851/spring07/scribe/lec09.pdf

- Suffix Trays and Suffix Trists: Structures for Faster Text Indexing: https://cs.nyu.edu/cole/papers/suffix-trays.pdf


=== DAFSA as data structure
Represents a finite (since it has no cycles) set of strings aka keys.  Single source vertex.  Each edge is labeled by a letter / symbol.  Each vertex has at most one vertex which is labeled with a given letter.  The accepted strings are formed by the letters on paths from the source to any sink / NIL vertex.

Can be seen as an compact form of a trie.  Uses less space than a trie.  A trie eliminates prefix redundancy.  A DAFSA additionally also removes suffix redundancy.  A trie can store attributes for each string aka key, whereas a DAFSA cannot.

Is an implementation of the ADT <<associative_array>>.


[[burrows_wheeler_transformation]]
=== Burrows-Wheeler transformation (BWT)

The _Burrows-Wheeler Transform_ (BWT) is a way of reversibly permuting the characters of a string T into another string BWT(T).  It has applications in indexing, see FM Index, and in compression.

Given a string T of length n over alphabet Σ.  The last character of T is a special character $ ∉ Σ which is lexicographically smaller than all characters in Σ.  The Burrow-Wheeler Transform of T, denoted BWT(T) (or just BWT) is a string of length n.  It's construction is described in the following.  Note that the BWT is the only thing which is actually stored.  The other introduced things are just for illustration.

Let the Burrows-Wheeler Matrix BWM(T) (or simply BWT) be the matrix constructed by first taking every possible rotation of T, row by row, and then sort it by row.  The first column is denoted F, the last column is denoted L.  The Burrows-Wheeler Transform, denoted BWT(T) (or simply BWT), is given by L.  Note that given a row i, L[i] precedes F[i] in T.  Also note that the suffixes given by the <<suffix_array>> SA(T) is exactly the same as the content of the BWM up to inclusive the $.

Example of many things introduced in the following:

----------------------------------------------------------------------
 T = bananas$   BWM: Burrows-Wheeler Matrix
     01234567   F: first column of BWM, L: last column of BWM,
                BWT = L: Burrows wheeler transform of T,
                SA: suffix array, CAS: compressed suffix array,
                LF: LF Mapping, C[l]: number of letters smaller
                than a given letter l
 Suffixes       
 given by        BWM                                  |
 SA = BWM      /------\           rank  rankall       |        
 up to $   row F      L  SA CAS LF R    a b . n . s . | {$,Σ}    C
                                                      |
 $         0   $bananas  7  7   7  0    0 0 0 0 0 1 0 | $     1  0
 ananas$   1   ananas$b  1  1   4  0    0 1 0 0 0 1 0 | a     3  1
 anas$     2   anas$ban  3  -   5  0    0 1 0 1 0 1 0 | b     1  4
 as$       3   as$banan  5  -   6  1    0 1 0 2 0 1 0 | .     0  5
 bananas$  4   bananas$  0  0   0  0    0 1 0 2 0 1 0 | n     2  5
 anas$     5   nanas$ba  2  -   1  0    1 1 0 2 0 1 0 | .     0  7
 nas$      6   nas$bana  4  4   2  1    2 1 0 2 0 1 0 | s     1  7
 s$        7   s$banana  6  -   3  2    3 1 0 2 0 1 0 | .     0  8
----------------------------------------------------------------------

__Rank of L[i] / R array__: Is a building block used in the following.  Given row i, determine rank of character at L[i] = BWT[i].  Solution 1)  Precompute in O(n) time an auxillary array R of size n, where R[i] stores the rank of character L[i]. Rank queries of character L[i] can then be answered in O(1) time by simply returning R[i]. Solution 2) When storing BWT with a <<wavelet_tree>>, rank queries cost O(log Σ) time.

__Number of letters smaller than a given letter l / C (counting) array__: Is a building block optionally used in the following. Given a letter l ∈ {$, Σ}, return the number of letters in T which are smaller than l.  Can be precomputed in O(n) time by scanning L, storing the result in an array C of size |Σ|+1.  L is trivially defined by C and vice versa, see also LF mapping.

__LF Mapping__: Is an essential building block used in most Burrows-Wheeler Transformation related algorithms.  Given row i, determine row j such that F[j] has same rank as L[i].  In less formal words, given L[i], find L[j] that preceeds L[i] in T.  j = LF(i) = C[L[i]] + R[i].  Rational: As described in greater detail further below in this chapter, the ranks of characters remain in the same order, within F and L.  Note that F is given by sorting L, or in other words, by sorting the letters occuring in T and then repeat each letter by its occurence count.  Row j is then given by the row where character L[i] first appears in F (possibly precomputed in array C), plus the rank of character L[i] (possibly precomputed in array R).

__(Re)construct T from BWT__: Start with empty result string T and in first row i = 0. Iteratively do n times (or until LF(i)=$): Prepend L[i] to T. i = LF(i).

__Construct BWT from T__: The naive way to construct BWT is via the Burrows-Wheeler Matrix (BWM), as described in the beginning of this chapter.  However that is obviously wastefull both in space and in time.  Better is to first construct the suffix array SA in O(n) time, see there, and the construct the BWT using the SA in O(n) time, see following point.

__Construct BWT from SA__: For i=0 to n(inclusive): if SA[i]>0 then BWT[i] = T[SA[i]-1], else BWT[i] = $. Obviously O(n) time.

__Construct SA from BWT__: Basically the same as constructing T from BWT. Start with j = |T| and in first row i = 0. Iteratively do n times (or until LF(i)=$): SA[i] = j--. i = LF(i).

[[compressed_suffix_array]]
__Compute SA[i] from BWT / compressed SA (CAS)__: Say we actually would like the complete SA array, but don't want to spend the space of a complete SA array.  A use case is the <<fm_index>>.  Store only every k-th SA element, counted in the order the LF mapping, starting at row 0, does access rows.  When quering SA[i], set j = i, do LF Mapping, modifying j, until SA[j] is a precomputed one.  Return SA[j] + number of LF Mapping steps. Is used within certain variations of <<fm_index>>. *to-do* more details what data structue to use. It can't be just a trivial array, due to the erratic jumping of the LF Mapping.

__Search pattern P in T__: See <<fm_index>>

When looking at F and L, the ranks of a given character c are the in the same order.  The following illustrates this.  In  F, all the charcters c are consecutive.  Regarding these rows, the suffixes BWM[...,1:n-1] (0-based index) are in lexicographical order.  The corresponding suffixes BWM[...,0:n-1] are also in lexicographical order.  Thus in the same order.  Thus regarding these rows, BWM[...,0] = F[...] and BWM[...,n-1] = L[...] are also in same order.

--------------------------------------------------
  F         L
  ..         
  c0 X  .. ..
  c1 Y  .. ..
  c2 Z  .. ..
  ..        
  ..
  X  .. .. c0  
  ..
  Y  .. .. c1
  ..
  Z  .. .. c2
  ..
--------------------------------------------------

Applications:

- compression:  In the BWT, there's a tendency that runs of the same character are suprisingly long.  Thus run-length encoding works well to compress the BWT string.  An intuition why this runs are suprisingly long may give the following example:  Consider columb F, the rows starting with n, which naturally will be consecutive.  The corresponding cells in L will be the consecutive charactes in BWT.  Since in the English language, only a few characters can come before an n with a relative high chance, there will be long runs of these characters in the BWT. (*to-do* so BWT plus run-length encoding only works well for human languages, but not for abritrary languages in the computer science sense?)

- indexing: See <<fm_index>>

Trivia: Named after the inventors Michael Burrows and David Wheeler.


References:

- Burrows-Wheeler Transform and FM Index: https://www.youtube.com/watch?v=4n7NPk5lwbI

- Introduction to the Burrows-Wheeler Transform and FM Index: http://www.cs.jhu.edu/~langmea/resources/bwt_fm.pdf

- Parallel Lightweight Wavelet Tree, Suffix Array and FM-Index Construction: https://people.csail.mit.edu/jshun/dcc2016.pdf

- https://www.youtube.com/watch?v=kvVGj5V65io

- https://people.unipmn.it/manzini/papers/focs00draft.pdf[Opportunistic Data Structures with Applications]

- FM-Indexes and Backwards Search: http://alexbowe.com/fm-index/

- A tutorial on Burrows-Wheeler indexing methods: http://blog.thegrandlocus.com/2016/07/a-tutorial-on-burrows-wheeler-indexing-methods

- A Wavelet Tree Based FM-Index for Biological Sequences in SeqAn: http://www.mi.fu-berlin.de/wiki/pub/ABI/FMIndexThesis/FMIndex.pdf


[[fm_index]]
=== FM Index

A space efficient index into a string T.  Based on the <<burrows_wheeler_transformation>>.  At the core consists only of the Burrows-Wheeler Transform (BWT), i.e. the last column L of the Burrows-Wheeler transformation matrix (BWM).  Usually also the suffix array SA or a variation of it is stored.  The BWT string might be stored using special data structures, e.g. wavelet trees, and optionally auxillary data structers might be used to improve query time.

Search pattern P in T:  We will iteratively try to match a longer suffix of P, starting at P's last character.  In the following, the range of selected rows in L = BWT represent the matches found so far.  Initially, select the range of rows where F starts with the last character of P.  I.e. Plastchar = P[|P|-1], rangefirst = C[Plastchar], rangelast = C[Plastchar+1]-1.  Set i = |P| - 2.  Iteratively, decreasing i, narrow the range of rows by taking one more character P[i] of P into account, progressing from P's back towards P's front.  In each iteration, within the current range of rows, determine the first and last occurence of P[i] in L.  Via LF mapping, that defines the new range of rows.  The algorithm stops when the range of rows becomes empty, which means P does not occur in T.  Otherwise, after iterating over all P's characters, the remaining range of rows represents the found matches.

The step of narrowing down the range of selected rows was above described as `find first/last occurence of P[i] within selected range of rows' plus `LF Mapping of that result'.  These two steps can at the core be combined in a single range query.  Recall that the core step of the LF Mapping is to find the rank of a given character at a given position in L.  Thus regarding narrowing down the the beginninig of the range of rows, the overall task is to find the rank of P[i] at the row just before the range of rows, and then add one, to get the rank of the first occurence of P[i] within or after the range of rows.  Analogous for the end of the range of rows.

How to narrow down range of selected row in each iteration:

__Brute force__:  Scan L within range of selected rows to find first and last occurence of P[i].  Once from the beginning and once from the end.  Then do an LF Mapping with each of the two results.  rangefirst = LF(firstoccurence), rangelast = LF(lastoccurence).

__Rankall matrix__: Precompute a |T| ⨯ |Σ| matrix denoted rankall, where rankall[i,c] delivers the rank of character c at row / position i in L.  rangefirst = C[P[i]] + rankall[rangefirst-i, P[i]], rangelast = C[P[i]] + rankall[rangelast, P[i]]. O(1) query time and O(T·Σ) auxillary space.  The chapter <<burrows_wheeler_transformation>> has an illustratory example of the rankall matrix.

__Sparse/compressed rankall matrix__: As before, but only store every k-th row.  What is missing can be recomputed on the fly analgous to the brute force scheme explained above.

__Store L=BWT as wavelet tree__: As with the rankall matrix, only that now the wavelet tree can directly answer the same range queries as the rankall matrix did.  O(log Σ) query time and O(1) auxillary space.

At the end, when having found a range of rows representing found matches, how to report the corresponding indexes into T:

_Suffix array SA_: The suffix array SA directly contains the required indexes.  Report SA[firstrow] through SA[lastrow].

_Sparse/compressed suffix array CSA_: Store only every k-th element of the suffix array. Via LF Mapping the suffix array elements inbetween can be recomputed.  See <<compressed_suffix_array>>.

Variations: Alphabet friendly FM Index (combines with wavelet trees): https://pdfs.semanticscholar.org/59a7/f5aae26198f41053a392b25a5ecc66485d13.pdf

Trivia: The name stands for Full-text index in Minute space.  This is according to the authors Ferragina and Manzini.  Note that FM also corresponds to their initials ....

References:

- See <<burrows_wheeler_transformation>>


=== Succinct strings

[[wavelet_tree]]
==== Wavelet tree

Succinctly store a string. The data structure is based on a tree, each node stores a <<bit_vector>>.  Here Σ denotes the alphabet of characters actually used in the string, opposed to the universe of known characters.  Supports rank~c~(i) in O(log Σ), and fast select~c~(i) queries.

------------------------------------------------------------
Note that only the bitvectors are stored in a node.
The characters are written down just for illustration.

               wavelettree  Σ={ael|rtvw}    paths:
               10100011100                  a = 00
             0/           \1                e = 010
Σ={a|el}  aeleee       wvttr  Σ={rt|vw}     l = 011
          011111       11000                r = 100
              |0     0/     \1              t = 101
Σ={e|l}   eleee      ttr    wv Σ={v|w}      v = 110
          01000      110    10              w = 111
------------------------------------------------------------

The tree is recursively defined as follows: Take the alphabet actually used in the current string.  The root node naturally takes the input string.  Devide that alphabet into two equally sized parts.  Encode the string using a bit vector, one bit per character.  0 for a characters in the first part of the alphabet, 1 for characters in the second part.  Pass on a string composed of only the characters in the first part to a newly created left child.  Analogously for the right child.  The recursion stops if a child's alphabet would consist of only a single letter.

The bit vector is the essence of what is stored per tree node. From this high level point of view, we don't care about further details of how to practically store the tree.  See <<bit_vector>> for variants of storing bit vectors.

Note that the shape of the tree is not really dependent on the actual content of the string; that is, it may be dependend on the character frequencies.

char_at(i): Returns character at character position/index i. *to-do*

rank~c~(i): Returns number of occurences of the character c up to and inclusive position/index i. *to-do*

select~c~(i): Returns the position/index of the i-th character c. *to-do*

find(P): Find pattern P in the string.  http://alexbowe.com/wavelet-trees/ says it's possible in O(P log Σ).

Analysis: *to-do*

References:

- http://alexbowe.com/wavelet-trees/

- https://www.youtube.com/watch?v=sLeNRREuZsM and the following videos in the series

- https://www.youtube.com/watch?v=cs9MbRdD50s 1:22:34, https://www.youtube.com/watch?v=fm-YJ133bAM&t=255s


==== Succincter

References:

- https://people.csail.mit.edu/mip/papers/succinct/succinct.pdf[succincter]. Store string of n elements/characters of alphabet Σ using space close to information-theoric minimum of n·log~2~(|Σ|) bits.


[[randomized_algorithms]]
== Randomized algorithms

See also subchapter <<randomized_online_algorithms>>.

Model one: *to-do*

Model two: *to-do*

S(x) : 1 if A(x)=F(x), 0 otherwise. S for same.

|=====
| Pr(S(x)) ≥ ε ∧ Pr(A(x)=?) + Pr(S(x)) = 1 | 0 < ε ≤ 1 ∧ ∀ inputs x | Las Vegas
| A is Las Vegas ∧ lim~\|x\|→∞~ Pr(S(x)) = 1 |  | Las Vegas*
| Pr(A(x) = 1) ≥ 1/2 for ∀ x ∈ L ∧ Pr(A(y) = 0) = 1 for ∀ y ∉ L | For decision problems of language L | 1MC
| A is 1MC ∧ lim~\|x\|→∞~ Pr(A(x) = 1) = 1 |  | 1MC*
| Pr(S(x)) ≥ 1/2 + ε  | 0 < ε ≤ 1/2, ε is independent of input ∧ ∀ inputs x | 2MC
| Pr(S(x)) > 1/2  | ∀ inputs x | MC
|=====

*to-do* Why constant 1/2 in monte carlo algorithms? Again, in general its just some constant, right? If its exactly 1/2, we get no information at all, i.e. we have a problem. If it's less than 1/2, we just inverse the logic and get > 1/2 again.

References:

- Book "Design and Analysis of Randomized Algorithms"


=== Las Vegas algorithm

Given a function F, a randomized algorithm A is called _Las Vegas algorithm_ if it can return `?' meaning ``I don't know the correct answer'' and it holds that CA = Pr(A(x)=F(x)) ≥ ε and Pr(A(x)=?) + CA = 1 for every input x and 0 < ε ≤ 1.  In plain English, it either returns the correct answer or optionally ?, but never an incorrect answer.  In other words, it gambles with resources used for computation, but not with correctness.  In the case that ? answers are _not_ allowed, i.e. ε = 1, definitions vary wether the algorithm is allowed to take infinite time or not.  If A is an Las Vegas Vegas Algorithm and lim~\|x\|→∞~ Pr(A(x)=F(x)) = 1, then it is called a _Las Vegas* algorithm_.

If the algorithm is allowed to take infinite time, any Las Vegas algorithm which is allowed to return ? can be converted to one which is not allowed to return ? by executing it repeatedly until the answer is not ?.

A Las Vegas Algorithm which is not allowed to return ? can be converted to one which is allowed to return ? by terminating early.  More generally, the ε can always be made smaller, as long as 0 < ε, in order to trade lower execution time for higher chance of getting ? answers.  Note that altough execution time varies, that variation is still independent of the input size, i.e. its hidden in the constant factor of the asymptotic time complexity.

Las Vegas to Monte Carlo: A Las Vegas algorithm which is allowed to return ? is also a Monte Carlo algorithm.

Examples: quick sort, quick select


=== Monte Carlo algorithm

Given a function F, a randomized algorithm A is called _Monte Carlo algorithm_ (or _MC algorithm_) if Pr(A(x)≠F(x)) < ε, for every input x and 0 < ε ≤ 1.  In plain English, it is allowed to return an incorrect answer with a certain bound on the probability.  In other words, it gambles with correctness,  and possibly also with ressources used for computation.

For the case of decision problems, a randomized algorithm A is called _false-biased Monte Carlo algorithm_ (or _on-sided-error Monte Carlo algorithm_ or _1MC algorithm_) if Pr(A(x)=F(x)) = 1 for every false F(x) and Pr(A(x)=F(x)) ≥ 1/2 for every true F(x).  In other words, it's always correct when it returns false.  If A is an 1MC Algorithm and lim~\|x\|→∞~ Pr(A(x)=F(x)) = 1, then it is called a _1MC* algorithm_.

*to-do* be sure to write down definition correctly. Its really confusing.

*to-do* 1) Book says: "Wo ist der Unterschied zwischen den 2MC-AIgorithmen und den
MC-AIgorithmen?" and then explains. But I didn't got the final conclusion. 2) Probably the same question: why 1/2, opposed to some other constant?



[[online_algorithms]]
== Online algorithms

An online algorithm is called _c-competitive_ if it there is a constant c for which the following conditition holds:

online minimum problem: cost(ALG(I)) ≤ c·cost(OPT(I)) + α for all inputs I +
online maximum problem: gain(OPT(I)) ≤ c·gain(ALG(I)) + α for all inputs I

Unfortunately there is no commonly used term for the factor c~I~ given a specific input I; even the notation c~I~ is made up by me.  I make up the term `_input dependent cost factor_'.  Also there is no term for the constant c.  c is an upper bound on the input dependend cost factor.  If there is no such c, the algorithm is called _not competitive_. The smallest c ≥ 1 for which that inequality is true is the _competitive ratio_ of the algorithm.  In other words the competitive ratio is the minimum of the set of valid constants c (i.e. the minimum of the set of upper bounds on the input dependend cost factor).  It is the supremum of the input dependend cost factor.  Intuitively it's a measurement of the online algorithm's quality.  If the constant offset α is zero, the algorithm is said to be _strictly competitive_.  An online algorithm is called _strongly c competitive_ if its competitive ratio equals the best that is achievable by any online algorithm for the problem at hand.  If c=1 and α=0, the online algorithm is _optimal_.  If looking only at a specific input I, we speak of the _performance_ of ALG on I. (*to-do* 1) term for c for a given instance I. 2) performance's meaning is inversed, no? a larger c is bad, but a larger performance is good.  3) not competitive). The notion of having the constant α allows an algorithm to achieve a good c for long inputs I, even if that algorithm is bad for short inputs I.  Using the paging problem as example, an _conservative algorithm_ has a cost of at most n  (n is the number of available pages) for any sequence of consecutive requests that involve (up to) n distinct pages. In other words, a conservative algorithm only updates its current hypothesis when making a mistake.

When analysing online algorthms, we're almost always only interested in the worst case, almost never in the average case.  We want to provide guarantees.

References:

- Book ``An Introduction to Online Computation: Determinism, Randomization, Advice'', D. Komm.

- Extracts of the above book as lectures notes: http://www.ita.inf.ethz.ch/~dkomm/lectures/online-algorithmen.pdf


[[randomized_online_algorithms]]
=== Randomized online algorithms

See also chapter <<randomized_algorithms>>.

A _randomized online algorithm_ has besides the input I ∈ 𝓘 additionally the separate input Φ which is a random binary string, all bits are mutually independent and have a uniform probability distribution of 1/2.  Thus for a given input I, due to random binary string Φ, the costs may vary.  The common approach is to consider the expected costs.  A randomized online algorithm is _c-competitive in expectation_ if the following condition holds:

online minimum problem: E[cost(ALG(I))] ≤ c·cost(OPT(I)) + α for all inputs I +
online maximum problem: gain(OPT(I)) ≤ c·E[gain(ALG(I))] + α for all inputs I

The smallest c for which the above condition holds is called _expected competitive factor_.

If for a given online problem there exists an optimal randomized algorithm, then there exists also an optimal deterministic online algorithm. (*to-do* understand. Probably the key thing is that randomized online algorithm are mostly about being robust against malicious advesaries trying to provoke worst case behaviour)

There are diffrent models of adversaries: The _oblivious adversary_ knows what algorithm I am running, but he sees none of the coin flips.  It's the adversary model commonly used.  The _fully adaptive adversary_ additionally also sees the coin flips. But that is uninteresting from a randomized perspective, because then the algorithm could as well be deterministic. The _adaptive adversary_ is somewhere inbetween. It knows the previous coin flips, but not the future flips. So it's an online algorithm itself.
exists also an optimal deterministic online algorithm. (*to-do* understand. Probably the key thing is tha

=== Page replacement algorithms

A page replacemenet algorithm decides which pages of a cache to evict (page out or swap out). E.g RAM (slow) and Cache (fast), or Swap on disk (slow) and virtual memory (fast).  A cache _miss_ is when a requested page is not in the cache. Updating cache from data is called _evicting_ (kicking out a page from the cache) and _fetching_ data into the now free page.

- No deterministic algorithm is k-competitive.

- No online algorithm is better than k-competitive. I.e. k is a lower bound for the competitive ratio of any online algorithm.

Page replacement strategies:

- _LRU_ (_least recently used_): Evict least recently used. Is a conservative strict k-competitive algorithm.  Experimentally shown to be better than FIFO on average.

- _FIFO_ (_first in first out_): Evict oldest-loaded page. Is a conservative strict k-competitive algorithm.

- _LFU_ (_least frequently used_): Evict the page that has been requested least frequently.

- _LFDT_ (_longest forward distance_) (or _OPT_ (_offline optimal_) or _MIN_): Evict page to be used farthest in the future. A greedy algorithm. Proofably optimal. Cost O(n/k) (n accesses). Proof: Only very k accesses there's an evict.

Applications:

- Cachings at all levels of the memory hierarchy


[[graph_theory]]
== Graph theory

References:

- http://en.wikipedia.org/wiki/Glossary_of_graph_theory

- ETH course 401-3052-10L / 401-3052-05L Graph Theory, Lecture Notes ``Graph Theory'', Benny Sudakov: https://moodle-app2.let.ethz.ch/mod/resource/view.php?id=227878 (needs login)


=== Fundamental definitions

This chapter explains graphs as a mathematical concept. For the corresponding abstract data type, see <<graph_adt>>.  If theorems or similar are labeled with numbers, they are according to the Book ``''

A _graph_ G=(V,E) is given by a set of _vertices_ V (aka _nodes_ or _points_) and a set of _edges_ E (aka _lines_), each edge being an pair of elements from V.  The _order_ of a graph G, denoted by |G| is the number of its vertices, i.e. |V|.  The _size_ of a graph G, denoted by ‖G‖, is the number of its edges, i.e. |E|.

An _undirected graph_ is one in which edges are an unordered pairs; the edge ++(a,b)++ is identical to the edge ++(b,a)++.  An _directed graph_ (aka _digraph_) is one in which edges are ordered pairs.  Such an directed edge is also called _arc_, _directed edge_ or _arrow_.  An _outgoing edge_ (_incoming edge_) of vertex v is a directed edge starting (ending) at v. A _successor_ (_predecessor_) is vertex that comes after (before) a given vertex in a directed graph. A _direct successor_ (_direct predecessor_) is an adjacent successor (predecessor).  A _loop_ is an edge which starts and ends on the same vertex.  A _link_ is an edge with two different ends.  _parallel edges_ (aka _multiple edges_ or a _multi-edge_) share the same pair of vertices, and in case of directed graphs, point in the same direction.  _antiparallel edges_ share the same pair of vertices and point in opposite directions.  In an undirected graph the two vertices of an edge are said to be _adjacent_ (or _neighbors_) to each other; in an directed graph only the destination vertex of an edge is adjacent to the source vertex.  Two edges are called _incident_ (or _adjacent_) if they share a vertex.  Pairwise non-adjacent vertices or edges are called _independent_.

The _degree_ (aka _valency_) d~G~(v)=d(v) of a vertex v in an undirected graph is the number |E(v)| of edges incident with v, with loops counted twice. In directed graphs, _out degree_ (_in degree_) is the number of outgoing (incoming) edges. A vertex of degree 0 is called _isolated_ (or _disconnected_), a vertex of degree 1 is called an _end-vertex_.  The number δ(G) := min { d(v) | v ∈ V } is the minimum degree of G, the number Δ(G) := max { d(v) | v ∈ V } its maximum degree. If all the vertices of G have the same degree k, then G is _k-regular_, or simply _regular_.  The _average degree_ d(G) of G is the average degree of G's vertices.

A _simple graph_ is an undirected graph that has no loops (mind: a loop is not a cycle) and no parallel edges.  A _trivial graph_ is a graph of order 0 or 1.  A _multigraph_ (or _general graph_) is a graph that is not simple.  Alternatively: a multigraph is allowed to have parallel edges.  A _sparse_ graph is one for which +|E|+ is much less than ++|V|^2^++.  A _dense_ graph is one for which +|E|+ is close to ++|V|^2^++.  An _empty graph_ (or _edgeless graph_) has no edges.  The term _null graph_ is ambigously used to either denote the graph ∅=(∅,∅) with no vertices and no edges, or as a synononym to empty graph.  The _singleton graph_ is the empty graph with one vertice.

A _vertex cover_ is a set of vertices such that each edge of the graph is incident to at least one vertex of the set.  An _independent set_ (aka _stable set_) is a set of vertices, no two of which are adjacent.  Given a simple Graph G, it's _complement_ graph has the same vertices, but only an edge between any two vertices iff they are not adjacent in G.

A _walk_ is a set of consecutive edges.  A _closed walk_ is one where the first and last vertices are the same, an _open walk_ is one where they are different.  A _trail_ is a walk with distinct edges.  A _circuit_ is a closed trail.  A _path_ is a walk with distinct vertices (which implies distinct edges), except possibly the first and the last.  Some authors call that a _simple path_, and use the term path as a synonym to walk.  Given a subgraph H of graph G, we call a path P an _H-path_ if it meets H only exactly at its two end vertices, i.e. no other common vertices, and no common edges.  A _cycle_ is a path in which the first and last vertex are adjacent.  An _open path_ is a path in which the first and last vertex are not adjacent.  Two paths are _vertex-independent_ (aka _vertex-disjoint_) if they do not have any vertices in common (*to-do* some sources are clear that they only mean inner vertices, other sources seem to include also end vertices).  Two paths are _edge-independent_ (aka _edge disjoint_) if they do not have any edges in common.  The _path weight_ is the sum of the weights of its constituent edges.  The _length_ of a path is sometimes defined as the number of edges on the path or as synonym to path weight.  The [[shortest_path]]_shortest path_ from vertex u to v is any path with minimal path weight.  See also <<shortest_path_problem>>.  The _shortest path weight_ is the path weight of the shortest path; defined to be infinite if there is no path, and often defined as -infinite it contains a negative-weight cycle.  Any sub path of a shortest path is itself a shortest path.  The _distance_ between two vertices is the length of the shortest path.  A _(pre/in/post)order tree walk_ does the key action with the current node's payload before/between/after recursively calling the children.

A graph is _edge-maximal_ with a given graph property if G has the property, but no Graph resulting from adding an (non-parallel) edge does.

Given a graph G, a _subgraph_ of G is a graph, each of whose vertices and edges belong to G.  Given a graph G, an _induced subgraph_ is a subgraph of G, whose edge set consists of all G's edges that have both endpoints in the subgraph. A _super graph_ is formed by adding vertices, edges, or both to a given graph.  If H is a subgraph of G, then G is a supergraph of H.

A graph is called _bipartite_ if there is a partition of its vertices into two sets V~1~ and V~2~ such that each edge is between V~1~ and V~2~.  K~n,m~ is the _complete bipartite_ graph where n = |V~1~| and m = |V~2~| and E contains every possible edge between V~1~ and V~2~.

A subgraph which contains every edge is called _spanning_.  A _spanning tree_ of an undirected graph G is a subgraph that is a tree which includes all of the nodes of G.  A [[MST]]_minimum spanning tree_ (aka _MST_) is a spanning tree of a graph G with the minimal total weighting for its edges.  See also the <<MST_problem>>.  The equivalent to a MST in an directed graph is a _spanning arborescence of minim weight_ (aka _optimum branching_).

[[DAG]]
An _acyclic graph_ (aka forest, see chapter forest) is a graph with no cycles.  A _directed acyclic graph_ (_DAG_) is a graph with no directed cycles.  Given a directed edge C->P, C is the _child_ and P the _parent_. Nodes reachable from C are C's _ancestors_, nodes which can reach P are P's _descendants_.  Whether or not a node is it's own ancestor/descendant is not defined across literature. CLRS say yes.  The _lowest common ancestor_ (_LCA_, aka, less accurately, _least common anchestor_) of two nodes x and y is the first common ancestor in topo order.


=== Misc. theorems / lemmas

For any graph G on n vertices with adjacency and indicence matrices A and B, we have BB^T^ = D + A where D is a diagonal matrix where the diagonal is the degree of vertices [v~1~, ..., v~n~]. [Fact 1 in ``Graph Theory'']

The sum over all vertex degrees equals 2|E|. Every graph has an even number of vertices of odd degree. [Proposition 1.22 and Corollary 1.23 in ``Graph Theory'']

Every graph with minimum degree δ ≥ 2 contains a path of length δ and a cycle of length ≥ δ+1. [Proposition 1.32 in ``Graph Theory'']

Every graph with minimum degree δ ≥ 2 contains cycles of at least δ - 1 different lengths. [Remark 1.33 in ``Graph Theory'']

A graph with n vertices and m edges has at least n - m connected components. [Proposition 1.38 in ``Graph Theory'']


[[tree_graph_theory]]
=== Tree (graph theory)

A _tree_ is an undirected graph in which any two nodes are connected by exactly one path (which then naturally is a simple path).  Alternatively: an undirected connected acyclic graph.  Alternativly:  An undirected connected graph where every edge is a bridge.  Thus it's always undirected, acylic, connected and bipartite.  Note that an arborescence is not a connected graph (consider a root with two childs; the two childs are not connected).  In informatic context, the term tree is often used for what we call here an directed rooted tree.  A _rooted tree_ is a tree in which one node has been designated the root.  An _arborescence_ (aka _directed rooted tree_ or _out-tree_) is a directed rooted tree in which all edges point away from the root.  An _anti-arborescence_ (aka _in-tree_) is an arborescence where all edge directions are reversed.  A _forest_ is a disjoint union of trees.  Alternatively: an acyclic undirected graph.  An _ordered tree_ (aka _plane tree_) is a rooted tree in which an ordering is specified for the children of each node.  A _poly tree_ is a directed acyclic graph which would be a tree if it's edges were undirected.

_Siblings_ are nodes with the same parent, _cousins_ are nodes with the same grand parent.
A node with at least one child is called an _internal node_, otherwise it is called an _external node_ (aka _leaf_).  A tree's _size_ is the number of it's nodes.  A node's _depth_ is its distance from the root.  A node's _level_ equals depth plus one.  The _height_ of a tree is the largest distance between root and any leaf. Formally: ++height(node) = max(height(node.left), height(node.right)) + 1++, whereas height of NULL is -1 (equalently: height of leaf node is 0). Height of tree, height of root, depth of deepest leaf are all synonymous.

A _balanced_ tree is one where its height is Θ(log |V|).  A _degenerated_ (aka _pathological_) tree is effectiviely a linked list; each node has at most one child.

A _binary tree_ is a tree where each node has at most two children.  A _full_ (aka _proper_) binary tree is one where every node other than the leaves has exactly two children. A full binary tree in which all leaves have the same depth is called _perfect_ (sometimes also complete, but this conflicts with the next definition).  In a _complete_ binary tree, every level, except possibly the last, is completely filled, and all nodes are as far left as possible.

[[number_of_trees]]
The number of possible trees of size n is given by the Catalan number.  An upper bound is 4^n^.  Informal proof for the upper bound: Encode a tree by an Euler Tour. Each edge traversal is encoded with one bit.  0 for going down, 1 for going up.  We do 2|E| edge traversals.  Thus 2^2n^.


[[BFS]]
=== Breadth-first search (BFS) / traversal

An algorithm for traversing or searching a graph in breadth first order in O(V+E) (or O(b^d+1^)) time and O(V) space.  Typically used to traverse a connected graph starting from a single source, thus that's what is shown here. Traversing a disconnected graphs, which implies multiple sources, is also possible, but not shown here. See the outer skeleton of DFS for the general idea how that would be done.

Intuitively the algorithm is: Starting at the source vertex, a spanning tree is built, adding vertices level by level.  A queue contains the neighbors of the interim spanning tree.  In other other words, the queue contains the vertices to be added next to the spanning tree, ordered after their level in the spanning tree.  A color attribute per vertex ensures that a vertex is only added once ever to the queue, and thus also ensures that the vertex is added only once to the spanning tree.

Overview version, using two color scheme:
--------------------------------------------------
Breadth-First-Search(Graph, source:vertex):
  for each vertex v
    v.color = undiscovered
  source.color = discovered
  create queue and enqueue root // queue contains neighbors of spanning tree
  while queue is not empty:
    current = queue.dequeue() // add current to spanning tree, aka visit it
    for each neighbor:
      if neighbor.color == undiscovered:
        neighbor.color = discovered
        queue.enqueue(neighbor)
--------------------------------------------------

Detailed version using three color scheme:
--------------------------------------------------
BFS(graph, source:vertex [, dest:vertex]):
  create queue  // queue contains neighbors of spanning tree
  BFS_init(graph, source, queue)
  while queue is not empty:
    current = queue.dequeue()  // add current to spanning tree, aka visit it
    [current.color = finished] // not needed in the two-colors schemes
    [do auxillary visit action with current]

    for each neighbor that is adjacent to current:
      if neighbor.color == undiscovered // or: neighbor.distance == NIL
        neighbor.color = discovered
        [neighbor.distance = current.distance + 1]
        [neighbor.parent = current]
        [if source==dest: return] // if its only about finding path source->dest
        queue.enqueue(neighbor)

BFS_init(graph, source:vertex, queue):
  for each vertex v in graph:
    v.color = undiscovered
    [v.distance = NIL]
    [v.parent = NIL]

  source.color = discovered
  [source.distance = 0]
  create empty queue Q
  queue.enqueue(source)
--------------------------------------------------

About the color attributes, both for DFS and BFS:  If it is known that the graph is acyclic the color attribute is not needed since it's inherently not possible for that algorithm to discover a node twice.  There are multiple common naming schemes for the colors.  The three color schemes have no advantage over the two color schemes other than some people find the algorithm easier to understand.  So the color finished (black) is technically superfluous.  In DFS, distinguishing three colors is required for certain applications, e.g. edge classification.  In DFS, personally I find the three color scheme unvisited / tentative / visited unfortunate,  since it conflicts with the popular usage of the term `visited' meaning the timepoint when the vertex is added to the spanning tree.  Likewise, in BFS I find the two color scheme unvisited / visited unfortunate for the same reason.

[options="header"]
|=====
   |Distance |2 colors  3+|3 colors. 3rd color not required |BFS                               |DFS
   |∞        |unvisited   |unvisited |undiscovered |white 2+|Not seen at all
.2+|not ∞ .2+|visited     |tentative |discovered   |gray    |Neighbor of spanning tree ⇔ in Q |In spanning tree, but not yet all descendants
                          |visited   |finished     |black   |In spanning tree.                 |In spanning tree, incl. all descendants
|=====


Analysis: Time complexity O(V + E).  Each vertex is enqued/dequed at most once, and each edge is looked at twice, from each of its two sides.  Auxillary space complexity is O(V).  Each vertex needs an color attribute.  Beside that, in the worst case, the queue contains all vertices.  For graphs which are implicitly defined or very large, time complexity is better given as (b^d+1^), whereas b is the branching factor and d is the distance, weights being 1, up to which we search.

Applications:

- Solves the single-source <<shortest_path_problem>> where all edge weights are equal / absent, i.e. where for all paths the path weight equals the path distance.


==== Level order tree traversal

Is basically a BFS, simplified by the fact that a tree is an acyclic graph, and thus no color attribute is needed.

--------------------------------------------------
level_order_tree_traversal(root):
  create empty queue Q
  Q.enqueue(root)

  while Q is not empty:
    current = Q.dequeue()
    [do auxillary visit action with current]
    for each child of current:
      Q.enqueue(n)
--------------------------------------------------


[[DFS]]
=== Depth-first search (DFS) / traversal

An algorithm for traversing or searching a graph in depth first order.  In Θ(V+E) time and O(V) space.  Typically used to traverse a complete, possibly disconnected graph,  as opposed to search only a connected graph starting from a single source.


==== Recursive algorithm

Regarding color attributes, see respective paragraph in chapter <<BFS>>.

Basic algorithm for a connected graph, using two color scheme:
--------------------------------------------------
DFS_single_source(graph, source:vertex):
  for each vertex v in graph
    v.color = undiscovered
  DFS_visit(graph, source)

DFS_visit(graph, current:vertex):
  current.color = discovered // add current to spanning tree, aka visit it
  for each neighbor of current: // aka explore edges (current, neighbor)
    if neighbor.color == undiscovered:
      DFS_visit(graph, neighbor)
--------------------------------------------------

More detailed algorithm for a general graph, using three color scheme:
[[DFS_all_source]]
--------------------------------------------------
DFS_all_source(graph):
  DFS_init(graph)
  for each vertex v in graph:
    if v.color == undiscovered:
      DFS_visit(graph, v)

DFS_single_source(graph, source:vertex):
  DFS_init(graph)
  DFS_visit(graph, source)

DFS_init(graph)
  time = 0
  for each vertex v in graph
    v.color = undiscovered
    [v.parent = NIL]

DFS_visit(graph, current:vertex):
  current.color = discovered // add current to spanning tree, aka visit it
  [current.discovery_time = ++time]
  [do auxillary pre-order visit action with current]
  for each neighbor adjacent to current: // aka explore edges (current,neighbor)
    [if neighbor.color is discovered: graph_has_cycles = true]
    if neighbor.color is undiscovered:
      [neighbor.parent = current]
      DFS_visit(graph, neighbor)
  [do auxillary post-order visit action with current]
  [push current to front of topo sorted sequence]
  [current.color = finished]  // not needed in the two color variants
  [current.finishing_time = ++time]
--------------------------------------------------

Analysis DFS-all-source: Time complexity: +Θ(V+E)+. Rational: Each vertex is visited (is current) once -> +O(V)+.  Each outgoing edge of each current (i.e. each node) is looked at -> +O(E)+. Space complexity: +O(V)+. Rational: Each vertex has at least the color attribute attached. Also in the worst case, when the graph is a list, there are as many recursion calls (stack pushes) as vertices.


==== Iterative algorithm

Intuitively the algorithm is: Starting at the source vertex, a spanning tree is build, prefering to grow the tree in depth rather than breadth.  A stack maintains the neighbors of the current nodes' spanning tree anchestors.  Ordered after spanning tree depth, except for those having the `is-in-spanning-tree' flag set; those are semantically not really part of the stack anymore.  When a vertex is popped from the stack, if it is not already part of the spanning tree, it is made the current node and is made part of the spanning tree.  When the current vertex adds a neighbor to the stack he means `I want that neighbor as my spanning tree child'.  Due to the stacks FILO policy, that `takes away' that neighbor from any spanning tree anchestor who also wanted that neighbor as its child.  I.e. the stack can contain a vertex multiple times.  When a given vertex is popped the first time from the stack, his parent wins, and it is added to the spanning tree.  Wannabe parents of further occurences of the same vertex further below in the stack loose.  To prevent adding the vertex again to the tree, each vertex needs an attribute which tells whether or not it's already part of the tree.

Basic algorithm 1 for a connected graph:
--------------------------------------------------
DFS-visit(G:graph, root:vertex):
  root.isInST = false // most authors call the flag 'visited'
  create stack and push root
  while stack is not empty:
    current = stack.pop()
    if !current.isInST:
      current.isInST = true // i.e. visit current vertex
      for each neighbor:
        // The if-guard is not required, but it would be silly to omit it.
        if !neighbor.isInST:   
          // Announce that the current vertex wants neighbor as its spanning
          // tree child. That takes 'take away' that neighbor from any
          // anchestor of the current vertex who also wanted it as its child.
          stack.push(neighbor)  
--------------------------------------------------

Basic algorithm 2, which is closer to the detailed that follows, for a connected graph:
--------------------------------------------------
DFS-visit(G:graph, root:vertex):
  while stack is not empty:
    current = stack.top()
    if current.color == unvisited:
      current.color = visited
      for each neighbor of current:
        stack.push(neighbor)
    else
      stack.pop() 
--------------------------------------------------

The recursive DFS saves on its call stack for each recursion the pair 1) the current vertex and 2) for that current vertex the current neighbor in the sequence of neighbors it is iterating over. The following iterative solution saves neighbors on the stack, but not the `current neighbor'. E.g. when starting, _all_ neighbors of the src node are pushed immediately onto the stack, and only after that the next iteration begins; that is unlike the recursive solution, which only explores the 2nd neighbor of the src after the complete DFS tree of the first neighbor has been explored. 

Note that DFS-visit is only part of DFS-all-src, *to-do* make it correct where to place init

--------------------------------------------------
DFS-visit(G:graph, root:vertex):
  init(G, root, S)
  while S is not empty:
    current = S.top() // not pop
    if current.color = undiscovered
      [do auxillary pre-order action with current]
      current.color = tentative !!! bad wording. we definitely added to the DFS, but we're not yet finished with this vertex
      for each neighbor of current:
        if neighbor.color = undiscovered: <3>
          [neighbor.parent = current] <4>
          S.push(neighbor) <4> !!! tentatively adding to DFS does _not_ change color 
    elif current.color = tentative
      [do auxillary post-order action with current]
      current.color = discovered <2>
      [push to front of topo sorted sequence]
      S.pop()
    elif current.color = discovered <1>
      S.pop()

init(G:graph, root:vertex, S:stack)
  for each vertex v in G:
    v.color = undiscovered
    [v.parent = NIL]
  create empty stack S
   S.push(source)
--------------------------------------------------

<1> Skipping vertices that are already in the DFS tree. There is no direct equivalent in the recursive DFS version because that
<2> (Definitly) adding current vertex to the DFS tree
<3> `If guard' is only required when parent pointers needs to be set. The guard prevents from modifying the now immutable parent pointer of a vertex which already is in the DFS tree.  If the parent pointer is not needed, keeping the if nevertheless may or may not be an optimization: you save `needlessly' adding vertices to the stack (they will be skipped by ① anyway), but pay with one more conditional branch.
<4> Tentatively add neighbor to DFS tree

When there are multiple paths to a node, a node can occur multiple times in
the stack. Since we want depth-first, we want to follow the longer path (take
the vertex instance that is higher up in the stack), and discard the shorter path (the
instance further down in the stack, discarded by the continue case ①). E.g. in
the following graph, A being the root, DFS pushes A as part of the init, pops
A and marks it as discovered, pushes C and B onto the stack, pops B and marks
is as discovered, pushed C _again_, pops C and marks it as discovered, pops C
(the original push) again and skips it since its marked as discovered.

--------------------------------------------------
        A
      /   \
     V     V
     B---->C
--------------------------------------------------

*to-do*: symmetry between DFS and BFS: http://stackoverflow.com/questions/5278580/non-recursive-depth-first-search-algorithm


[[DFS_edge_classification]]
==== Edge classification

These edge properties are edge properties of the spanning forest (aka DFS forest) that results from a particular DFS run, not of the graph per se.

_Tree edges_: An edge in the DFS forest. When the destination vertex is undiscovered (white) at the time the edge is explored.

_Back edges_: An edge to an anchestor in the DFS forest.  A self-loop is considered a back edge. When the destination vertex is discovered (gray) at the time the edge is explored.

_Forward edges_: An edge to an non-child descendant in the DFS forest.  When the destination vertex is finished (black) at the time the edge is explored and src.discovery_time < dest.discovery_time.

_Cross edges_: An edge between two diffrent (sub)trees in the DFS forest.  When the destination vertex is finished (black) at the time the edge is explored and src.discovery_time > dest.discovery_time.

--------------------------------------------------
      ---A<--
     /  / \  \
     | V   V  |
for- | B   C  |back edge
ward | |   |  |
edge | V   V  |
     \>D<--E-/
       cross
       edge
--------------------------------------------------

Applications:

- <<cycle_dedection>>: A graph is acyclic iff there are no back edges.


==== Tree (pre-/in-/post-) order traversal: Recursive approach

Trivial

==== Tree (pre-/in-/post-) order traversal: Iterative approach

Is a DFS, but since a tree has no cycles, the color attribute is not needed.

--------------------------------------------------
void traverse(Node* n) {
  MyStack<Node*> parents; // pop returns top element and removes it
  Node* prev = NULL; // prev is always non-NULL except at the beginning
  parents.push(prev);
  for ( Node* next = NULL; n ; prev = n, n = next) {
    // came from top
    if ( prev==parents.top() ) {
      preorder_visit(n);
      if (n->left) { // go down left
        parents.push(n);
        next = n->left;
      else if (n->right) { // skip left, go down right
        inorder_visit(n);
        parents.push(n);
        next = n->left;
      } else { // skip left, skip right, go up
        inorder_visit(n);
        postorder_visit(n);
        next = parents.pop();
      }
    }

    // came from left
    else if (prev == n->left) {
      inorder_visit(n);
      if (n->right) { // go right
        next = n->right;
      } else { // skip right, go up
        postorder_visit(n);
        next = parents.pop();
      }
    }

    // came from right
    else {
      postorder_visit(n);
      next = parents.pop(); // go up
    }
  }
}
--------------------------------------------------


=== (Greedy) best-first search
*to-do*:


[[topological_sort]]
=== Topological sort

A _topological sort_ (aka _topsort_, _toposort_, _topological ordering_) of a directed
acyclic graph (DAG) is a linear ordering of its vertices such that for every directed edge (u,v) from vertex u to vertex v, u comes before v in the ordering.  Topological sort is possible only for DAGs; see <<cycle_dedection>> for how to check.

Algorithms:

- DFS based: When an vertex v is finished, prepend it to the front of the output sequence.  In other words, a topological sort is equivalent to reverse DFS post order traversal.  Time complexity Θ(V+E).

- <<kahns_algorithm>> runs in Θ(V+E) time.

- Parallel algorithms in O(log² n) exist, see https://en.wikipedia.org/wiki/Topological_sorting#Parallel_algorithms.


Applications:

- Part of an algorithm solving the single source shortest path problem for a DAG, see <<single_source_shortest_path>>.

References:

- Book ``Introduction to algorithms'', chapter ``22.4 Topological sort''.

- https://www.geeksforgeeks.org/topological-sorting/

- http://www.cs.nthu.edu.tw/~wkhon/ds/ds11/lecture/lecture12.pdf


[[kahns_algorithm]]
==== Kahn's algorithm

Computes the topological sort of a directed graph in O(V+E); dedects cycles.

Intuitively: Have a queue which always maintains all the source vertices (a vertice with indegree 0) of the graph.  While there are vertixes left, pick a source, append it to output sequence, remove it from graph.  If any vertices are left, the graph contains at least one cycle.

--------------------------------------------------
kahns_algorithm(graph): list
  create empty map (key vertex, value int) -> indegree
  for each vertex v in graph:
    indegree[v] = 0
  for each edge e in graph:
    indegree[e.destination]++

  create empty queue -> sources
  for each vertex v in graph:
    if indegree[v] == 0:
      sources.enqueue(v)
 
  create empty list -> topoorder
 
  while !sources.empty():
    current = sources.dequeue()
    topoorder.append(current)
     
    // 'remove' current vertex from graph
    for all neigbors of current:
      indegree[neighbor]--
      if indegree[neighbor] == 0:
        sources.enqueue(neighbor)

  if topoorder.size() != graph.vertex_count()
    raise error "Graph contains at least one cycle"

  return topoorder
-------------------------------------------------

Intuitition why the algorithm works: The graph's sources appear consecutively as the first elements in the topoorder sequence.  Removing a source from the graph does not affect the topoorder sequence of the remaining vertices.  Thus we can iteratively remove sources and append them to the topoorder sequence.

*to-do*: Could we also do the same, but with sinks instead sources? One disadvantage would be that we cant update the indegree map as easily when `removing' a vertex, because generally it's not trivial to know which vertices point to a given vertex.

Analysis: Runs in O(V+E)

References:

- https://www.geeksforgeeks.org/topological-sorting-indegree-based-solution/

- http://www.cs.nthu.edu.tw/~wkhon/ds/ds11/lecture/lecture12.pdf, starting at slide 6


[[cycle_detection]]
=== Cycle detection

The task is to determine whether or not a given graph has at least one cycle.

Algorithms:

- Undirected graph: When DFS or BFS discover a vertex which was discovered before, a cycle is found. Runs in O(V+E) time.

- Undirected graph:  Based on the idea <<kruskals_algorithm>> uses internally. Using a <<disjoint_set>>, put each vertex in its on set.  Then iterate over all edges.  If both ends are in the same set, a cycle is found and the algorithm terminates. Otherwise join the two sets.  Run in O(V + E·α(V)) time and needs O(V) auxiallary space, where α is the very slowly growing inverse function of the Ackermann function.  Is better than BFS / DFS for the case when we need to tell after each edge insertion whether that introduced a cycle. In that case, the running time after an edge insertion is O(α(V)).

- Directed graph: When <<DFS>> finds a <<DFS_edge_classification,back edge>>. Runs in O(V+E) time.

- Rocha–Thatte. Is a distributed algorithm in graph theory for detecting cycles on large-scale directed graphs based on the bulk synchronous message passing abstraction. *to-do*.

- Many <<topological_sort>> algorithms detect cycles too, since cycles are an obstacle for topological sort.


Applications:

- Dedect cycles (i.e. problems) in a dependency graph


[[LCA_problem]]
=== Lowest common ancestor (LCA) problem

See <<DAG>> for the definition of lowest common ancestor (LCA).  It can be shown that the two problems <<RMQ>> and LCA are equivalent, see <<RMQ_LCA_equivalence>>.

Solutions:

- With O(n^2^) space, O(1) time is trivial: An O(1) time lookup table stores the answer for all input pair vertices.

- Tarjan's off-line LCA: After preprocessing the DAG, solvable in O(1) time and O(n) space. *to-do*

- If DAG is a cartesian tree: reduce to array, see <<cartesian_tree>>, and solve <<RMQ>> there. *to-do*: how exactly, there we're rediricted to LCA

References:

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees: https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video]


[[LA_query]]
=== Level ancestor problem / query

Given a rooted tree and a node v, LA(v, k) delivers delivers the k-th ancestor (where parent is the 1st ancestor).

|=====
| space      | query    | 
| O(n²)      | O(1)     | Brute force 2D table A[node,k].
| O(n log n) | O(log n) | Jump pointers (JP)
| O(n)       | O(log n) | Ladder decomposition (LD)
| O(n log n) | O(1)     | LD + JP
| O(n)       | O(1)     | Indirection: LD (parent tree internal nodes) + JP (parent tree leaves) + table (bottom tree types).
|=====


References:

- MIT course 6.851 Advanced Data Structures, spring 2012, lecture 15 Static trees: https://courses.csail.mit.edu/6.851/spring14/scribe/lec15.pdf[lecture notes], https://www.youtube.com/watch?v=0rCFkuQS968&index=15&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&t=0s[video]


==== Jump pointers

Each node stores a table to its 2^i^-th ancestor, 0 ≤ i ≤ log n.  To find k-th ancestor, goto node stored at index ⌊log k⌋, then recurse with k~i+1~ = k~i~ - 2^⌊log k~i~⌋^.  I.e. in each step, we jump at least half of the remaining distance.


==== Ladder decomposition

A preliminary notion is longest path decomposition.  Recursively store the longest path of the remaining tree as an array of pointers to tree nodes.  A[0] represents the leaf, A[1] its 1st parent and so on.  Each tree node stores a pointer to its array and its index within that array.  Within that array, it's trivial to go to k-th ancestor: just add k to the current index.  Each array stores a pointer to its parent array, i.e. the array containing the parent node of the last node in the current array.  That way we can find the k-th ancestor in the general case. If k is smaller then the number of remaining elements in the current array, the current array has the answer.  Else we recursively follow the parent array pointer to higher level arrays until the k~i~ is small enough to end up in an array.  However, as the following diagram shows, in the worst case we never make use of the arrays, always only chasing the pointers to the higher level array.  Thus the worst case query is O(√n).

--------------------------------------------------
  o
  |\      arrays are all verticaly 
  o o
  | |\
  o o o
  | | |\
  o o o o 
--------------------------------------------------

Ladder decomposition extends the idea of longest path decomposition by doubling the length of each array.  The intuition are those extensible ladders.  The arrays are now also called ladders.  Each array overshoots now.  Only the first half of the nodes really belong to the array, just as in longest path decomposition.  A tree node can appear in multiple arrays.  But just as in longest path decomposition, it only stores a pointer and index for the array it really belongs to.  The query algorithm is as before.  However in contrast to longest path decomposition, now the progess made by each array is substential.

Analysis: Note that each ladder starts at an leaf. Thus each ladder can at least double the current height. Thus query time is O(log n).  In longest path decomposition, there's an array element for each node in the tree, and each node in the tree is amended.  Thus space complexity is O(n).  In ladder decomposition, we doubled the length of each array, thus space complexity is still O(n).


==== Ladder decomposition plus jump pointers

Note that jump pointers initially makes a big jumps which cover at least half the remaining distance, but then in each iteration the jump distance about halfes.  Ladder decomposition is inverse.  In the worst case it starts with only a small height gain, but then in each iteration we can at least double our height.  When we employ both schemes, we make one jump with the help of jump pointers, which covers at least half of the distance, and will then end up guaranteed in a ladder which can cover the remaining distance.

Analysis: O(1) query time, which is apparent from the description above.  We overlayed jump pointers having space complexity O(n log n) and ladder decomposition having O(n), thus the overall space complexity is O(n log n).


==== Indirection + JP + LD

We like the ladder decomposition plus jump pointers approach due to its O(1) query time, but instead of O(n log n) space complexity, the nasty log n factor being due to the jump pointer tables, we would like O(n).  The main idea to reach O(n) space is on one hand to store jump pointers only in a few nodes,  and on the other hand to make the bottom trees small enough such that there are less bottom tree types than actual bottom trees.  As a consequence we can store a data structure per type, rather than use some data structure per actual bottom tree.

Divide the tree into a parent tree and a set of bottom trees.  The leaves of the parent tree store jump pointers.  The internal nodes of the parent tree do ladder decomposition and store a pointer to one of there leaves.  For each possible type of bottom tree, we store a brute force lookuptable.  Each node in the bottom trees has a pointer to its type / lookuptable.  Thus within the parent tree and within bottom trees we have O(1) query time.  Nodes in bottom trees also store a pointer to their respective leaf in the parent tree.  Thus also queries starting in a bottom tree and ending in the parent tree require only O(1) time.

Details and analysis:  We cut below all maximally deep nodes, now leaves in the parent tree, which have at least 1/4 log n descendants.  Thus there are O(n / log n) leaves in the parent tree, and followingly also as many bottom trees.  Each parent tree leaf requires  O(log n) space for the jump pointers.  Overal thus O((n/log n) log n) = O(n) space for the jump pointers.  The ladder decomposition for the parent tree internal nodes requires O(n / log n) space, but that's now irrelevant.

The size nʹ of a bottom tree is about 1/4 log n. The number of different binary trees of size nʹ is given by the Catalan number.  An upper bound is 4^nʹ^ = 2^2 1/4 log n^ = √n, see also <<number_of_trees>>.  Thus there are only √n possible different bottom tree types, which is less than the number of actual bottom trees being n / log n.  Thus we can store look up tables per bottom tree type, rather than per actual bottom tree.  Regarding a lookup table query in a bottom tree type: there are O(nʹ) = O(log n) nodes to start from, and the same amount of different k's (recall that a binary tree might be degenerated to a path), thus there are O(log² n) different queries.  The space needed for a single cell in the lookup table is the number of bits needed to identify O(nʹ) = O(log n) nodes, which is O(log log n)  (*to-do* but how can I find the actual tree node object when only given the abstract id of a node in respect to a tree type).  Thus the overall space is number of tree types times the number of possible queries per lookuptable times the space per cell = O(√n log²n log log n) = o(n). (*to-do* why is that last equal sign valid?)

Overall we get O(1) query time and O(n) space.


[[shortest_path_problem]]
=== Shortest path problems
The problem of finding a <<shortest_ path>> (there might be multiple shortest paths) in a graph. Recall that the shortest path is undefined, or it's weight is -INFINIT, if it contains negative-weight cycles, because one can always make an allegedly `shortest path' shorter by walking through the cycle one more time.

optimal substructure: The shortest path problem has optimal substructure. A subpath of a shortest path is itself a shortest path; if it wasn't, we could replace it by the alegedly shorter path and thus make the overall path shorter.

Applications: *to-do*


[[single_source_shortest_path]]
==== Single source shortest path problem
general graph: <<Bellman_Ford>> +O(V*E)+

non-negative weights: <<Dijkstra>> +O(E+V*lg(V))+

DAG: <<topological_sort>>, then for each node, for each neighbor, relax. +Θ(E + V)+

unweighted graph: <<BFS>> +O(E+V)+

integer weights: Thorup *to-do*


==== Single destination shortest path problem
Can be reduced to single source shortest path by reversing direction of each edge.


==== Single pair shortest path problem
All known algorithms for this problem have the same worst case asymptotic running time as the best single source algorithms.

non-negative weights: <<A_star>>


==== All pairs shortest path problem
general graph (neg weights, dedects neg. cycles): <<floyd_warshall>> in O(|V|^3^)


[[A_star]]
==== A*
A* is a best-first-search algorithm which solves the single-pair <<shortest_path_problem>>, not allowing negative weights.  A* uses an heuristic, involving the function h, to find the next node to be added to the shortest path tree.  It can also be used to solve the single-source shortest-path problem, but is not intended for it, since h is typically optimized for a specific destination node.  A* is a generalized version of <<Dijkstra>>'s algorithm: if h returns always 0 (i.e. is independent of a destination node) then A* equals Dijkstra.

How the algorithm works intuitively (use case `monotonic h'):  Construct the shortest path tree (_SPT_) by adding source to the SPT, and then iteratively adding a vertex to the SPT.  The vertex v to be added to the SPT is the one with minimal `estimated shortest path length from source to destination via v'. That is correct due to the monotonic h and the fact that any sub path of a shortest path is itself a shortest path.

Each vertex gets attached two additional attributes: shortest path tree parent (*+spt_parent+*) and shortest path weight from source to this node (*+spwfs+*).  While a node is in the queue, these are tentative values. Once a node is dequed and thus really added to the shortest path tree, they remain at that final value.  In case of +spwfs+ its value is an upper bound on the true value.

As parameter the algorithm takes an heuristic function *h*, or more verbosely, +*estimated_spw_to_dest*(from:vertex)+, which shall return an estimated shortest path weight from the given vertex to the implicit destination vertex. More on h later.

From h another function is derived: ++function vertex::**k**() = .spwfs + estimated_spw_to_dest(this);++.  It returns the estimated shortest path weight from the implicit source vertex to the implicit destination vertex via vertex v.  k() is used as the key for the min priority queue.

Algorithm which assumes h is monotonic:

When dest==NIL the algorithm solves the single-source shortest path problem.  The solution is the shortest path tree given by the .spt_parent attribute of each vertex, along with the .spwfs attribute of each vertex.

When dest!=NIL the algorithm solves the single-pair shortest path problem.  The solution is the shortest path from source to dest with a weight of dest.spwfs and given by a linked list from dest to source, starting at dest.spt_parent.

--------------------------------------------------------------------------------
function A*(graph, source:&vertex, dest:&vertex,
        estimated_spw_to_dest:function(:vertex)->double )
    create min priority queue outsideSptQ  where key is vertex::k() <1>
    for all vertices v in graph:
        [v.spt_parent = NIL]
        v.spwfs       = (v==source ? 0 : INFINITE)
        outsideSptQ.enqueue(v)

    while outsideSptQ not empty:
        current = outsideSptQ.deque() <2>
        [if current == dest return]
        for each neighbor of current:
            relax(current, neighbor, outsideSptQ) <3>

function relax(u:vertex, v:&vertex, Q:MinPriorityQ)
    alternate_spwfs_for_v = u.spwfs + weight(u,v)
    if alternate_spwfs_for_v < v.spwfs:
        Q.decreaseKey(v, alternate_spwfs_for_v)
        [v.spt_parent = u]
--------------------------------------------------------------------------------

Optimizations and notes to the above algorithm:

<1> Optionally adapt the min priority queue implementation slightly: If +dequeue+ returns NIL if all remaining keys are infinite, we can sooner terminate.  Also the implementation might take advantage of the knowledge that many keys are infinite, especially at the beginning.
<2> Greedely choose vertex with smallest k and add it to the SPT. +current.spwfs+ is now at its final true value, i.e. no longer an estimate / upper bound.
<3> Note that +neighbor+ could already be part of shortest path tree and thus could be skipped.  However it's not worth explicitly checking that (in the presented implementation there would also not be a trivial way to do so), since the if statement within +relax+ implicitely ensures that not much is made with +v+.

Properties of the A* algorithm:

- complete (will always find a path if one exists)
- optimal (*to-do*: i think this explains optimal wrongly: finds the shortest path), but only if the provided heuristic function is admissible.  However see <<bounded_relaxation>> later in the A* sub chapter.
- *to-do:* I don't trust the time complexity, space complexity noted in Wikipedia,  I guess they forget to account for the costs of the min priority queue and of h.  If h is const, then there two options: call it once for every vertex at the beginning and store the result, or call it every time when needed.  Depending on the problem one or the other will be more optimal.
- *to-do:* Does it work for the case when the single-source shortest path problem is tried to be solved?
- Is an best-first search, but not greedy

About the heuristic function h aka +estimated_spw_to_dest(from:vertex)+:

- Responsibility: Returns an estimated shortest path weight from the given vertex v to the implicit destination vertex.
- Should be an admissible heuristic.  That is, it must not overestimate.  In other words, the estimation must not be higher than the lowest possible cost.  If it fails to be admissible, A* is no longer optimal, see also <<bounded_relaxation>>.
- Should be monotone (aka consistent: For every edge (x,y): h(x) ≤ edge_weight(x,y)+h(y)).  A* can be implemented more efficiently by not making a node the current more then once (remember the above algorithm is for monotonic h).  Running such an A* algorithm on graph G is the same as running Dijkstra's algorithm on an alternate graph G' where edge_weight'(x,y) = edge_weight(x,y) + (h(y)-h(x)).
- *to-do*: must be constant (during the run-time of the algorithm)?
- Examples how to implement h: euclidean distance.

[[bounded_relaxation]]
_Bounded relaxation_: While the admissibility criterion guarantees an optimal solution path, it also means that A* must examine all equally meritorious paths to find the optimal path.  It is possible to speed up the search at the expense of optimally by relaxing the admissibility criterion.

Relation between different common naming schemes. spt_parent and and spwfs are my own abbreviations/terms; I prefer them over just parent and distance respectively since they more precisely say what they mean exactly.

[options="header"]
|=====
   |scheme 1  | scheme 2       | scheme 3 | spwfs' value           | is in outsideSptQ
.2+|unvisited | unvisited      | white    | INFINIT, upper bound   | yes 
              | tentative/open | gray     | < INFINIT, upper bound | yes
   |visited   | closed         | black    | final value            | no
|=====

[options="header"]
|=====
|scheme 1   | scheme 2       | comments
|spwfs      | d or distance  | actually an upper bound
|spt_parent | π or parent    |
|=====


[[Dijkstra]]
==== Dijkstra's algorithm

A greedy (can also be seen as dynamic programming) algorithm which solves the single-source <<shortest_path_problem>>, not allowing negative weights, in +O(E+V*lg(V))+ time and +O(V)+ space, assuming Fibonacci heaps are used. That notably includes directed or undirected graphs and graphs with cycles.

Terms and abbreviations: ubspwfs = upper bound on shortest path weight from source (in literature often called distance or simply d), SPT = shortest path tree. See also <<A_star>>.

Intuition: A spanning tree is built, more specifically a SPT (see terms).  Vertices are added in order of how close to the SPT they are.  Each vertex is assigned an ubspwfs (see terms) attribute.  Out of the vertices not yet in the SPT, iteratively greedely choose the vertex with the smallest ubspwfs.  I.e. the vertex which is closest to the SPT.  Typically a min priority queue with ubspwfs as key is used to find that vertex.  Add the found vertex to the SPT and update the ubspwfs for all it's neighbors.

----------------------------------------------------------------------
Dijkstra(graph, source:vertex)
  create empty min priority queue sptNeighborsQ with ubspwfs as key
  for each vertex v in graph:
    v.ubspwfs = (v==source ? 0 : INFINITE)
    sptNeighborsQ.enque(v)
  while sptNeighborsQ not empty:
    // greedely choose vertex nearest to SPT and add it to SPT
    current = sptNeighborsQ.deque()
    for each neighbor of current:
      relax(current, neighbor)
----------------------------------------------------------------------

Detailed description: Each node has an attribute ubspwfs. It is initially infinite, and each relaxation step potentially makes it smaller, i.e. potentially tightens the upper bound, until it reaches its final, true smallest value. It can be proven that the smallest ubspwfs in sptNeighborsQ, i.e. the one that the next dequeue call will return, has arrived at its true final spwfs value, and will never change again. Thus by choosing the vertex with the smallest ubspwfs, the algorithm always adds a vertex to the SPT which is not only closest, but in fact for which the spfws is known. Since the relaxation sets the spt_parent always to the current vertex, i.e. a node which already is in the SPT, when a vertex is dequed, its spt_parent is in the SPT, and thus it is implicitely added to the SPT.

----------------------------------------------------------------------
Dijkstra(graph, source:vertex [,dest:vertex])
  create empty min priority queue sptNeighborsQ with ubspwfs as key
  for each vertex v in graph:
    [v.spt_parent = NIL]
    v.ubspwfs   = (v==source ? 0 : INFINITE)
    sptNeighborsQ.enqueue(v)
  while sptNeighborsQ not empty:
    // greedely choose vertex nearest to SPT and add it to SPT
    current = sptNeighborsQ.deque()
    [if current==dest return]
    for each neighbor of current:
      relax(current, neighbor, sptNeighborsQ)

relax(u:vertex, v:vertex, Q:MinPriorityQueue)
  alternate_ubspwfs_for_v = u.ubspwfs + weight(u,v)
  if alternate_ubspwfs_for_v < v.ubspwfs:
    Q.decreaseKey(v, alternate_ubspwfs_for_v)
    [v.spt_parent = u]
----------------------------------------------------------------------

Proof: Note that the shortest path problem has optimal substructere, see <<shortest_path_problem>>. *to-do*: Understand proof that the (upper bound) spwfs of the front vertex ofs sptNeighborsQ has arrived at it's true final value.

Notes:

- relax is called for all neighbors, even if they are already part of the SPT. Since their spwfs is already at the true final value, which can be proven, it will never be decreased anymore, so always calling relax doesn't hurt.
- Rational why negative weights are not allowed: The Dijkstra algorithm relies upon that adding a vertex to a shortest path does not decrease the shortest path's weight.
- Dijkstra can be seen as dynamic programming algorithm. DP(i) is the spwfs for vertex i: DP(i) = min~all predecessors j of i~{DP(j) + weight(j,i)}, with base case DP(startvertex)=0. See also https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Dynamic_programming_perspective.

Relation to other algorithms: Dijkstra is a special case of the A* in that that A*'s h function is constant 0, but is a generalization of A* in that that it not only can solve the single-pair shortest path problem but also the single-source shortest path problem. Algorithm when implemented in terms of A*:

----------------------------------------------------------------------
function Dijkstra(graph, source:vertex)
    return Base(graph, source, NIL, lambda(v:vertex){0})

function Dijkstra(graph, source:vertex, dest:vertex)
    return Base(graph, source, dest, lambda(v:vertex){0})
----------------------------------------------------------------------

Analysis: Time +O(E+V*lg(V))+ if a Fibonacci heap is used to implement the min priority queue.  Using a binary heap it's +O((E+V)*lg(V))+, with an array it's  +O(E+V^2^)+.  Auxillary space: +O(V)+ -- however, the same space amount is also used for an answer which includes all shortest path weights and the shortest path tree.  If the answer must only include the weight of one target node the time and auxiliary space complexity remains the same.

Trivia: Etymology of the term `relaxation': There are two variants. 1) It comes from mathematics where relaxation means relaxing a constraint. Here the constraint is v.spwfs<=u.spwfs+weight(u,v). The smaller v.spwfs is, the less `pressure' there is to satisfy this constraint, thus the constraint is relaxed. 2) Think of the upper bound as an extended spring. Making the upper bound smaller relaxes the spring. The true value is reached when the spring is in its resting position. However from another viewpoint one could find it strange to call tightening an upper bound a relaxation.


==== Bidirectional search
It runs two simultaneous searches: one forward from the initial state, and one backward from the goal, stopping when the two meet in the middle.

*to-do*

[[Bellman_Ford]]
==== Bellman-Ford
A dynamic programming algoritm solving the shortest-path single source problem in O(|V|·|E|). Allows for negative weights (which Dijkstra doesn't) and can report negative cycles.

--------------------------------------------------
fun bellman-ford(G, source:vertex)
  init(G, source)
  |V| times:
    for each edge e in G:
      relax(e)
  [dedect-negative-cycles]

relax(e:Edge)
  for both directions of e:
    alternate_distance = e.v_from.distance + e.weight
    if alternate_distance < e.v_to.distance
      e.v_to.distance = alternate_distance
      [e.v_to.parent = e.v_from]

init(G)
  for each vertex v in G:
    v.distance = inf
    [v.parent = NIL]
  source.spwfs = 0

dedect-negative-cycles(G)
  for each edge e in G:
    if relax(e) would relax:
      abort, negative cycle found
--------------------------------------------------


[[floyd_warshall]]
==== Floyd–Warshall algorithm
A dynamic programming algorithm which solves the <<shortest_path_problem>> all pairs problem in O(|V|^3^). Negative weights are allowed, negative cycles are dedected.

Basic idea: You have a matrix C (V×V) storing shortest path for all vertex
pairs. Initially, no intermediate vertices are allowed, i.e. C corresponds to
the graph in its adjacency matrix representation. Then you iterate |V| times:
in each iteration, one more intermediate vertex is allowed, thus relaxing each
cell.

----------------------------------------------------------------------
Floyd-Warshall(G:GraphAsAdjacencyMatrix)
  C = G
  for k=1 to |V|:
    for i=1 to |V|:
      for j=1 to |V|:
        C[i][j] = min(C[i][j], C[i][k] + C[k][j]) // relaxation
----------------------------------------------------------------------

Explanation: c~ij~^k^ is a cell in the matrix in iteration k. It represents
the shortest path from v~i~ to v~j~, choosing intermediate vertices only from
the set {v~1~, ..., v~k~}. It's value is the min of:

- c~ij~^k-1^, i.e. directly going from v~i~ to v~j~, choosing intermediate
  vertices only from set {v~1~, ..., v~k-1~}.
- c~ik~^k-1^ + c~kj~^k-1^, i.e. going via v~k~, and both v~i~ to v~k~ and v~k~ to v~j~ choosing intermediate
  vertices also only from set {v~1~, ..., v~k-1~}.

*to-do* cycle dedection


=== Longest path problem
*to-do*


[[hamiltonian_cycle]]
[[hamiltonian_path]]
=== Hamiltonian path / cycle

An _Hamiltonian path_ (aka _traceable path_) is a path in an undirected or directed graph that visits each vertex exactly once.  A _Hamiltonian cycle_ (aka _Hamiltonian circuit_, _vertex tour_ or _graph cycle_) is a Hamiltonian path that is a cycle.  A graph that contains a Hamiltonian path is called a _traceable graph_.  A graph is _Hamiltonian-connected_ if for every pair of vertices there is a Hamiltonian path between the two vertices. A graph that contains a Hamiltonian cycle is called a _Hamiltonian graph_.  The _Hamiltonian path problem_ and the _Hamiltonian cycle problem_ are problems of determining whether a Hamiltonian path or a Hamiltonian cycle exists in a given graph (whether directed or undirected).  Both problems are NP-complete.

Properties:

All Hamiltonian graphs are biconnected, but a biconnected graph need not be Hamiltonian.

A tournament (with more than two vertices) is Hamiltonian iff it is strongly connected.


[[eulerian_circuit]]
[[eulerian_trail]]
=== Eulerian trail / circuit

An _Eulerian trail_ (aka _Eulerian path_ or _Euler walk_) is a trail in an undirected or directed graph (including multigraphs) that uses all the Graph's edges.  If such as walk exists, the graph is called _traversable_ (aka _semi-eulerian_).  An _Eulerian cycle_ (aka _Eulerian circuit_, or _Eulerian tour_) is a circuit that uses all the Graph's edges.  If such a cycle exists, the graph is called _Eulerian_ or _unicursal_.

Properties:

An connected undirected graph has an Eulerian cycle if and only if every vertex has even degree.

An connected undirected graph has an Eulerian trail if and only if exactly zero or two vertices have odd degree.

A directed graph has an Eulerian trail if and only if at most one vertex has (out-degree) − (in-degree) = 1, at most one vertex has (in-degree) − (out-degree) = 1, every other vertex has equal in-degree and out-degree, and all of its vertices with nonzero degree belong to a single connected component of the underlying undirected graph.

A connected directed graph has an Eulerian cycle if and only if its strongly connected and every vertex has equal in degree and out degree. Equivalently, a directed graph has an Eulerian cycle if and only if it can be decomposed into edge-disjoint directed cycles and its strongly connected.

Problems:

- Finding Eulerian trails:
  * Fleury's algorithm find's Eulerian trails or cycles in +O(E²)+
  * Hierholzer's algorithm find's Eulerian cycles linear time: +O(E)+.

Applications:

- Eulerian trails are used in bioinformatics to reconstruct the DNA sequence from its fragments.
- They are also used in CMOS circuit design to find an optimal logic gate ordering.
- There are some algorithms for processing trees that rely on an Euler tour of the tree (where each edge is treated as a pair of arcs).

Trivia: Was first discussed by Leonhard Euler while solving the famous _Seven Bridges of Königsberg_ problem in 1736.


[[TSP]]
=== Travelling salesman problem (TSP)
In an weighted graph (directed or undirected), the TSP is finding the path with mimimum weight visiting each vertex exactly once and start vertex being the end vertex.

TSP is a special case of the travelling purchaser problem.  

TSP is NP-complete.

Algorithms:

- Exact: Held–Karp, a dynamic programming algorithm.
- Exact: Various branch-and-bound algorithms
- Exact: ... linear programming ...
- Approximations: *to-do*

Applications: *to-do*


=== Travelling purchaser problem
*to-do*


[[MST_problem]]
=== Minimum spanning tree problem

The problem of finding the <<MST>>, actually minimum spanning forest, in an undirected weighted possibly disconnected graph.

Both Kruskal's algorithm and Prim's algorithm rely on the fact that adding a light edge to a partial MST is safe.  Both algorithms essentially start with an empty partial MST, and iteratively greedely add a light edge until the MST is finished.

Algorithms:

- <<kruskals_algorithm>>

- <<prims_algorithm>> (restricted to connected graphs)

References:

- Book ``Introduction to algorithms'', chapter ``Minimum Spanning Trees''.


[[kruskals_algorithm]]
==== Kruskal's algorithm

A greedy algorithm solving the <<MST_problem>> for a connected weighted graph in O(E log E) time.

Intuition: Start out with each vertex being its own tree.  They represent the partial yet disconnected MST.  Then iteratively add the smallest weighted edge to the partial MST iff that does not produce a cycle in the partial MST, since a by definition a tree is not allowed to have cycles.  Typically that cycle detection is done via the help of a <<disjoint_set>> data structure.  There would be a new cycle if the start and the end vertex of a given edge are in the same tree, i.e. in the same set.

--------------------------------------------------
KRUSKAL(G):
  foreach vertex v:
    MAKE-SET(v)
    v.MSTParent = NIL
  order edges by weight, increasing
  foreach edge (u, v) in that ordered edge sequence:
    if FIND-SET(u) ≠ FIND-SET(v):
      add edge to MST, e.g. u.MSTparent = v
      MERGE-SETS(u, v)
  starting at any vertex, follow MSTparent pointers to find MST's root
--------------------------------------------------

Proof: It's not trivial to see why this greedy algorithm is optimal, see http://tandy.cs.illinois.edu/Kruskal-analysis.pdf.

Analysis: O(sort(E) + (E+V)α(V)) time, assuming an asymptotically optimal disjoint-set data structure is used internally, and where α is the very slowly growing inverse function of the Ackermann function.  Note that the running time depends heavily on the used sort algorithm used to sort the edge weights.  So if the weights are integers, a non-comparative sorting algorithm such as radix sort can be used.

References:

-  http://tandy.cs.illinois.edu/Kruskal-analysis.pdf

- Book ``Introduction to algorithms'', subchapter ``The algorithms of Krustal and Prim'', section ``Kruskal's algorithm'', p. 631.


[[Prim]]
==== Prim's algorithm

A greedy algorithm solving the <<MST_problem>> for a connected graph in O(E log V) time when a binary heap is used.

Intuition: Start with any vertex as being the root of the MST.  There's a cut between the nodes in the partial MST and the rest of the nodes.  Iteratively greedely add a light edge.

To be able to do that, each vertex as an attribute distanceToMst.  It is the distance to the partial MST using only one edge, initialy infinite.  Vertices in the partial MST have distanceToMst set to zero.  Thus distanceToMst is larger than zero and less than infinite iff the vertex has an edge crossing the cut.  Thanks to a min piority queue having distanceToMst as key, we always know a light edge.

Prim's algorithm and <<Dijkstra>> are highly related. The difference is that Prim builds an minimum spanning tree by choosing a vertex with a light edge, and Dijkstra builds a shortest path tree by choosing the vertex with the smallest path weight from source.

--------------------------------------------------
MST-Prim(G:graph):
  for each vertex v:
    v.distanceToMst = infinit
    v.parent = NIL
  choose any vertex as root
  root.distanceToMst = 0
  create min priority queue outsideMstQ out of all vertexes, distanceToMst being key  
  while outsideMstQ not empty:
    current = outsideMstQ.deque() // greedely add vertex to MST
    current.distanceToMst = 0
    for each neighbor of current:
      prim-relax(current, neighbor, outsideMstQ)
  return root

prim-relax(u:vertex, v:vertex, Q):
  if weight(u,v)<v.distanceToMst
    Q.decreaseKey(v, weight(u,v))
    v.parent = u
--------------------------------------------------

Analysis:

- Initialization loop is done V times, and costs O(V) overall.

- Overall prim-relax is called twice for each edge, i.e. O(E) times. prim-relax costs O(decrease-key), which is O(log V) for a binary heap, so its O(E log V) overall.

- Outer loop is over all vertices, i.e V times. dequeue costs O(log V), so overall its O(V log V).

- All together its thus O((V+E) log V) = O(E log V).


References:

- Book ``Introduction to algorithms'', subchapter ``The algorithms of Krustal and Prim'', section ``Prim's algorithm'', p. 634.


=== Connectivity

Two vertices v and u of an undirected graph are _connected_ if they are linked by a path, otherwise they are called _disconnected_.  An undirected graph is _connected_ when every pair of vertices is connected.  Two vertices in an directed graph are _strongly connected_ if they are mutually linked by paths.  A directed graph is _weakly connected_ (or just _connected_) if it would be a connected graph if the edges were taken to be undirected.  A directed graph is _strongly connected_, if for every pair there's a path in both directions.  A _connected component_ (or just _component_) of an undirected graph is a subgraph which is connected and is not connected to any vertices of the supergraph.  A directed graph is called _strongly connected_ (or _strong_) if it contains a path from u to v and from v to u for every pair of vertices u and v.  A _strongly connected component_ (_SCC_, or _strong component_) of a directed graph G is a subgraph that is strongly connected, and is maximal with this property: no additional edges or vertices from G can be included in the subgraph without breaking its property of being strongly connected.

Contracting each strongly connected component of a directed graph G to a single vertex is called the _condensation_ of G. The condensation of G is a DAG and also called _kernel DAG_ (or _component graph_).

A _cut_ is a partition of V.  A _vertex cut_ (aka _separating set_) of a connected graph G is a set of vertices whose removal renders G disconnected.  A set of edges _respects_ a cut if no edge in that set croses the cut.  An edge crossing a cut is a _light edge_ if its weight is the minimum of any edge crossing the cut.  A graph is called _k-connected_ if k<|G| and G remains connected if k-1 vertices (or less of course) are removed.  The greatest k such that a graph G is k-connected is called the _connectivity_ (or _vertex connectivity_) κ(G) of G.  In other word, it is the size of the minimal vertex cut unless it's a complete graph, in which case κ(G) = |G|.  Is the vertex connectivity 1, the single vertex of the vertex cut is called _articulation point_ (aka _cut point_, _separating vertex_ or _cut vertex_).  2-connectivity is also called _biconnectivity_, and 3-connectivity is also called _triconnectivity_.

The removal of a _disconnecting set_ of edges disconnects the graph.  Partition the graph in two set of vertexes; an _edge cut_ is an edge set where each edge as an endpoint in one partition and the other endpoint in the other partition.  A graph is _k-edge-connected_ if every disconnecting set has at least k edges.  The greatest k such that a graph is k-edge-connected is called the _edge connectivity_ κʹ(G) of G.  In other words, is the minimum size of a disconnecting set.  A _bridge_ (aka _cut-edge_) is an edge in a connected (sub)graph whose removal would disconnect the (sub)graph.

A _complete graph_ with n vertices, denoted K~n~, is a simple undirected graph in which every pair of distinct vertices is connected by a unique edge.  A _tournament_ is a directed graph obtained by assigning a direction for each edge in an complete graph.  A _clique_ in an undirected graph is a subset of its vertices such that every two vertices in the subset are connected by an edge.  A _block_ is a maximal connected subgraph that has no cut-vertex.

Every (non-empty) graph is 0-connected.  A connected graph (see also previous definition) is a 1-connected graph.  A _biconnected graph_ is a 2-connected graph.  An equivalent definition (except in the case of the path graph P~2~ which has vertex connectivity 1 but no articulation vertices) is a connected graph having no articulation vertices.  A _biconnected component_ (aka _block_ or _2-connected component_) is a maximal (*to-do*: what does maximal mean here?) biconnected subgraph.  Note a biconnected component, unlike connected components, can be connected to other parts of the supergraph.  A _block graph_ (aka _clique tree_) is an undirected graph in which every biconnected component (aka block) is a clique.

For every graph, its connectivity is smaller or equal its minimum degree [Proposition 3.3 in ``Graph Theory''].

Mader: Every graph of average degree at least 4k has a k-connected subgraph.

_Menger's Theorem_: Vertex connectivity: k-connected vertices are connected by k internally vertex-disjoint paths.

Motivation: Connectivity measures fault tolerance of a network. E.g. how many connections can fail without cutting off communications.

An edge can only be a bridge if it is not contained in an cycle.

References:

- http://www2.nauk.si/files/894/adventes.pdf

- Book Graph Theory, 5th Ed., Reinhard Diestel, chapter "Connectivity"

- Book ``Introduction to algorithms'', chapter ``Strongly connected components''.

- Book Algorithms (4th Edition), Sedgewick & Wayne, subchapter "Strong connectivity in digraphs", p. 584


==== Tarjan's algorithm for finding articulation points

Finds articulations points in an undirected graph in Θ(E+V) time. Note that there is also an ``Tarjan's algorithm'' which finds strongly connected components.

*to-do*

References:

- https://www.slideshare.net/TraianRebedea/algorithm-design-and-complexity-course-8, beginning at slide 27


[[finding_connected_components]]
==== Finding connected components in undirected graphs

Algorithms:

- Using an disjoint-set data structure, put each vertex into its own set. Then iterate over all edges, and join the two sets associated with the two end points.  Each remaining set represents a connected component.  Runs in O(V+E·α(V)) time and needs O(V) auxillary space, assuming an disjoint set forest is used.  α is the very slowly growing inverse function of the Ackermann function.

References:

- Book ``Introduction to algorithms'', subchapter ``21.1 Disjoint-set operations'', section ``An application of disjoint-set data structures'', p. 562.


==== Finding strongly connected components

Algorithms:

- <<kosaraju_sharir_algorithm>> in O(V+E) time.  Two DFS passes.  Simple to implement, rather difficult to understand why it works.

- <<tarjans_algorithm>> in O(V+E) time.  A single DFS pass.  More complex than the Kosaraju-Sharir algorithm.

- path based strong component algorithm. Uses a single DFS pass, like Tarjan's algorithm, but with two stacks.  The first linear time version of this algorithm was published by Dijkstra. *to-do*

- Reachability-based Algorithms, O(n log n) time.  However these algorithms are easier to parallelize than the previous DFS based algorithms. https://en.wikipedia.org/wiki/Strongly_connected_component. *to-do*


References:

- https://www.quora.com/Is-there-any-difference-or-advantages-or-disadvantages-between-Kosarajus-algorithm-and-Tarjans-algorithm-for-finding-strongly-connected-component-Which-one-is-most-useful


[[kosaraju_sharir_algorithm]]
==== Kosaraju-Sharir algorithm

Finds the strongly connected components of a directed graph G in O(V+E) time.

The first step is building the reverse of a DFS post order traversal.  Typically this is done by an all source DFS which pushes finished vertices on a stack.  The second step is to transpose the graph, i.e. to reverse the direction of all edges.  In the third step we do again an all source DFS.  The vertices which are tried as roots of the DFS trees are popped from the stack of the first step.  Each resulting DFS tree represents a strongly connected component.

Informal description why the algorithm works: Recall that transposing a graph does not change the strongly connected components.  Let CTG denote the condensation of the tranposed graph.  The first step orders the input graphs vertices such that when then iterating over them and conceptually marking the CTG vertex in which they appear, the CTG vertices are marked in reverse topological sort order, i.e. from CTG sink to CTG source, not skipping over any CTG vertex in the CTG toposort sequence.  Note however that in the process we may encounter input graph vertices lying in any of the already marked CTG vertices.  Since no CTG vertex is skipped over, the second DFS in the algorithm is forced to stay within a CTG vertex.  It cannot discover input graph vertices lying in CTG ancestor vertices because by now they are already discovered.  It cannot discover input graph vertices lying in CTG descendant vertices, because that would be against the edge direction connecting CTG vertices.  Informal rational for why the 2nd DFS can't just use the 1st DFS post order sequence (i.e. not reversed) directly on the input graph (i.e. not transposed):  The input graph vertices at the beginning of the post order sequence (i.e. at the end of the reversed post order sequence) can be in any vertex of the condensed input graph, as opposed to just the sink,  thus the 2nd DFS potentially could leave a vertex of the condensed input graph.

--------------------------------------------------
  graph G              condensation of
                       transposed G
  1-->2-->4-->5-->7    1     4
  ^   |   ^   |   ^    2 <-- 5 <-- 7
  |   V   |   V   V    3     6     8
  +---3   +---6   8

  Some possible reverse DFS post order traversals of G.
  1 2 4 5 7 8 6 3   starting at 1
  1 2 3 4 5 6 7 8   starting at 1
  1 2 3 4 5 6 7 8   starting at 7, 4, 1
  2 3 1 6 4 5 7 8   starting at 7, 6, 2
--------------------------------------------------

References:

- Book ``Introduction to algorithms'', chapter ``Strongly connected components''.

- https://algointuition.wordpress.com/

- http://www2.nauk.si/files/894/adventes.pdf

- Book Algorithms (4th Edition), Sedgewick & Wayne, subchapter "Kosaraju's algorithm", p. 586

- https://www.slideshare.net/TraianRebedea/algorithm-design-and-complexity-course-8, starting at slide 11


[[tarjans_algorithm]]
==== Tarjan's algorithm (for finding strongly connected components)

Finds the strongly connected components of a directed graph in O(V+E) time.

*to-do*


==== Tarjan's algorithm for finding bridges

*to-do*

References:

- https://www.slideshare.net/TraianRebedea/algorithm-design-and-complexity-course-8, starting at slide 38


=== Graph coloring
*to-do*
Relation to four color problem?


[[flow_network]]
=== Flow networks

A _flow network_ (aka _transportation network_) is a directed connected simple graph with no antiparallel edges.  One vertex is denoted the _source_ and one vertex is denoted the _sink_.  Each edge has a _capacity_ ≥ 0 and a _flow_. The _capacity constraint_ dictates that the flow is ≥ 0 and cannot exceed the capacity.  The _flow conservation constraint_ dictates the the amount of flow into a node must equal the amount of flow out of it, unless the node is the source or the sink.

The _residual graph_ G~f~ induced by flow f conceptually has two edges for every edge in G. The forward (same direction as in G) edges capacity is c~e~-f~e~, the backward edges capacity is f~e~. However edges in G~f~ with capacity 0 are removed. The residual graph is almost a flow network just like the original graph, with the small difference, that now antiparallel edges are allowed.  An _augmenting path_ p is a path in the residual graph vom source to sink. The _residual capacity_ of such a path p is the minimal edge capacity on p.  An edge on p is said to be _critical_ if its capacity equals the residual capacity of p.

A __s-t edge cut__ is a partition of the graph's vertices into set S and T, S containing source and T containing sink.  The __edge-cut capacity__ is the sum of the capacities of edges from S to T, thus ignoring edges from T to S. The _net flow_ f(S,T) across the cut (S,T) is the sum of the flows of edges from S to T, minus the sum of the flows of edges from T to S.

Lemma: Given a flow in a flow network, the flow equals the net flow of any s-t cut. Figuratively: Any cut partitions the network in two networks, one containing the source, the other the sink.  The two groups are connected by two pipe bundles.  It's intuitive that the flow of these two pipe bundles equals the flow from source to sink.

[[max_flow_min_cut_theorem]]
__Max-flow min-cut theorem__: The following three are equivalent, given a graph G and a flow f: 1) f is a maximum flow in G 2) The residual network induced by f contains no augmenting path 3) There is a cut such that it's capacity equals the flow f. In other words, the maximum flow equals the capacity of the cut with the minimal capacity. Intuitively that becomes apparent having the previous lemma in mind: Since the capacity of a s-t cut is an upper limit of G's maximum flow, the maximum flow is bounded by the cut with the minimal capacity.

Convertions: A multi-source multi-sink flow network can easily be transformed to a single-source single-sink flow network by adding a consolidated source and a consolidated sink. Given an antiparallel edge pair, replace one of the two edges by figuratively inserting a new vertex in its middle, splitting the edge in two edges.  Given an undirected graph, replace each edge with an antiparallel edge pair, and then replace those as described bevore.

References:

- MIT course 6.046J, Design and Analysis of Algorithms (Spring 2015), Lecture 13 "Incremental Improvement: Max Flow, Min Cut":  https://www.youtube.com/watch?v=WwMz2fJwUCg&t=603s[video], https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-notes/MIT6_046JS15_lec13.pdf[lecture notes]

- CMU, Course 15-451/651 (Algorithms) Fall 2013, Lecture "Network Flows and Matchings I": https://www.cs.cmu.edu/~avrim/451f13/lectures/lect1003.pdf[lecture notes]

- Book ``Introduction to algorithms'', chapter ``flow networks''.


[[maximum_flow_problem]]
==== Maximum Flow Problems

_Maximum flow problems_ involve finding the maximum flow in a <<flow_network>>.  It can be seen as a special case of more complex problems, e.g. the circulation problem.

Solutions of max-flow:

- <<ford_fulkerson_algorithm>> in +O(E·f)+ (whereas f is the maximum flow) for the case where capacities are integers.

- <<edmonds_karp>> algorithm in +O(VE²)+ for the case where capacities are integers.

- _Dinic's_ algorithm runs in O(VE²) *to-do*

- An algorithm implementing the <<push_relabel>> approach. The generic version is +O(V²E)+, more specific version get better, the `highest label selection' has +O(V²√E)+

- *to-do* many more, especially blocking flow, see https://en.wikipedia.org/wiki/Maximum_flow_problem#Solutions


[[ford_fulkerson_method]]
==== Ford-Fulkerson method

The ford-fulkerson method is a greedy method which solves the <<maximum_flow_problem>>.  It's called a method opposed to algorithm since it's a template on which the more concrete algorithms are built.  *to-do*: why is it called a greedy algorithm? a) It does not choose the local best solution, it just picks _a_ solution b) it arguably undoes previous decisions by allowing `removing' already existing flow from an edge.

Overview: Search some path in the residual network, augment the current flow with the found path. Iterate until there is no augmenting path in the residual network.

--------------------------------------------------
ford-fulkerson-method(G:flownetwork, source:vertex, sink:vertex)
  flow = 0
  while there exists an augmenting path p in the residual network:
    augment flow along p
  return flow
--------------------------------------------------

If graph is undirected, see <<maximum_flow_problem>> for a transformation. If the capacities are rational numbers opposed to integers, transform by appropriately scale all capacities to turn them into integers.

Sending flow along the residual graphs backward edges means conceptually `undoing' decisions of previous iterations.

References:
- See <<flow_network>>
- Book ``Introduction to algorithms'', subchapter ``The Ford-Fulkerson Method''.


[[ford_fulkerson_algorithm]]
==== Ford-Fulkerson algorithm

An implementation of the <<ford_fulkerson_method>> which solves the <<maximum_flow_problem>> in +O(Ef)+.

--------------------------------------------------
ford-fulkerson-algorithm(G:flownetwork, source:vertex, sink:vertex)
  for each edge e in G:
    e.flow = 0
  while there exists an augmenting path ap in the residual network:
    rcp = min capacity of ap's edges // residual capacity of path ap
    for each edge re in ap:
      be e the corresponding edge in G
      if re is an forward edge: e.flow += rcp
      else (i.e. backward)    : e.flow -= rcp
  return flow
--------------------------------------------------

Analysis: In the worst case, mind that all capacities are integers, the residual capacity is 1, so there are +O(f)+ iterations. Each iteration takes +O(E)+, so the overall cost is +O(Ef)+, i.e. pseudo-polynomial. The reason is that the algorithm allows that in each iteration, a silly augmenting path is choosen, while there might be much better augmenting paths.

References:

- See <<flow_network>>


[[edmonds_karp]]
==== Edmonds-Karp algorithm

An specialiation of the <<ford_fulkerson_algorithm>> which solves the <<maximum_flow_problem>> in ++O(VE²)++. It is a specialication by specifying that the augmenting path is to be found by a breadth-first-search (O(V+E)=O(E)) (i.e. searching the shortest path where each edge has weight 1).

Analysis: Each iteration is +O(E)+. It's proofable that the number of iterations
is +O(VE)+. Thus the overal running time is +O(VE²)+.  The mentioned proof is based upon that once a critical edge is removed from residual network, it proofably can reappear only a certain mount of times. Also, the shortest path distance in the residual network from source to sink proofably increases monotonically after each augmentation / iteration.

Intution in what way we want to improve the ford-fulkerson algorithm: If in the residual graph there is no augmenting path, i.e. source and sink are disconnected, then we found the maximum flow. Thus we strive for increasing the distance (edge weights 1) between the source and the sink.

References:

- See <<flow_network>>
- CMU, Course 15-451/651 (Algorithms) Fall 2013, Lecture "Network Flows II: Edmonds-Karp 1, Edmonds-Karp 2, and blocking flows": https://www.cs.cmu.edu/~avrim/451f13/lectures/lect1008.pdf[lecture notes]


[[push_relabel]]
==== Push-relabel algorithms

Is an algorithm which solves the <<maximum_flow_problem>>. Is considered one of the most efficient maximum flow algorithms. The generic algorithm has +O(V²E)+, the variant based on the highest label node selection rule has +O(V²√E)+.

Concepts: A _preflow_ is like a flow, only that the flow conservation constraint is relaxed: The flow into a vertex may exceed the flow out of a vertex.  The _excess flow_ of a vertex is the difference between flow in and flow out. Note that in most physical analogies, the capacity is a quantity per time, and so is excess. An excess of 3 thus means that 3 units accumulate per unit of time in the given vertex.  Most authors describe that figuratively, each vertex has a reservoir of infinite size.  Alternatively figuratively an excess flow means that a vertex is leaking.  In a regular flow all excess flows are 0.  In a preflow they are ≥ 0. An vertex other than source or think is said to be _overflowing_ (aka _active_) if its excess flow is > 0.  Each vertex as a _height_, which is an integer. The source has always height |V|. The sink has always height 0.  All other vertices start at height 0 and potentially raise over time.  They never decrease.  In the residual graph, edges can go downhill by at most 1. They can be flat an go uphill.  An edge in the residual graph is _admissible_ if it's downhill. Since edges in the residual graph can go downhill
only by at most one (see above definition of height), admissible edges go downhill exactly by one. Recall that in the residual graph, all capacities are > 0.  To _push (excess) flow_ means decreasing the excess flow of a vertex by sending flow through an outgoing unsaturated downhill edge in the residual network.  That increases the excess flow in the receiving vertex by the same amount.  To _relabel_ a vertex means to increase its height to one unit more than the lowest of its direct successors to which there's an unsaturated pipe.

Intuition: The algorithm starts by setting height of source to |V|, and all other vertices to 0, flooding all out edges of the source to their capacity. The residual graph now is almost identical to the original graph, only that source's edges are reversed. All direct successors of the source are overflowing. We iteratively try to turn all remaining overflowing vertices into non-overflowing vertices, in which case the preflow proofably is the maximum flow. We do that by moving (part of) the excess flow to an direct successor vertex. More concretely by pushing flow downhill through an admissible edge in the residual graph. And if that is not possible because the overflowing vertex has no admissible outgoing edges, by relabeling it.  Ultimatively all excess flow is pushed either to the sink or to the source,  which by definition have no excess flow.  In other words, the algorithm tries to turn the initial preflow into a flow (no more overflowing vertices), which proofably will then be a maximum flow.

*to-do*: why to encode in the description and in the pseudo code that source and think don't have an excess flow?


--------------------------------------------------
push-relabel(G:flownetwork)
  init(G)
  while there is an overflowing node u
    If u has an admissible outgoing edge v in the residual graph: push(u, v)
    else: relabel(u)

// precondition:
//   u is overflowing
//   residual edge (u,v) is admissible
push(u:vertex, v:vertex)
  oe = edge(u,v) in original graph
  re = edge(u,v) in residual graph
  df = min(u.excess, re.capacity)
  if e is an forward edge: oe.flow += df
  else                   : oe.flow -= df
  u.excess -= d
  v.excess += d

// precondition:
//   u is overflowing
//   u has no admissible outgoing edge in the residual graph
relabel(u:vertex)
  u.height = 1 + (minimal height among u's direct successors in residual graph)
--------------------------------------------------

Compare and contrast the push-relabel approach with the augmenting path approach: Augmengting path maintains the invariant feasability, i.e. the conservation and the capacity constraints. The goal is to reach a residual graph where the source and the sink are disconnected; i.e. we are trying to get better and better flows. Push-relabel is the exact opposite: The invariant is that in the residual graph source and sink are disconnected. The goal is restoring feasability, or in other words, transform the preflow into a flow. I.e. push-relabel first relaxes feasability, and then tries to restore it.


References:

- See <<flow_network>>
- CMU, Course 15-451/651 (Algorithms) Fall 2013, Lecture "Network Flows III: Push-relabel flow algorithms, and Min-Cost Max-Flow.": https://www.cs.cmu.edu/~avrim/451f13/lectures/lect1010.pdf[lecture notes]
- Book ``Introduction to algorithms'', chapters ``Push-relabel algorithms'' and ``The relabel-to-front algorithm''.


== Computational Geometry

A subset S of the plane is called _convex_ iff for any pair of points p,q ∊ S the linesegment pq is completely contained in S.  Given a set S, the _convex hull_ 𝒞ℋ(S) is the smallest convex set that contains S.  Alternatively, the convex hull is the unique convex polygon whose vertices are points from S and that contains all points of S.

__Determining the orientation of an ordered point triple (p1, p2, p3)__: Intuition: If slope(p2, p3) > slope(p1, p3), the orientation is clockwise. Using the formula for slope, Δy/Δx, and simple transformations delivers the formula used in the pseudo code below. Alternatively, one can look at `cross product' (when defined as just the determinant, rather than a vector) of (p1-p2) ⨯ (p3-p1).

----------------------------------------------------------------------
enum Orientation { colinear, clockwise, counterclockwise  }
orientation(p1: point, p2: point, p3: point): Orientation
  val = (p2.y - p1.y) * (p3.x - p2.x) -
        (p2.x - p1.x) * (p3.y - p2.y);
  if val==0: return colinear;
  if val>0 : return clockwise;
  else     : return counterclockwise;
----------------------------------------------------------------------

_Order points p2 and p3 around a point p1_: From the viewpoint of point p1, determine wether point p2 is right of point p3.  Or equivalently, from the viewpoint of p1, determine  wether line (p1, p2) is right of line (p1, p3).

----------------------------------------------------------------------
is2ndRightOf3rd(p1: point, p2: point, p3: point): bool
  return orientation(p1, p2, p3) == counterclockwise
----------------------------------------------------------------------

_Determine whether two line segments intersect_: Assumption for simplicity: no three point lie on a common line.  The general case is not significantly more complex.  Two line segments (p1, p2) and (q1, q2) intersect iff p1 and p2 are on opposite sides of line (not segment) (q1, q2) and q1 and q2 are on opposite sides of the line (p1, p2). p1 and p2 are on opposite sides of the line (q1, q2) iff exactly one of the two triples (p1, q1, q2) and (p2, q1, q2) is in counterclockwise order.

----------------------------------------------------------------------
// returns true if segment (p1, p2) and (q1, q2) intersect
intersect(p1: point, p2: point, q1: point, q2: point): bool
  if orientation(p1, q1, q2) == orientation(p2, q1, q2): return false
  if orientation(q1, p1, p2) == orientation(q2, p1, p2): return false
 return true
----------------------------------------------------------------------

In _sweeping_, an imaginary vertical sweep line pases through the given set of geometric objects, usually from left to right.  We treat the spatial dimension that the sweep line moves across, in this case the x-dimension, as a dimension of time.  Sweeping provides a method for ordering geometric objects.

References:

- Book "Computational Geometry - Algorithms and Applications", aka 4M.

- Book "Introduction to algorithms", chapter "Computational Geometry".

- MIT course 2.158J / 1.128J / 16.940J "computational geometry"

  * spring 2003: https://ocw.mit.edu/courses/mechanical-engineering/2-158j-computational-geometry-spring-2003/

- MIT 6.838 "Geometric Computation"

  * fall 2003: https://people.csail.mit.edu/indyk/6.838/

- UMD course CMSC 754 "Computational Geometry",  https://www.cs.umd.edu/class/spring2012/cmsc754/Lects/cmsc754-lects.pdf

- http://jeffe.cs.illinois.edu/teaching/373/notes/allnotes.pdf, Non-lecture notes at the end.

- http://www.cs.umd.edu/~mount/754/Lects/754lects.pdf


=== Convex hull

The convex hull problem asks for the set of points forming the convex hull, given a set of points.  Often the algorithms return the convex hull not only as a set of points, but as a sequence of points constituting the convex hull polygon.

Algorithm's which find the convex hull, h being number of points on the convex hull:

- <<jarvis_march>> in O(nh)

- <<grahams_scan>> in O(n log n)

- Given an voronoi digram in O(h). The points on the convex hull are the sites which have the site at infinity as a nearest neighbor.  Equivalently, a site is on the convex hull iff its face is unbounded.


[[jarvis_march]]
==== Jarvis's march

_Jarvis's march_ (or _Jarvis's algorithm_, or _gift wrapping algorithm_) finds the <<convex_hull>> of a set of points in O(nh). h is the number of points on the convex hull.

Intuition: Start by finding any point which is known to be on the convex hull, e.g. the leftmost point.  An outer loop keeps adding the proper next point to the hull sequence until the hull cycle is closed.  An inner loop finds this next point the same way one finds the maximum element in a set.  Here, the `maximum' is the point which is furthest to the right from the perspective of the current point, looking at the other points.  Note that Jarvis's march resembles selection sort.  Both repeatedly find the item that goes in the solution's next slot.

Assumptions for simplicity: no three points lie on a common line, rounding error problems ignored, points.size <= 3 ignored.

----------------------------------------------------------------------
jarvis_march(points, hullpoints[out])
  leftmost = iteratively search leftmost point in points
  current = leftmost
  do
    hullpoints.append(current)
    tentativenext = any point but current
    for each point i in points
      if is2ndRightOf3rd(current, i, tentativenext)
        tentativenext = i
    current = tentativenext
  until current = leftmost
----------------------------------------------------------------------

Analysis: O(nh) time, where h is the number of points on the convex hull.  It's thus an output-sensitive algorithm. Proof: The outer iteration makes O(h) iteretions.  The inner loop makes O(n) iterations.


References:

- https://www.geeksforgeeks.org/convex-hull-set-1-jarviss-algorithm-or-wrapping/

- http://jeffe.cs.illinois.edu/teaching/373/notes/x05-convexhull.pdf


[[grahams_scan]]
==== Graham's scan

_Graham's scan_ finds the <<convex_hull>> of a set of points in O(n log n).

Assumptions for simplicity: no three points lie on a common line, rounding error problems ignored, points.size ≤ 3 ignored.

Find any point on the convex hull, e.g. the left-most point.  Sort the remaining points in counterclockwise order around that left-most point.  Connect all points in counterclockwise order, starting at the left-most point, resulting in a simple polygon with n vertices.

We transform the polygon into the convex hull using the `three-penny algorithm'.  We have three pennies, which sit on three consecutive vertices of the current polygon.  Initially, the first of the three pennies is on the left-most point.  We now iteratively apply the following two rules until a penny is moved forward onto the left-most point:

* If p1 p2 p3 are in counterclockwise order, move the penny on p1 to p3's successor.  Intuitively, we `advance' on the polygon because (p1, p2, p3) could be part of the convex hull because they are in counter clockwise order.

* Else, remove p2 from the polygon, add the edge (p1, p3) to the polygon, and move the penny on p2 to p1's predecessor.  Intuitively, we found a dent in the polygon and remove that dent.

--------------------------------------------------
three-penny(p: polygon)
  create a steack, push p[0], p[1], p[3]
  for i = 3 to p.size-1
    while orientation(stack.nextToTop(), stack.top(), p[i])==clockwise
      stack.pop()
    stack.push(p[i])  
  return stack
--------------------------------------------------

Analysis: O(n log n) time. Proof: The initial sorting takes O(n log n) time.  The three penny algorithm takes O(n) time:  The first rule moves a penny to a vertex that has never seen a penny before, so the first rule is applied at most n-2 times.  The 2nd rule removes a vertex from the polygon, so the 2nd rule is applied exactly n-h times.  h is the number of points on the convex hull.

References:

- http://jeffe.cs.illinois.edu/teaching/373/notes/x05-convexhull.pdf

- Chapter "Convex Hulls" in book "Computation Geometry - Algorithms and Applications". However, there a pretty diffrent version of Graham's scan is presented.

- Chapter "33.3 Finding the convex hull" in book "Introduction to Algorithms"


=== Line segment intersection

References:

- Book "Computational Geometry - Algorithms and Applications", chapter "line segment intersection"

- http://courses.csail.mit.edu/6.006/spring11/lectures/lec24.pdf

- https://people.csail.mit.edu/indyk/6.838/handouts/lec2.pdf

- https://www.youtube.com/watch?v=j6o8k5uM02c&index=2&list=PLe-ggMe31CTdBsRIw0hXln0hilRs-DqAx for the case of orthogonal line segments


==== Sweep line

Given a set of line segments, determine whether any pair of segments intersects, as opposed to report all intersecting line segments.

Assumptions for simplicity: No input segment is vertical.  No three input segments intersect at a single point.

The general idea is to only test those segments for intersection which are `close'.  The sweep line paradigm, moving it horizontally, ensures avoiding checking segments which don't overlap in x-direction.  Segments currently intersecting the sweep line are ordered after their intersection points with the sweep line, top to bottom.  Obviously those segments do overlapp in x-direction.  Among these x-overlapping segments, we only check those segment pairs for actual intersection, which are adjacent on the sweep line, i.e. which are adjacent in y-direction.

Create an _event point schedule_, which is a sequence of points, called _event points_. Here, the endpoints of the segments constitute the event points.  The ordering is from left to right, breaking ties left endpoint before right endpoint, breaking further ties top to bottom.

Process the event point schedule.  Imagine sweeping a vertical line from left to right, stoping at each event point.  We maintain a top-to-bottom ordered sequence of those line segments which currently intersect the sweep line.  That sequence is called _sweep-line status_.  The sequence can only change when the sweep line encounters and endpoint or an segment intersection.  When the sweep line encounters an left endpoint, the associated segment is inserted into the sequence.  We test whether the new segment intersects with any of its two neighbors.  When the sweep line encounters an right endpoint, remove its associated segment from the sequence.  We test whether the two new neighbors intersect.  Of course, whenever an intersection is found, we can terminate the algorithm.

--------------------------------------------------
any-intersections(points): bool
  eventschedule = points sorted from left to right
  // sweep line status, using isBelow (defined below) as comperator.
  sls = ∅
  for each point current_point in eventschedule:
    current_segment = segmentof(current_point)
    // for simplicity, successor / predecessor returning NIL is ignored
    if current_point is left endpoint:
      insert(sls, current_segment)
      if intersect(current_segment, successor(swt, current_segment)) or
         intersect(current_segment, predecessor(swt, current_segment)):
        return true
    else
      if intersect(successor(swt, current_segment), predecessor(swt, current_segment)):
        return true;
      remove(sls, current_segment)  
  return false
--------------------------------------------------

*to-do*: isBelow is only valid for a specific x-position of the sweep line, no? How can it then be used as comperator for the sweep line status datastructure? I believe it only works if left(s2).x <= left(s1).x <= right(s2).x.  Thus maybe first sort s1 s2 after left().x, and only then do the core comparision?

--------------------------------------------------
// returns true if leftendpoint(s1).x is below s2 at x-coordinate leftendpoint(s1).x
// precondition: leftendpoint(s2).x <= leftendpoint(s1).x <= rightendpoint(s2).x
isBelow(s1: segment, s2: segment)
  return orientation(leftendpoint(s2), rightendpoint(s2), leftendpoint(s1)) == clockwise
--------------------------------------------------

The data structure for the sweep line status should support the following operations in O(log n) time: insertion, deletion, find successor / precessor.  For example some sort of binary search tree.

Analysis: The running time is O(n log n).  The initial sorting takes O(n log n).  The sweep line stops at most at 2n endpoints, thus there are O(n) iterations.  Each operation on the sequence on the sequence requires O(log n). So the loop as a whole needs O(n log n), and the algorithm as a whole also O(n log n).

References:

- Book "Introducion to algorithms", subchapter "3.2 Determining whether any pair of segments intersects"

- http://jeffe.cs.illinois.edu/teaching/373/notes/x06-sweepline.pdf
 

[[rectangle_intersection]]
=== Orthogonal rectangle intersection search

Given a set of n orthogonal rectangles, find all intersections.


==== Sweep line paradigm

O(n log n + r log n) time, where r is the number of reported intersections.

Assumptions for simplicity: All x and y coordinates are distinct.

Events: x-coordinates of left and right endpoints.

Sort events after x-coordinates.

Sweep line status: Set of rectangles that intersect the sweep line.  More specifically, use an <<interval_tree>> to store the set of intervalls that result from these intersections.

Left end point event: Report all intervals in sweep line status intersecting the new interval (see <<interval_tree>>).  Add interval to sweep line status.

Right end point event: Remove perishing interval from sweep line status.

Analysis: O(n log n + r log n) time.  O(n log n) for the presorting.  An left end point event needs O(r~i~ log n) for finding all intersecting intervalls (r~i~ being number of reports for i-th event) and O(log n) for insertion.  An right end point needs O(log n) for removal.  So all events together need O(n log n +  r log n).

References:

- https://www.youtube.com/watch?v=LQ-vRetWnu4&list=PLe-ggMe31CTdBsRIw0hXln0hilRs-DqAx&index=5

- https://algo.kaust.edu.sa/documents/cs372l07.pdf


[[dcel]]
=== Doubly-Connected Edge List (DCEL)

Often used representation for planar subdivionis such as <<voronoi_diagram>>s.

References:

- http://www.cs.sfu.ca/~binay/813.2011/DCEL.pdf

- https://www.ti.inf.ethz.ch/ew/lehre/CG12/lecture/Chapter%205.pdf 


[[voronoi_diagram]]
=== Voronoi diagram

References:

- Book ``Computational Geometry - Algorithms and Applications'', chapter ``Voronoi Diagrams''


[[fortunes_algorithm]]
====  Fortune's algorithm

Fortune's algorithm is a sweep line algorithm for generating a Voronoi diagram from a set of points in a plane using O(n log n) time and O(n) space.

Site events: Static events. Correspond to the Voronoi sites.

Vertex events (or ciricle events): Dynamic events.  The goal is to dedect when the sweep line indirectly encounters a Voronoi vertex again, long after it actually encountered it.
Consider the three sites associated to three consecutive arcs on the beach line.  Recall the Voronoi vertex associated to these three sites is the center of the circumcircle for these three sites. The actual vertex event is the bottom most point of the circumcircle.

Event queue data: A priority queue with the y-coordinate of events as key.  A vertex event has a pointer to the three site events that generated it.

The partial Voronoi diagram that has been constructed so far is stored in an <<DECL>>.

Sweep line status: Actually conceptually it's more about the beach line.  In an <<associative_array>> we store the Voronoi sites having at last one associated parabolic arc on the beach line.

In other words, the middle arc of the three consecutive arcs on the beach line just has disappeared, the two Voronoi edges it traced out now coincide in a Voronoi vertex.

*to-do*

References:

- Book ``Computational Geometry - Algorithms and Applications'', chapter ``Computing the Voronoi Diagram''

- http://people.math.gatech.edu/~randall/Algs07/mount.pdf

- http://www.cs.sfu.ca/~binay/813.2011/Fortune.pdf


[[delaunay_triangulation]]
=== Delaunay triangulation (DT)

References:

- Book "Computational Geometry - Algorithms and Applications", chapter "?????"

- Chapter "Lecture 17: Delaunay triangulation" in http://www.cs.umd.edu/~mount/754/Lects/754lects.pdf


=== Nearest neighbor search (NNN)

*to-do*:


[[closet_pair_of_points]]
=== Closest pair of points

Solutions:

- Deleauny triangulation O(n)

- Voronoi diagram O(n)

- <<closest_pair_of_points_divide_and_conquer>>


[[closest_pair_of_points_divide_and_conquer]]
==== Divide and conquer with presorting both in x and y

Solves the <<closet_pair_of_points>> problem in O(n log n).

Preparation: Sort set of input points by x coordinates → PointsXS. In another container also sort them by y coordinates → PointsYS. The recursive divide and conquer function gets both PointsXS and PointsYS as input parameters.

Base case: n≤3 points. Solve with brute force, i.e. compare all pairs and choose the pair with the smaller distance.

Divide: Partition PointsXS into two equal sized still x-sorted subsets around an imaginary vertical line.  Note that multiple points can lie on that line, and both partitions can contain points on that line.  This is trivial since PointsXS is already sorted in x direction.  Distribute PointsYS into two still y-sorted subsets PointsYSLeft and PointsYSRight.  Points being in PointsXSLeft go to PointsYSLeft, the others to PointsYSRight.

Conquer: Make two recursive calls, one with (PointsXSLeft, PointsYSLeft) as arguments, one with (PointsXSRight, PointsYSRight) as arguments. This delivers min_left and min_right.

Combine: Choose the smaller of min_left, min_right delivering min.  Now it's possible that there's a pair with a distance smaller than min in the vertical strip ±min around the vertical line from the devide step above.  One point of the pair being in the left half of the strip, the other in the right half.  Recall that points on the line can be in either partition.  From PointsYS extract those points being in the strip while keeping them y sorted, resulting in StripPointsYS.  For each point in StripPointsYS, compare it with all points further ahead in StripPointsYS which are at most min away in y direction.  It can be proven that there are at most 7 such points ahead.

--------------------------------------------------
closest_dist(points)
  sort points in x direction
  PointsYS = an y-sorted array of pointers to into points
  return closest_dist_core(points, 0, points.length-1, PointsYS)

closest_dist_core(AllPointsXS: points, from:int, to:int, PointsYS: point_pointers)
  if to-from+1 <= 3
    return closest_dist_brute_force(PointsYS)
  middle_index = (from + to) / 2
  PointsYSLeft, PointsYRLeft = ypartition(AllPointsXS, middle_index, PointsYS)
  min_left  = core(AllPointsXS, from, middle_index, PointsYSLeft)
  min_right = core(AllPointsXS, middle_index+1, to, PointsYSRight)
  min = min(min_left, min_right)
  return closest_dist_strip(min, AllPointsXS, middle_index, PointsYS)  

ypartition(AllPointsXS: points, middle_index:int, PointsYS: point_pointers)
  create two new arrays PointsYSLeft, PointsYSRight
  for each point p in PointsYS
    index = p - AllPointsXS // pointer arithmetic
    if index<=middle_index: PointsYSLeft.append(*p)
    else                  : PointsYSRight.append(*p)
  return PointsYSLeft, PointsYSRight

closest_dist_strip(min, AllPointsXS: points, middle_index:int, PointsYS: point_pointers)
  // Find points being in strip.
  // Note that since PointsYS is sorted, so is StripPointsYS
  xmiddle = AllPointsXS[middle_index].x
  StripPointsYS = new array of point-pointers
  for each point-pointer p in PointsYS
    if abs(p->x - xmiddle) < min
      StripPointsYS.append(*p)  

  for i=0 upto StripPointsYS.length-1
    j=i+1
    // Inner loop proofably makes at most 7 iterations. Note that we
    // also compare points being on the same strip side, which is needless,
    // but its not worth to make a special case.
    while (j<StripPointsYS.length) and (StripPointsYS[j]->y < StripPointsYS[i]->y+min)
      min = min(min, distance(*StripPointsYS[i], *StripPointsYS[j]))
      j++

  return min
--------------------------------------------------

Informal proof that closest_dist_strip's inner loop needs to check at most 7 points ahead: In the worst case, i.e. where the points are packed as dense as possible, the situation looks like in the following diagram. ❍ is the currently checked point as determined by the outer loop, ➊ is the point one ahead, ➌ is three ahead and so on.  Recall that the points are sorted in y.  In this worst case scenario, the 1st and 2nd point coincide; 1st being part of the left partition, 2nd being part of the right partition.  Likewise for 5th and 6th.  We don't need to consider points further ahead, because their y distance to ❍ would be larger than min.  Thus at most 7 points are ahead with a y distance smaller than min.  Personal note:  As far as I understand it, 7 is an upper bound, but maybe not tight.  With more complicated math, we might be able to prove that there are even less considerable points ahead.  But it's really only about proving that it is a constant number of points we have to consider at most.  That results in O(n) for closest_dist_strip.  If we didn't had this proof, it would be O(n²), since we had to assume having to compare every point in the strip with every other in the worst case.

--------------------------------------------------
     vertical
      line
       ‖
  ❍----➊----➌    Each horizontal / vertical
       ‖          neighboring pair is min appart
       ‖
       ‖
       ‖
  ➍----➎----➐
       ‖
--------------------------------------------------


References:

- https://www.geeksforgeeks.org/closest-pair-of-points-onlogn-implementation/

- Book ``Introduction to algorithms'', subchapter ``Finding the closest pair of points''.


==== Divide and conquer with presorting only in x

Solves the <<closest_pair_of_points>> problem in O(n log² n).  Is the simpler version of the previous algorithm.  The points are not presorted in y.  Thus also we don't need to maintain a sequence of y sorted points in closest_dist_core.  However now closest_dist_strip needs to y-sort the points within the strip.

References:

- https://www.geeksforgeeks.org/closest-pair-of-points/

- http://cse.unl.edu/~ylu/raik283/notes/ClosestPair.ppt


== Computer arithmetic

Typical assymptotic bounds analysis: It is assumed that one digit operations can be done in constant time.  However in practice, on an for example 32 bit computer architecture, already operations on 32 bit numbers can be done in constant time.  So that is the base case of algorithms dividing the problem in subproblems.


=== Arbitrary-precision arithmetic

See also:

- The GNU Multiple Precision Arithmetic Library: https://gmplib.org/


=== Arbitrary-precision integer multiplication

The task is to multiply n-digit factors. The radix is typically irrelevant.

Multiplication is an important base case.  E.g. high precission division a / b is typically implemented by multiplying a · 1/b.  Roots are implemented via Newton's method, which then also comes down to multiplication and addition.

Algorithms:

- The standard grad-school multiplication algorithm is O(n²).

- _Karatsuba algorithm_ is O(n^log~2~ 3^) ≈ O(n^1.58^).  Instead of multiplying x · y directly, split the factors in numbers being half the digits large.  The multiplication then becomes (x~1~r^n/2^+x~0~) · (y~1~r^n/2^+y~0~), where r is the radix.  Multiplying out, sorting after r polynomials, results in four multiplications of n/2 digit numbers, and a few additions and subtractions.  A bit of cleverness reuses two multiplications, so one multiplication can be saved, resulting in an overall of three multiplications.  Recurse.  Converges quadratically, i.e. the number of known digits in the result doubles in each step.

- _Toom-Cook algorithm_ is O(n^log~3~ 5^) ≈ O(n^1.46^).  Generalizes Karatsube by splitting a factor in k parts opposed to exactly two.  The given asymptotic bounds are for k=3.

- _Schönhage–Strassen algorithm_, fast fourier transformation based, in O(n log(n) log(log(n))).

- Simplified rough answer: we can multiply in approximately O(n log n)


References:

- MIT course 6.006 "Introduction to Algorithms", Fall 2011, Lecture 11 Integer Arithmetic, Karatsuba Multiplication: https://www.youtube.com/watch?v=eCaXlAaN2uE.


=== Arbitrary-precision integer division

==== Newton–Raphson division

Instead of directly calculating a / b, we calculate a · floor(R/b), where R is a large number, and it is easy to divide by R. E.g. R is a power of two. We calculate R/b via Newton's method: f(x) = 1/x - b/R is zero at R/b.  Newton's method then tells us that the zero can be iteratively calculated by x~i+i~ = 2x~i~ - bx~i~²/R.

Calculating R/b this way converges quadratically, i.e. the number of known digits in the result doubles in each step.

Analysis: Runs in O(n^α^), assuming multiplications can be done in O(n^α^).  I.e. the same asymptotic complexity as multiplication, however with a higher hidden constant factor.  You could think that it runs in O(log n · n^α^), because due to the quadratic convergence, we need log n iterations, and each iteration runs in O(n^α^) since it only consists of multiplactions, divisions, and an easy division.  However observe that the number of digits we need to compute in each iteration, again due to quatdratic convergence, is only {1, 2, 4, ..., n/4, n/2, n}.  That sums up to 2n^α^.

References:

- MIT course 6.006 "Introduction to Algorithms", Fall 2011, Lecture 12. Square Roots, Newton's Method: https://www.youtube.com/watch?v=2YeJ-5UAke8&t=1400s


=== Bit manipulation
A _nibble_ is a four bit aggregation (aka _halb-byte_ or quartet).

--------------------------------------------------
set:    x |=  y
clear:  x &= ~y
toggle: x ^=  y
test:   x &   y
--------------------------------------------------

In C / C&plus;&plus;, +CHAR_BIT+ is the number of bits in a byte.

- http://graphics.stanford.edu/~seander/bithacks.html


== Misc. related computer science


=== NFA
*to-do*:


=== DFA
*to-do*:


=== DAFSA
*to-do*:


== References

- Book "Algorithms" (4th Edition), Sedgewick & Wayne: https://algs4.cs.princeton.edu/home/

 * Closely related: Princeton university, Course Algorithms and Data Structures,
https://www.youtube.com/playlist?list=PLxc4gS-_A5VDvP_9W8JJ04zk6m1qTolzG

- Book "Introduction to algorithms" aka CLRS (3rd Edition), Cormen, Leiserson, Rivest, Stein

- MIT course 6.006 Introduction to Algorithms: 
  * Umbrella over all semesters: https://courses.csail.mit.edu/6.006
  * Fall '11: https://courses.csail.mit.edu/6.006/fall11/notes.shtml[lecture notes], https://www.youtube.com/playlist?list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb[videos]

- MIT course 6.046J / 18.410J: In 2015 called "Design and Analysis of Algorithms", before "Introduction to Algorithms (SMA 5503)". Aparantly in '15 it's an advanced course between 6.006 and 6.851, before it was a course similar to 6.006.
 * Spring '15: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-notes/[lecture notes], https://www.youtube.com/playlist?list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp[videos]
 * Fall '05: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/index.htm[OCW home page], https://www.youtube.com/playlist?list=PL81A705FB7F988E7C[videos]

- MIT course 6.851 Advanced Data Structures:
  * Umbrella over all semesters: https://courses.csail.mit.edu/6.851/
  * Spring '12: https://courses.csail.mit.edu/6.851/spring12/lectures/[lecture notes], https://www.youtube.com/playlist?list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf[videos]

- MIT course 6.854 Advanced Algorithms
  * Spring '16: https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c[videos]
  * Unknown date: https://www.youtube.com/playlist?list=PLXzW9t1q_fb_3k_KzBfBnw0NXjvq45-bf[videos]

- https://www.cs.usfca.edu/~galles/visualization/

- https://www.quora.com/What-are-the-very-basic-algorithms-that-every-Computer-Science-student-must-be-aware-of

- Book ``Algorithmics for Hard Problems: Introduction to Combinatorial Optimization, Randomization, Approximation, and Heuristics'', 2nd Edition, Juray Hromkovič. The Introduction chapter serves as good summary of computer science fundamentals.

// Local Variables:
// eval: (visual-line-mode 1)
// eval: (auto-fill-mode -1)
// eval: (filladapt-mode -1)
// End:

//  LocalWords:  pre th ADT Multimap multihash multimap emptyCount fullCount
//  LocalWords:  useQueue putItemIntoQueue getItemFromQueue Treap DAFSA Deque
//  LocalWords:  BST spw spwfs decreaseKey spt dest unicursal eulerian NPC
//  LocalWords:  Königsberg Hierholzer's subgraph supergraph Horner Horner's
//  LocalWords:  adaptors acc umulator Quickselect supremum infimum CLRS DFS
//  LocalWords:  AStarMonotonicH AStar toposort topsort BSF ith preorder args
//  LocalWords:  inorder Sedgewick Karp textlen patternlen patternhash str
//  LocalWords:  texthash issubstring rollinghash len BFS MyStack prev Thorup
//  LocalWords:  Brodal mergeable
