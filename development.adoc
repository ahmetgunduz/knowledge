:encoding: UTF-8
// The markup language of this document is AsciiDoc

== CPU cache hierarchy

- Know which basic operations (acess (next, n-th, ...), insert, delete, find,
...) you do how often relative to each other. Mind that to e.g. insert/delete
an element, often you first have to find it first.
- Know how many items are in your collection.
- Know the characteristics of the underlying hardware. E.g. how expensive a CPU
cache miss is, how big the CPU cache is etc. Mind the prefetcher which gives
an additional cache level of infinite size _if_ memory is accessed
sequencially
- With the HW information and having an idea of the implementation details of an
algorithm you can estimate the hidden constant factors of the big O analysis
(in space and time, time affected by space due to CPU cache / memory
properties). Knowing which basic operations you do how often allows you to do
a big O analysis of the overall-task, inclusive an estimate of the hidden
factor. You also know for range of container size you have to do this overall
big O analysis.
* With todays consumer electronics CPU's, a CPU cache miss is in the range of
a few hundreds times slower than reading directly from cache.

The example. Per element:
1 insert-in-order (=find element just before the one to be inserted, insert), 1 find-nth, 1 remove.
Vector list and map all have O(n) overall, but vector has much smaller constant factor (a few hundreds times) because it accesses memory sequencially. List and map have high factor because they randomly access memory locations.  One of the things to note is that the overall O(n) is not very obvious for list, even less so for map.

Order statistic tree

- What is ``cache-friendly'' code?

== Performance measurements

- Glen suggests the tool `code performance'
- perf
 * http://www.brendangregg.com/linuxperf.html
 * off-cpu: http://www.brendangregg.com/offcpuanalysis.html
- strace / ltrace
- valgrind, cachegrind, callgrind, ...
- kcachegrind
- oprofile
- gprof
- systemtab
- dtrace
- Intel® VTune™ Amplifier 2016: https://software.intel.com/en-us/intel-vtune-amplifier-xe/try-buy


=== Brainstorming

* Measure first, tune what matters.  If you don't have all the relevant
  information, you can't make the right decision, and you can't have the
  right information until you measure.

* While using CPU or a ressource in general
 - Efficiency: Do the minimum amount of work needed to accomplish the task

* Reduce the amount of time the CPU is not used to accomplish my task/work
  - Reduce unproductively waiting for IO
  - Reduce unproductively waiting for `memory' access. I.e. data should come from registers / cpu cache hierarchy / RAM in that order.
    ** Mind false sharing
    ** Mind page faults / trashing
  - Reduce waiting time to be scheduled for CPU. I.e. reduce contention with other processes / threads.
  - Reduce waiting time on locks

* Use all ressources which can accomplish work
 - All cores / cpus.
 - All io devices
 - All of faster storage before using slower storage (register, cpu cache, ram, disk, network)

* Make use of ressources efficiently. Use ressources the way they can operate the fastest
 - Sequencial access (disk, ram)
 - CPU / branche prediction: Conditional branches shall take the same branch in a row, and only seldom switch to taking the other one.


=== perf

As root, edit +++/etc/sysctl.conf+++, add the line +++kernel.perf_event_paranoid = -1+++, make it `active' with +++sysctl -p+++. See also http://unix.stackexchange.com/questions/14227/do-i-need-root-admin-permissions-to-run-userspace-perf-tool-perf-events-ar, http://www.cyberciti.biz/faq/howto-set-sysctl-variables/

Use the option -fno-omit-frame-pointer to compile.

++++++++++++++++++++++++++++++++++++++++++++++++++
perf record -g -s mycommand_and_args
perf report -g -T
++++++++++++++++++++++++++++++++++++++++++++++++++

+perf top+

==== Questions

- what does perf's children column really mean? I think it should mean 'percentage of all samples where this function is on the call stack'. But grepping e.g. BOGetKurs on the folded perf output and counting number of found lines I cannot verify that.

- where is my process/thread not doing anything but waiting

- perf-chidren of getBOKurs


=== Ressources
- http://www.linuxprogrammingblog.com/io-profiling[Profiling Input/Output performance]
- http://stackoverflow.com/questions/375913/what-can-i-use-to-profile-c-code-in-linux
- https://www.youtube.com/watch?v=fHNmRkzxHWs[Chandler Carruth "Efficiency with Algorithms Performance with Data Structures"]

== Inlining / (virtual) function call

- Instructions for a function call
 * Push registers on stack which are used by caller and might be modified by callee
 * Pass paremeters: Some are passed in registers, others by pushing them on the stack. For some, what is passed is not the object itself, but it's address.
 * Pass return object's address as implicit parameter, see above.
 * Frame stuff, push IP (i.e. return addr), ...
 * Actuall call instruction
 * For the parameters not passed by registers, callee must read them from stack.
 * Frame stuff, ...
 * Return instruction

- What does virtual add to the above?

- When inlining, (much) more optimizations can be done.

- When the produced code at call site for inlining is larger than the produced code for a function call (both times the optimized result). A larger footprint is the result. It's possible that more cpu cache misses result.

- C&plus;&plus;: +inline+ is a hint for the compiler to inline (and most compilers flat out ignore it since they know better), and a command to the linker.

- C&plus;&plus;: For inlining to work, the definition must be known to the compiler, i.e. the definition must be in the header [however there is also Time Optimization (LTO), and as part of that inlining]. That introduces compile time dependencies, and thus potentially slower builds.

- Virtual function call is an indirection at run-time.
 - Thus it makes live harder for (branch etc) prediction.
 - Two additional memory accesses (virtual function pointer and function's address), both of which might result in CPU cache misses. However there is prediction on that too: http://stackoverflow.com/questions/2141726/can-you-cache-a-virtual-function-lookup-in-c
 - Inlining is no longer possible



- http://stackoverflow.com/questions/1759300/when-should-i-write-the-keyword-inline-for-a-function-method
- http://stackoverflow.com/questions/145838/benefits-of-inline-functions-in-c


== call stack

A _stack frame_ (aka _frame_ aka _activation record_) contains information for
a function: its parameters, pushed IP (instruction pointer, the value in the
stack frame is often called _return adress_), pushed BP, its locals.

Register BP (_base pointer_ aka FP (_frame pointer_)) points to top stack
frame, i.e. the stack frame of the current function. The current function thus
can access its params and locals with a constant offsets relative to BP. If
there was only SP, the offsets of locals and params releative to SP would
change after each modification of SP. E.g. consider +alloca+.

This forms a singly linked list, where the register BP is the pointer to the
head, and the BP member of each stack frame is the pointer to the next stack
frame.

In this visualization the stack grows upwards:

--------------------------------------------------
frames     stack                         registers   text
        addr  description                            ----------
----------------------------------------             f2:
f2's    35    local 2 of f2               <-- SP     .. ...
frame   36    local 1 of f2                   IP---->.. ...
        37 /--prev frame / f1's pushed BP <-- BP     .. ...
        38 |  ret addr / f1's pushed IP ------+      .. ...
        39 |  param 2 for f2                  |      .. ...
        3A |  param 1 for f2                  |      ----------
--------   |                                  |      f1:
f1's    3B |  local 2 of f1                   |      .. ...
frame   3C \  local 1 of f1                   +----->.. call f2
        3D  =>prev frame / f0's pushed BP            .. ...
        3E /  ret addr / f0's pushed IP ------+      .. ...
        3F |  param 2 for f1                  |      ----------
        40 |  param 1 for f1                  |      f0:
--------   |                                  |      .. ...
...     41 |  ...                             +----->.. call f1
        42 \=>BP ...                                 .. ...
--------------------------------------------------

A typical sequence of events might look like this:

--------------------------------------------------
   function call                           return from function
1. push params (decreases SP)              10. SP += sizeof(params)
2. call fun (pushes IP,                    9. return (pops IP,
           decreases SP,                           increases SP)
           reseats IP)
3. push BP (decreases SP)                  8. pop BP
4. BP = SP                                 7. SP = BP
5. alloc locals (decrease SP)              6. -
--------------------------------------------------


References:
- http://www.cs.princeton.edu/courses/archive/spr06/cos320/notes/Stack-handout.pdf


=== Howto use a stack trace (aka stack backtrace)

1. extract function name from stacktrace
+
  [01]: 0x00002b162f974735 BOBuchhaltungTaskWorker::adhoc(BOManager*, BOBuchhaltungTaskDataElement*)+0x85 (at 0x00002b162f974735 in /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so)

2. get relative address of that function symbol
+
  $ nm /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so | c++filt | grep BOBuchhaltungTaskWorker::adhoc
  000000000074f6b0 T BOBuchhaltungTaskWorker::adhoc(BOManager*, BOBuchhaltungTaskDataElement*)

3. use gdb to disassemble the function
+
  gdb /home/xentis/xentis/packages/XENTIS/lib/libAmisBO.so
  disass 0x000000000074f6b0

4. stacktrace said its the instruction with offest +0x85 (+133 dec), so in the disassembly:
+
   0x000000000074f735 <+133>:	mov    (%r12),%rax


== Error handling

Use asserts for conditions during development that can never be true if all your code is correct. `cannot be' means `will never happen if the program is correct', or `it is under my control'. Then again who is `my', what parts of the program are we talking about? When an exception fires it means that the program is in an ill state and data might be corrupt. It makes no sense to continue the current unit of work on such a basis. I.e. don't use asserts to check preconditions (since in the release version the check wont be there and the precondition would be violated).



Better talk about unit of work (program/progress/thread/cmd of loop/function) than of program.

Depending on the program
- The user prefers that the program gracefully continues, altough it doesn't do exactly what it should. The displayed/outputed data might be incorrect.
- The user prefers that the behaviour/data of the program is absolutely correct. He can better tolerate that the program terminates, maybe even ungracefully.


- https://msdn.microsoft.com/en-us/library/hh279678.aspx[Errors and Exception Handling (Modern C++)]



== Static / Dynamic code analysis

https://clang.llvm.org/docs/index.html


=== clang tidy

clang-tidy is a LibTooling-based tool. It can be used as a frontend for the static analyzer checkers (clang-analyzer-*).


=== clang static analizer

Tutorial

- scan-build cmake ...
- scan-build [generator-cmd, e.g. make] ...
- Note: QtCreator has `running clang static analyzer' conveniently integrated. *to-do*: how about eclipse?



Notes:

- The `clang --analyze' command should be viewed as an implementation detail. You should rely on scan-build.


=== AddressSanitizer (ASan)

Memory error dedector. But _not_ a leak dedector, however apparently LeakSanitizer is integrated by default.

- Needs compiler instrumentation module. Available at least for gcc (4.8) and clang (3.1). Compile with -fsanitize=address.
- Needs a runtime lib which replaces the malloc/free functions. Link with -fsanitize=address (use clang++, not ld, says the manual).
- Allows to ignore certain functions. One can use the no_sanitize_address attribute supported by Clang (3.3+) and GCC (4.8+).
- Allegedly has no false positives
- Apparently relatively fast. Slowdown ~2x.
- Uses a lot of memory. Stack ~3x, heap depends on allocation sizes (larger relative overhead for smaller allocations).

Consequences:

- Does not handle libraries built without -fsanitize=address (because asan depends on compiler instrumentation module)

Recommendations:

- Better stack traces: compile with -fno-omit-frame-pointer -fno-optimize-sibling-calls -O1 (to disable inlining)
- -01 for acceptable performance
- Set env variable ASAN_SYMBOLIZER_PATH to path of llvm-symbolizer to symbolize output
- Enable address-use-after-scope: Compile with -fsanitize-address-use-after-scope. To turn off at runtime: Env variable ASAN_OPTIONS=detect_stack_use_after_scope=0 (colon separated)
- redzone size of up to 128: ASAN_OPTIONS=redzone=128 (colon separated)
- debuggig:
 * stop before an asan error: breakpoint on __asan::ReportGenericError.
 * stop after asan error: breakpoint on __sanitizer::Die or use ASAN_OPTIONS=abort_on_error=1.
- Env variable ASAN_OPTIONS=check_initialization_order=1.


=== LeakSanitizer (LSan)

Run-time memory leak detector. Integrated into AddressSanitizer, see there. To use LSan in standalone mode, link with -fsanitize=leak.


=== Undefinded behaviour sanitizer (UBSan)

- Modifies program at compile time. Compile with -fsanitize=undefined (clang 3.3). (gcc also has this option, but I don't know if it's the same sanitizer)
 * Enables all checks other than unsigned-integer-overflow and the nullability-*.

Recommendations:
- Nicer stack trace: Compile with -g -fno-omit-frame-pointer. Run with env variable UBSAN_OPTIONS=print_stacktrace=1. Make sure llvm-symbolizer binary is in PATH.


=== cppchecker

=== valgrind


==== general

- Essentially a virtual machine using JIT.
- Liscence: GNU GPL
- Widely used

Limitations:
- Memcheck doesn't do bounds checking on globals or local arrays.

Consequences:

- Any executable can be run, i.e. it's language/compiler agnostic.
- 100% of user space is covered. I.e. also parts you don't have the source code for, e.g. certain libraries.

Recommendations / tips:

- Compile with -g, -fno-omit-frame-pointer, -O0 or -O1, and don't strip symbol tables for more detailed call stacks
- Don't link libc statically, or if you do links statically later use valgrind option --soname-synonyms=somalloc=NONE, in order valgrind can replace malloc etc with its own versions. See also --soname-synonyms=somalloc=foo option to let valgrind replace foo if you use the foo lib (tcmalloc, jemalloc, ...).
- Adjust --num-callers when callstacks are not deep enough
- With option --track-origins=yes (since 3.4.0), valgrind's output lets you more easily track down `uninitialized value' errors, at the cost of speed. See also client request VALGRIND_CHECK_VALUE_IS_DEFINED.
- avoid calling dlclose on shared objects, because valgrind will discard debug information, which means that you have ?? entries in the callstack
- To trace child processes, use the --trace-children=yes option
- Occasionally Valgrind stack traces get the wrong function names. Examples: bcmp instead of memcmp, index instead of strchr, and rindex instead of strrchr.

- Example:
 * Many checks and rather verbose output: valgrind  --leak-check=full --show-leak-kinds=all --track-origins=yes --num-callers=100 --gen-suppressions=all --suppressions=<suppressions-file> foo

Memcheck;; Calls to malloc/new/free/delete are intercepted. Memcheck tracks addressability at the byte-level, and initialisation of values at the bit-level (i.e. does not report spurious errors on bitfield operations). Slowdown ~10x-30x.
Cachegrind;; CPU cache profiler. It performs detailed simulation of the I1, D1 and L2 caches in your CPU. Slowdown ~20x-100x.
Callgrind / KCacheGrind;; Extension to Cachegrind: Additionally delivers callgraph information. KCacheGrind is a visualization frontend.
Massif;; Heap profiler.
Helgrind;; Thread debugger / finds data races.
DRD;; Also thread debugger?



== Build tools / Libraries

=== Linker
gold

=== Compiler
gcc, clang

=== Build
build system: cmake, ant, maven
?: ninja, make


=== Dynamic memory allocation
tcmalloc


== Floating-point numbers

Is a representation for a subset of the real numbers and has the form p×ß^e^, where p is the _significant_ (or _coefficient_ or _fraction_), ß the _base_ (or _radix_) and e is the _exponent_. The number of digits in the significant is called _precision_. The range of the exponent is e~min~≤e≤e~max~. The real numbers that are exactly representable are called _machine numbers_.

In a _normalized_ floating-point representation, the leading digit of the significant is non-zero. A normalized representation is _unique_. In contrast, 1.20×10^0^ and 0.12×10^-1^ represent the same number. A normalized representation cannot directly represent zero. A natural way to _represent zero_ is 1×ß^e~min~-1^, since this preserves the fact that the numerical ordering of nonnegative real numbers corresponds to the lexicographic ordering of their floating-point representations. As a consequence, when the exponent is stored in a k bit field, only 2^k^-1 values are available for use as exponents.

The smallest positive normalized number is _UFL_ = 1×ß^e~min~^ and is called the _underflow level_. The largest positive normalized number is _OFL_ = ß^e~max~+1^(1-ß^-p^) and is called the _overflow level_.

A disadvantage of normalized numbers is the relatively large empty gap (0, UFL), called _underflow gap_. Note that this gap is much (*to-do* prove) larger than the gap between the UFL and the next larger float. (*to-do* talk about _machine epsilon_ and _underflow level_ (aka _UFL_).) _Underflow_ (or _arithmetic underflow_ or _floating point underflow_) is when a result falls into the underflow gap. It is then truncated to zero, which is called _flush to zero_. That can lead to large relative errors.

Any number lying in the underflow gap is called _denormalized number_ (or _subnormal number_ or _denormal _number_). It is one with an exponent of e~min~ and a zero leading bit, i.e. it is not normalized. E.g. when e~min~=-5 (and p=3, ß=10), the smallest positive number is 0.01×10^-5^ instead of 1.00×10^-5^. When a result falls in the underflow gap, the result can be rounded to one of the denormalized numbers, which is called _gradual underflow_. Denormalized numbers ensure x=y ⇔ x-y=0 even for small numbers. That is arguably important to reason about the program. E.g. only then "if (x!=y) z=1/(x-y)" really never ends up in a division by zero. Also, without denormalized numbers, x-y with normalized inputs can have a large relative error. Opponents of denormalized numbers argue that they are too complicated given that they are only occasionally used. Even today some IEEE compliant HW supports them only in SW via traps.

When the base is 2, often an _implicit leading_ (aka _hidden leading_) bit is used. It is 1 if e~stored~≥e~min~ (1.xx×2^e~stored~^), and, if denormalized numbers are used, 0 if e~stored~=e~min~-1 (0.xx×2^e~min~^).

If a real number x is not exactly representable, then it is approximated by a "nearby" floating-point number _fl(x)_. This process is called _rounding_, and error introduced called _rounding error_.

=== IEEE

IEEE 754: Base is 2 or 10. e~min~ = 1 - e~max~.

Signed zero: There are multiple good reasons that a distinction is made bewteen
+0 and -0. See chapter "signed zero" in https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html.


An attempt to generate a nonzero floating–point number that is too tiny to represent in the usual way precipitates _Underflow_.

*to-do* Epsilon comparison. Isn't relative error better than absolute?

References:

- https://bitbashing.io/comparing-floats.html
- https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html
- http://www.maths.lth.se/na/courses/FMN140/FMN140-05/float.pdf

== Information managers / note taking

Consider using Evernote: https://evernote.com/intl/de/?var=1
